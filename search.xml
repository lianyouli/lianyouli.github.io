<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>it-python-plugin</title>
      <link href="/uncategorized/it-python-plugin/"/>
      <url>/uncategorized/it-python-plugin/</url>
      
        <content type="html"><![CDATA[<blockquote><blockquote><p>使用python开发一套简单的插件框架是比较快的，可以利用<code>importlib</code> ，可以参考<a href="https://stackoverflow.com/questions/932069/building-a-minimal-plugin-architecture-in-python" target="_blank" rel="noopener">Building a minimal plugin architecture in Python - Stack Overflow</a><br>这里还是关注在python 插件框架 - yapsy上</p></blockquote></blockquote><a id="more"></a><h1 id="官网"><a href="#官网" class="headerlink" title="官网"></a>官网</h1><h1 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h1><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install yapsy</span><br></pre></td></tr></table></figure><h1 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h1><p><a href="https://stackoverflow.com/questions/5333128/yapsy-minimal-example" target="_blank" rel="noopener">python - Yapsy minimal example - Stack Overflow</a></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">.</span><br><span class="line">├── plugins</span><br><span class="line">│   ├── __pycache__</span><br><span class="line">│   │   └── plugin1.cpython-39.pyc</span><br><span class="line">│   ├── plugin1.py</span><br><span class="line">│   └── plugin1.yapsy-plugin</span><br><span class="line">└── <span class="built_in">test</span>-main.py</span><br></pre></td></tr></table></figure><h2 id="test-main-py"><a href="#test-main-py" class="headerlink" title="test-main.py"></a>test-main.py</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">Author: Arthur lianyoucq@163.com</span></span><br><span class="line"><span class="string">Date: 2023-04-07 21:57:57</span></span><br><span class="line"><span class="string">LastEditors: Arthur</span></span><br><span class="line"><span class="string">LastEditTime: 2023-04-08 06:19:50</span></span><br><span class="line"><span class="string">Description: invoke the plugin</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="keyword">from</span> yapsy.PluginInfo <span class="keyword">import</span> PluginInfo</span><br><span class="line"><span class="keyword">import</span> logging</span><br><span class="line"><span class="keyword">from</span> yapsy.PluginManager <span class="keyword">import</span> PluginManager</span><br><span class="line"></span><br><span class="line">logging.basicConfig(level=logging.DEBUG)</span><br><span class="line"></span><br><span class="line">manager = PluginManager()</span><br><span class="line">manager.setPluginPlaces(directories_list=[<span class="string">"plugins"</span>])</span><br><span class="line">manager.collectPlugins()</span><br><span class="line">i = <span class="literal">None</span>  <span class="comment"># type: PluginInfo</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> manager.getAllPlugins():  <span class="comment"># type: PluginInfo</span></span><br><span class="line">    logging.debug(<span class="string">"##############"</span>)</span><br><span class="line">    i.plugin_object.transform(text=&#123;<span class="string">"Hello"</span>: <span class="string">"World"</span>&#125;)</span><br><span class="line">    logging.debug(<span class="string">"##############"</span>)</span><br><span class="line">    </span><br><span class="line">    logging.info(hasattr(i.plugin_object, <span class="string">'transform'</span>))</span><br><span class="line">    p = getattr(i.plugin_object, <span class="string">'transform'</span>)</span><br><span class="line">    logging.debug(<span class="string">"##############"</span>)</span><br><span class="line">    p(text=&#123;<span class="string">"hello"</span>: <span class="string">"arthur"</span>&#125;)</span><br><span class="line"></span><br><span class="line">    logging.debug(<span class="string">"##############"</span>)</span><br><span class="line">    logging.info(i.description)</span><br><span class="line">    logging.info(i.author)</span><br><span class="line">    logging.info(i.version)</span><br></pre></td></tr></table></figure><h2 id="plugin1-py"><a href="#plugin1-py" class="headerlink" title="plugin1.py"></a>plugin1.py</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Author: Arthur lianyoucq@163.com</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Date: 2023-04-07 22:06:17</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">LastEditors: Arthur</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">LastEditTime: 2023-04-07 22:19:45</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Description: show plugin</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="keyword">from</span> yapsy <span class="keyword">import</span> IPlugin</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">PluginOne</span><span class="params">(IPlugin.IPlugin)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">transform</span><span class="params">(self, text: dict)</span>:</span></span><br><span class="line">        print(<span class="string">"transform the data"</span>, text)</span><br></pre></td></tr></table></figure><h2 id="plugin1-yapsy-plugin"><a href="#plugin1-yapsy-plugin" class="headerlink" title="plugin1.yapsy-plugin"></a>plugin1.yapsy-plugin</h2><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">[Core]</span></span><br><span class="line"><span class="attr">Name</span> = Plugin <span class="number">1</span></span><br><span class="line"><span class="attr">Module</span> = plugin1</span><br><span class="line"></span><br><span class="line"><span class="section">[Documentation]</span></span><br><span class="line"><span class="attr">Author</span> = Arthur Li</span><br><span class="line"><span class="attr">Version</span> = <span class="number">1.3</span>.<span class="number">3</span></span><br><span class="line"><span class="attr">Website</span> = https://lianyouli.gitee.io/</span><br><span class="line"><span class="attr">Description</span> = just a demo plugin</span><br></pre></td></tr></table></figure><p>这个配置可以从<code>PluginManager.py</code>文件中找到</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line">Plugin Info File Format</span><br><span class="line"></span><br><span class="line">-----------------------</span><br><span class="line"></span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">The plugin info file is a text file *encoded in ASCII or UTF-8* and</span><br><span class="line"></span><br><span class="line">gathering, as its name suggests, some basic information about the</span><br><span class="line"></span><br><span class="line">plugin.</span><br><span class="line"></span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">- it gives crucial information needed to be able to load the plugin</span><br><span class="line"></span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">- it provides some documentation like information like the plugin</span><br><span class="line"></span><br><span class="line">author&#39;s name and a short description fo the plugin functionality.</span><br><span class="line"></span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">Here is an example of what such a file should contain::</span><br><span class="line"></span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">[Core]</span><br><span class="line"></span><br><span class="line">Name &#x3D; My plugin Name</span><br><span class="line"></span><br><span class="line">Module &#x3D; the_name_of_the_pluginto_load_with_no_py_ending</span><br><span class="line"></span><br><span class="line">[Documentation]</span><br><span class="line"></span><br><span class="line">Description &#x3D; What my plugin broadly does</span><br><span class="line"></span><br><span class="line">Author &#x3D; My very own name</span><br><span class="line"></span><br><span class="line">Version &#x3D; the_version_number_of_the_plugin</span><br><span class="line"></span><br><span class="line">Website &#x3D; My very own website</span><br></pre></td></tr></table></figure><h1 id="运行结果"><a href="#运行结果" class="headerlink" title="运行结果"></a>运行结果</h1><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">....</span><br><span class="line">DEBUG:yapsy:correct subclass tests failed <span class="keyword">for</span>: __spec__ <span class="keyword">in</span> /Users/arthur/Documents/Workspace/python/lab/hello-plugins/plugins/plugin1</span><br><span class="line"></span><br><span class="line">Traceback (most recent call last):</span><br><span class="line"></span><br><span class="line">File <span class="string">"/Users/arthur/opt/miniconda3/lib/python3.9/site-packages/yapsy/PluginManager.py"</span>, line 530, <span class="keyword">in</span> loadPlugins</span><br><span class="line"></span><br><span class="line">is_correct_subclass = issubclass(</span><br><span class="line"></span><br><span class="line">TypeError: issubclass() arg 1 must be a class</span><br><span class="line"></span><br><span class="line">DEBUG:root:<span class="comment">##############</span></span><br><span class="line"></span><br><span class="line">DEBUG:root:<span class="comment">##############</span></span><br><span class="line"></span><br><span class="line">INFO:root:True</span><br><span class="line"></span><br><span class="line">DEBUG:root:<span class="comment">##############</span></span><br><span class="line"></span><br><span class="line">DEBUG:root:<span class="comment">##############</span></span><br><span class="line"></span><br><span class="line">transform the data &#123;<span class="string">'Hello'</span>: <span class="string">'World'</span>&#125;</span><br><span class="line"></span><br><span class="line">transform the data &#123;<span class="string">'hello'</span>: <span class="string">'arthur'</span>&#125;</span><br><span class="line"></span><br><span class="line">INFO:root:just a demo plugin</span><br><span class="line"></span><br><span class="line">INFO:root:Arthur Li</span><br><span class="line"></span><br><span class="line">INFO:root:1.3.3</span><br></pre></td></tr></table></figure><p>符合预期</p><h1 id="Q-amp-A"><a href="#Q-amp-A" class="headerlink" title="Q&amp;A"></a>Q&amp;A</h1><h2 id="TypeError-issubclass-arg-1-must-be-a-class"><a href="#TypeError-issubclass-arg-1-must-be-a-class" class="headerlink" title="TypeError: issubclass() arg 1 must be a class"></a>TypeError: issubclass() arg 1 must be a class</h2><p>编辑<code>PluginManager.py</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># 在文件开头导入inspect</span></span><br><span class="line"><span class="keyword">import</span> inspect</span><br><span class="line"></span><br><span class="line"><span class="comment"># 530行左右</span></span><br><span class="line"><span class="keyword">for</span> element, element_name <span class="keyword">in</span> ((getattr(candidate_module, name), name) <span class="keyword">for</span> name <span class="keyword">in</span> dir(candidate_module)):</span><br><span class="line">    plugin_info_reference = <span class="literal">None</span></span><br><span class="line">    <span class="keyword">for</span> category_name <span class="keyword">in</span> self.categories_interfaces:</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            <span class="comment"># https://sourceforge.net/p/yapsy/bugs/42/</span></span><br><span class="line">            <span class="comment"># 添加：  inspect.isclass(element) and</span></span><br><span class="line">            is_correct_subclass = inspect.isclass(element) <span class="keyword">and</span> issubclass(</span><br><span class="line">                element, self.categories_interfaces[category_name])</span><br><span class="line">        <span class="keyword">except</span> Exception:</span><br><span class="line">            exc_info = sys.exc_info()</span><br><span class="line">            log.debug(<span class="string">"correct subclass tests failed for: %s in %s"</span> % (element_name, candidate_filepath),</span><br><span class="line">                      exc_info=exc_info)</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        <span class="keyword">if</span> is_correct_subclass <span class="keyword">and</span> element <span class="keyword">is</span> <span class="keyword">not</span> self.categories_interfaces[category_name]:</span><br><span class="line">            current_category = category_name</span><br></pre></td></tr></table></figure><h2 id="DEBUG-yapsy-plugin1-py-is-not-a-valid-plugin-for-strategy-info-ext"><a href="#DEBUG-yapsy-plugin1-py-is-not-a-valid-plugin-for-strategy-info-ext" class="headerlink" title="DEBUG:yapsy:plugin1.py is not a valid plugin for strategy info_ext"></a>DEBUG:yapsy:plugin1.py is not a valid plugin for strategy info_ext</h2><p>导致这个debug错误的原因是因为<code>PluginFileLocator</code>会扫描plugins目录的中的每个文件，它只读取.yapsy-plugin后缀的文件，不过这个目录还有其他的python文件，所以这个python文件是不符合的插件说明文件的命名规则，所以就debug报错了。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> analyzer <span class="keyword">in</span> self._analyzers:</span><br><span class="line">    <span class="comment"># print("... with analyzer %s" % analyzer.name)</span></span><br><span class="line">    <span class="comment"># eliminate the obvious non plugin files</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> analyzer.isValidPlugin(filename):</span><br><span class="line">        log.debug(<span class="string">"%s is not a valid plugin for strategy %s"</span> % (filename, analyzer.name))</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> IT，PYTHON, PLUGIN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>团队沟通</title>
      <link href="/Team/team-communication/"/>
      <url>/Team/team-communication/</url>
      
        <content type="html"><![CDATA[<blockquote><p>沟通</p></blockquote><p>团队有两个小朋友，说小朋友，确实比我小一些，其实也工作了好几年的了。团队使用confluence文档管理系统以及Jira协作管理平台。小朋友在自己的任务里，jira都是空白，没有任何问题或者任何值得记录下来的。我也经常提醒，然后依旧是空白。我在讲解需求时，都没有问题，一旦去做时，一个小朋友把需求讲解时提到的都忘得一干二净，需求明确标识的地方都视而不见，然后自己凭空捏造。然后，我在过代码时，简直不能直视。</p>]]></content>
      
      
      <categories>
          
          <category> Team </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Team </tag>
            
            <tag> Communication </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Flink安装</title>
      <link href="/IT/it-bigdata-flink-installation/"/>
      <url>/IT/it-bigdata-flink-installation/</url>
      
        <content type="html"><![CDATA[<blockquote><p>对于学习一个新的事物时，最好的开始就是把它运行起来；当实操时，才能更深地理解一些新的概念以及其边界。</p><p>flink 1.14.4 standalone 安装， Zookeeper HA 安装</p></blockquote><a id="more"></a><h2 id="Standalone"><a href="#Standalone" class="headerlink" title="Standalone"></a>Standalone</h2><p>如果一台机器，直接启动就可以使用了。</p><p>如果是多台机器，则需要在</p><ul><li><strong>masters</strong> 配置一台job manager 主机名称</li><li><strong>workers</strong>文件里配置所有节点信息</li><li><strong>jobmanager.rpc.address</strong> 配置成<strong>masters</strong>里的机器主机名称。</li><li>服务启动账户在机器之间免密登录</li></ul><h2 id="Zookeeper-HA"><a href="#Zookeeper-HA" class="headerlink" title="Zookeeper HA"></a>Zookeeper HA</h2><p><a href="https://nightlies.apache.org/flink/flink-docs-release-1.15/docs/deployment/ha/zookeeper_ha/" target="_blank" rel="noopener">ZooKeeper HA Services | Apache Flink</a></p><h3 id="flink-shade-hadoop"><a href="#flink-shade-hadoop" class="headerlink" title="flink-shade-hadoop"></a>flink-shade-hadoop</h3><p>根据自己的版本将对应的flink-shaded-hadoop-X-uber下载下来，放到lib目录。 因为HA时，参数high-availability.storageDir 需要存放在分布式文件系统上。</p> <img src="/IT/it-bigdata-flink-installation/image-20220527210655782.png" alt="image-20220527210655782" style="zoom:50%;"><h3 id="flink-conf-xml"><a href="#flink-conf-xml" class="headerlink" title="flink-conf.xml"></a>flink-conf.xml</h3><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#==============================================================================</span></span><br><span class="line"><span class="comment"># High Availability</span></span><br><span class="line"><span class="comment">#==============================================================================</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># The high-availability mode. Possible options are 'NONE' or 'zookeeper'.</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="attr">high-availability:</span> <span class="string">zookeeper</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># The path where metadata for master recovery is persisted. While ZooKeeper stores</span></span><br><span class="line"><span class="comment"># the small ground truth for checkpoint and leader election, this location stores</span></span><br><span class="line"><span class="comment"># the larger objects, like persisted dataflow graphs.</span></span><br><span class="line"><span class="comment"># </span></span><br><span class="line"><span class="comment"># Must be a durable file system that is accessible from all nodes</span></span><br><span class="line"><span class="comment"># (like HDFS, S3, Ceph, nfs, ...) </span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="attr">high-availability.storageDir:</span> <span class="string">hdfs:///lab/flink/ha/</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># The list of ZooKeeper quorum peers that coordinate the high-availability</span></span><br><span class="line"><span class="comment"># setup. This must be a list of the form:</span></span><br><span class="line"><span class="comment"># "host1:clientPort,host2:clientPort,..." (default clientPort: 2181)</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="attr">high-availability.zookeeper.quorum:</span> <span class="string">localhost:2181</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># The root ZooKeeper node, under which all cluster nodes are placed.</span></span><br><span class="line"><span class="attr">high-availability.zookeeper.path.root:</span> <span class="string">/flink</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Optional, The cluster-id ZooKeeper node, under which all required coordination data for a cluster is placed.</span></span><br><span class="line"><span class="attr">high-availability.cluster-id:</span> <span class="string">/flink_arthur_ns</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># ACL options are based on https://zookeeper.apache.org/doc/r3.1.2/zookeeperProgrammers.html#sc_BuiltinACLSchemes</span></span><br><span class="line"><span class="comment"># It can be either "creator" (ZOO_CREATE_ALL_ACL) or "open" (ZOO_OPEN_ACL_UNSAFE)</span></span><br><span class="line"><span class="comment"># The default value is "open" and it can be changed to "creator" if ZK security is enabled</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># high-availability.zookeeper.client.acl: open</span></span><br></pre></td></tr></table></figure><h3 id="zookeeper"><a href="#zookeeper" class="headerlink" title="zookeeper"></a>zookeeper</h3><p>我使用的是独立的单节点的zookeeper。</p><p>不过flink自带了zookeeper，可以通过配置conf/zoo.cfg，然后执行bin/start-zookeeper-quorum.sh 启动</p><h3 id="masters"><a href="#masters" class="headerlink" title="masters"></a>masters</h3><p>根据自己实际情况配置多个master，以实现HA。不过我只配置一个做测试。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">localhost:8081</span><br><span class="line">extra-master-node1:8081</span><br><span class="line">...</span><br></pre></td></tr></table></figure><h3 id="workers"><a href="#workers" class="headerlink" title="workers"></a>workers</h3><p>配置不是job manager角色的机器。</p><h3 id="启动"><a href="#启动" class="headerlink" title="启动"></a>启动</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">(base) ➜  flink bin/start-cluster.sh </span><br><span class="line">Starting HA cluster with 1 masters.</span><br><span class="line">Starting standalonesession daemon on host sleety.local.</span><br><span class="line">Starting taskexecutor daemon on host sleety.local.</span><br></pre></td></tr></table></figure><h3 id="zookeeper-记录"><a href="#zookeeper-记录" class="headerlink" title="zookeeper 记录"></a>zookeeper 记录</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">[zk: localhost:2181(CONNECTED) 43] ls /</span><br><span class="line">[flink, zookeeper]</span><br><span class="line">[zk: localhost:2181(CONNECTED) 44] ls /flink</span><br><span class="line">[flink_arthur_ns]</span><br><span class="line">[zk: localhost:2181(CONNECTED) 45] ls /flink/flink_arthur_ns</span><br><span class="line">[jobgraphs, leader]</span><br><span class="line">[zk: localhost:2181(CONNECTED) 46] ls /flink/flink_arthur_ns/leader</span><br><span class="line">[dispatcher, resource_manager, rest_server]</span><br><span class="line">[zk: localhost:2181(CONNECTED) 47] ls /flink/flink_arthur_ns/leader/resource_manager</span><br><span class="line">[connection_info, latch]</span><br><span class="line">[zk: localhost:2181(CONNECTED) 48] get /flink/flink_arthur_ns/leader/resource_manager/connection_info</span><br><span class="line">��w=;akka.tcp://flink@localhost:52797/user/rpc/resourcemanager_1srjava.util.UUID����m�/J</span><br><span class="line">                                                                                        leastSigBitsJ</span><br><span class="line">                                                                                                     mostSigBitsxp�kNP�OD�)7Y��H?</span><br><span class="line">[zk: localhost:2181(CONNECTED) 49] get /flink/flink_arthur_ns/leader/rest_server/connection_info </span><br><span class="line">��whttp://localhost:8081srjava.util.UUID����m�/J</span><br><span class="line">                                                leastSigBitsJ</span><br><span class="line">                                                             mostSigBitsxp�</span><br><span class="line">                                                                           �0A�hVp��J�</span><br><span class="line">[zk: localhost:2181(CONNECTED) 50]</span><br></pre></td></tr></table></figure><h3 id="hdfs-ha目录"><a href="#hdfs-ha目录" class="headerlink" title="hdfs ha目录"></a>hdfs ha目录</h3><p><img src="/IT/it-bigdata-flink-installation/image-20220527212122441.png" alt="image-20220527212122441"></p><h2 id="Yarn"><a href="#Yarn" class="headerlink" title="Yarn"></a>Yarn</h2><p><a href="https://nightlies.apache.org/flink/flink-docs-release-1.15/docs/deployment/resource-providers/yarn/" target="_blank" rel="noopener">YARN | Apache Flink</a></p><h3 id="启动-1"><a href="#启动-1" class="headerlink" title="启动"></a>启动</h3><blockquote><p>会读取conf/flink-conf.yml的配置</p></blockquote><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> HADOOP_CLASSPATH=`hadoop classpath`</span><br><span class="line"><span class="comment"># 以detach模式启动，即客户端关闭掉，也不影响yarn上的application。</span></span><br><span class="line"><span class="comment"># -tm 指定task manager的内存大小</span></span><br><span class="line"><span class="comment"># -jm 指定job  manager的内存大小</span></span><br><span class="line">bin/yarn-session.sh -d  -tm 1024 -jm 1024</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line">(base) ➜  flink bin/yarn-session.sh -d  -tm 1024 -jm 1024                                         </span><br><span class="line">SLF4J: Class path contains multiple SLF4J bindings.</span><br><span class="line">SLF4J: Found binding <span class="keyword">in</span> [jar:file:/Users/arthur/opt/apache/flink-1.14.4/lib/log4j-slf4j-impl-2.17.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]</span><br><span class="line">SLF4J: Found binding <span class="keyword">in</span> [jar:file:/Users/arthur/opt/apache/hadoop-3.3.1/share/hadoop/common/lib/slf4j-log4j12-1.7.30.jar!/org/slf4j/impl/StaticLoggerBinder.class]</span><br><span class="line">SLF4J: See http://www.slf4j.org/codes.html<span class="comment">#multiple_bindings for an explanation.</span></span><br><span class="line">SLF4J: Actual binding is of <span class="built_in">type</span> [org.apache.logging.slf4j.Log4jLoggerFactory]</span><br><span class="line">2022-05-28 09:16:35,158 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: jobmanager.rpc.address, localhost</span><br><span class="line">2022-05-28 09:16:35,166 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: jobmanager.rpc.port, 6123</span><br><span class="line">2022-05-28 09:16:35,167 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: jobmanager.memory.process.size, 3600m</span><br><span class="line">2022-05-28 09:16:35,167 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: taskmanager.memory.process.size, 4728m</span><br><span class="line">2022-05-28 09:16:35,167 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: taskmanager.numberOfTaskSlots, 4</span><br><span class="line">2022-05-28 09:16:35,167 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: parallelism.default, 1</span><br><span class="line">2022-05-28 09:16:35,167 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: high-availability, zookeeper</span><br><span class="line">2022-05-28 09:16:35,167 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: high-availability.storageDir, hdfs:///lab/flink/ha/</span><br><span class="line">2022-05-28 09:16:35,167 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: high-availability.zookeeper.quorum, localhost:2181</span><br><span class="line">2022-05-28 09:16:35,168 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: high-availability.zookeeper.path.root, /flink</span><br><span class="line">2022-05-28 09:16:35,168 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: high-availability.cluster-id, /flink_arthur_ns</span><br><span class="line">2022-05-28 09:16:35,168 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: jobmanager.execution.failover-strategy, region</span><br><span class="line">2022-05-28 09:16:35,205 INFO  org.apache.flink.yarn.cli.FlinkYarnSessionCli                [] - Found Yarn properties file under /var/folders/y7/45pp3_f51f5f0z_mcj851j4h0000gn/T/.yarn-properties-arthur.</span><br><span class="line">2022-05-28 09:16:35,645 WARN  org.apache.hadoop.util.NativeCodeLoader                      [] - Unable to load native-hadoop library <span class="keyword">for</span> your platform... using <span class="built_in">builtin</span>-java classes <span class="built_in">where</span> applicable</span><br><span class="line">2022-05-28 09:16:35,812 INFO  org.apache.flink.runtime.security.modules.HadoopModule       [] - Hadoop user <span class="built_in">set</span> to arthur (auth:SIMPLE)</span><br><span class="line">2022-05-28 09:16:35,846 INFO  org.apache.flink.runtime.security.modules.JaasModule         [] - Jaas file will be created as /var/folders/y7/45pp3_f51f5f0z_mcj851j4h0000gn/T/jaas-11283110048640415560.conf.</span><br><span class="line">2022-05-28 09:16:35,914 WARN  org.apache.flink.yarn.configuration.YarnLogConfigUtil        [] - The configuration directory (<span class="string">'/Users/arthur/opt/apache/flink-1.14.4/conf'</span>) already contains a LOG4J config file.If you want to use logback, <span class="keyword">then</span> please delete or rename the <span class="built_in">log</span> configuration file.</span><br><span class="line">2022-05-28 09:16:35,998 INFO  org.apache.hadoop.yarn.client.RMProxy                        [] - Connecting to ResourceManager at localhost/127.0.0.1:8050</span><br><span class="line">2022-05-28 09:16:36,292 INFO  org.apache.flink.runtime.util.config.memory.ProcessMemoryUtils [] - The derived from fraction jvm overhead memory (102.400mb (107374184 bytes)) is less than its min value 192.000mb (201326592 bytes), min value will be used instead</span><br><span class="line">2022-05-28 09:16:36,298 INFO  org.apache.flink.runtime.util.config.memory.ProcessMemoryUtils [] - The derived from fraction jvm overhead memory (102.400mb (107374184 bytes)) is less than its min value 192.000mb (201326592 bytes), min value will be used instead</span><br><span class="line">2022-05-28 09:16:36,298 INFO  org.apache.flink.runtime.util.config.memory.ProcessMemoryUtils [] - The derived from fraction network memory (57.600mb (60397978 bytes)) is less than its min value 64.000mb (67108864 bytes), min value will be used instead</span><br><span class="line">2022-05-28 09:16:36,526 INFO  org.apache.hadoop.conf.Configuration                         [] - resource-types.xml not found</span><br><span class="line">2022-05-28 09:16:36,526 INFO  org.apache.hadoop.yarn.util.resource.ResourceUtils           [] - Unable to find <span class="string">'resource-types.xml'</span>.</span><br><span class="line">2022-05-28 09:16:36,595 INFO  org.apache.flink.yarn.YarnClusterDescriptor                  [] - Cluster specification: ClusterSpecification&#123;masterMemoryMB=1024, taskManagerMemoryMB=1024, slotsPerTaskManager=4&#125;</span><br><span class="line">2022-05-28 09:16:39,052 INFO  org.apache.flink.runtime.util.config.memory.ProcessMemoryUtils [] - The derived from fraction jvm overhead memory (102.400mb (107374184 bytes)) is less than its min value 192.000mb (201326592 bytes), min value will be used instead</span><br><span class="line">2022-05-28 09:16:39,066 INFO  org.apache.flink.yarn.YarnClusterDescriptor                  [] - Submitting application master application_1653690191446_0011</span><br><span class="line">2022-05-28 09:16:39,115 INFO  org.apache.hadoop.yarn.client.api.impl.YarnClientImpl        [] - Submitted application application_1653690191446_0011</span><br><span class="line">2022-05-28 09:16:39,115 INFO  org.apache.flink.yarn.YarnClusterDescriptor                  [] - Waiting <span class="keyword">for</span> the cluster to be allocated</span><br><span class="line">2022-05-28 09:16:39,117 INFO  org.apache.flink.yarn.YarnClusterDescriptor                  [] - Deploying cluster, current state ACCEPTED</span><br><span class="line">2022-05-28 09:16:57,652 INFO  org.apache.flink.yarn.YarnClusterDescriptor                  [] - YARN application has been deployed successfully.</span><br><span class="line">2022-05-28 09:16:57,653 INFO  org.apache.flink.yarn.YarnClusterDescriptor                  [] - Found Web Interface localhost:58343 of application <span class="string">'application_1653690191446_0011'</span>.</span><br><span class="line">2022-05-28 09:16:57,949 INFO  org.apache.flink.shaded.curator4.org.apache.curator.utils.Compatibility [] - Running <span class="keyword">in</span> ZooKeeper 3.4.x compatibility mode</span><br><span class="line">2022-05-28 09:16:57,949 INFO  org.apache.flink.shaded.curator4.org.apache.curator.utils.Compatibility [] - Using emulated InjectSessionExpiration</span><br><span class="line">2022-05-28 09:16:57,975 INFO  org.apache.flink.shaded.curator4.org.apache.curator.framework.imps.CuratorFrameworkImpl [] - Starting</span><br><span class="line">2022-05-28 09:16:57,993 INFO  org.apache.flink.shaded.curator4.org.apache.curator.framework.imps.CuratorFrameworkImpl [] - Default schema</span><br><span class="line">2022-05-28 09:16:57,993 WARN  org.apache.flink.shaded.zookeeper3.org.apache.zookeeper.ClientCnxn [] - SASL configuration failed: javax.security.auth.login.LoginException: No JAAS configuration section named <span class="string">'Client'</span> was found <span class="keyword">in</span> specified JAAS configuration file: <span class="string">'/var/folders/y7/45pp3_f51f5f0z_mcj851j4h0000gn/T/jaas-11283110048640415560.conf'</span>. Will <span class="built_in">continue</span> connection to Zookeeper server without SASL authentication, <span class="keyword">if</span> Zookeeper server allows it.</span><br><span class="line">2022-05-28 09:16:57,995 ERROR org.apache.flink.shaded.curator4.org.apache.curator.ConnectionState [] - Authentication failed</span><br><span class="line">2022-05-28 09:16:58,000 INFO  org.apache.flink.shaded.curator4.org.apache.curator.framework.state.ConnectionStateManager [] - State change: CONNECTED</span><br><span class="line">2022-05-28 09:16:58,020 INFO  org.apache.flink.runtime.leaderretrieval.DefaultLeaderRetrievalService [] - Starting DefaultLeaderRetrievalService with ZookeeperLeaderRetrievalDriver&#123;connectionInformationPath=<span class="string">'/leader/rest_server/connection_info'</span>&#125;.</span><br><span class="line">JobManager Web Interface: http://localhost:58343</span><br><span class="line">2022-05-28 09:16:58,055 INFO  org.apache.flink.yarn.cli.FlinkYarnSessionCli                [] - The Flink YARN session cluster has been started <span class="keyword">in</span> detached mode. In order to stop Flink gracefully, use the following <span class="built_in">command</span>:</span><br><span class="line">$ <span class="built_in">echo</span> <span class="string">"stop"</span> | ./bin/yarn-session.sh -id application_1653690191446_0011</span><br><span class="line">If this should not be possible, <span class="keyword">then</span> you can also <span class="built_in">kill</span> Flink via YARN<span class="string">'s web interface or via:</span></span><br><span class="line"><span class="string">$ yarn application -kill application_1653690191446_0011</span></span><br><span class="line"><span class="string">Note that killing Flink might not clean up all job artifacts and temporary files.</span></span><br></pre></td></tr></table></figure><p><img src="/IT/it-bigdata-flink-installation/image-20220528092326670.png" alt="image-20220528092326670"></p><h3 id="停Flink"><a href="#停Flink" class="headerlink" title="停Flink"></a>停Flink</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 优雅的方式</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"stop"</span> | ./bin/yarn-session.sh -id &lt;application id&gt;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 暴力的方式</span></span><br><span class="line"><span class="comment"># 可能不会清理job artifacts和temporary files</span></span><br><span class="line">yarn application -<span class="built_in">kill</span> &lt;application id&gt;</span><br></pre></td></tr></table></figure><h3 id="提交任务"><a href="#提交任务" class="headerlink" title="提交任务"></a>提交任务</h3><blockquote><p>yarn-session模式</p></blockquote><h4 id="命令行方式"><a href="#命令行方式" class="headerlink" title="命令行方式"></a>命令行方式</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">flink ./bin/flink run -t yarn-session \        </span><br><span class="line"> -Dyarn.application.id=application_1653690191446_0011 \</span><br><span class="line"> ./examples/streaming/TopSpeedWindowing.jar</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">(base) ➜  flink ./bin/flink run -t yarn-session \        </span><br><span class="line">  -Dyarn.application.id=application_1653690191446_0011 \</span><br><span class="line">  ./examples/streaming/TopSpeedWindowing.jar</span><br><span class="line">SLF4J: Class path contains multiple SLF4J bindings.</span><br><span class="line">SLF4J: Found binding <span class="keyword">in</span> [jar:file:/Users/arthur/opt/apache/flink-1.14.4/lib/log4j-slf4j-impl-2.17.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]</span><br><span class="line">SLF4J: Found binding <span class="keyword">in</span> [jar:file:/Users/arthur/opt/apache/hadoop-3.3.1/share/hadoop/common/lib/slf4j-log4j12-1.7.30.jar!/org/slf4j/impl/StaticLoggerBinder.class]</span><br><span class="line">SLF4J: See http://www.slf4j.org/codes.html<span class="comment">#multiple_bindings for an explanation.</span></span><br><span class="line">SLF4J: Actual binding is of <span class="built_in">type</span> [org.apache.logging.slf4j.Log4jLoggerFactory]</span><br><span class="line">2022-05-28 09:22:56,925 INFO  org.apache.flink.yarn.cli.FlinkYarnSessionCli                [] - Found Yarn properties file under /var/folders/y7/45pp3_f51f5f0z_mcj851j4h0000gn/T/.yarn-properties-arthur.</span><br><span class="line">2022-05-28 09:22:56,925 INFO  org.apache.flink.yarn.cli.FlinkYarnSessionCli                [] - Found Yarn properties file under /var/folders/y7/45pp3_f51f5f0z_mcj851j4h0000gn/T/.yarn-properties-arthur.</span><br><span class="line">Executing TopSpeedWindowing example with default input data <span class="built_in">set</span>.</span><br><span class="line">Use --input to specify file input.</span><br><span class="line">Printing result to stdout. Use --output to specify output path.</span><br><span class="line">WARNING: An illegal reflective access operation has occurred</span><br><span class="line">WARNING: Illegal reflective access by org.apache.flink.api.java.ClosureCleaner (file:/Users/arthur/opt/apache/flink-1.14.4/lib/flink-dist_2.12-1.14.4.jar) to field java.lang.String.value</span><br><span class="line">WARNING: Please consider reporting this to the maintainers of org.apache.flink.api.java.ClosureCleaner</span><br><span class="line">WARNING: Use --illegal-access=warn to <span class="built_in">enable</span> warnings of further illegal reflective access operations</span><br><span class="line">WARNING: All illegal access operations will be denied <span class="keyword">in</span> a future release</span><br><span class="line">2022-05-28 09:22:57,344 WARN  org.apache.flink.yarn.configuration.YarnLogConfigUtil        [] - The configuration directory (<span class="string">'/Users/arthur/opt/apache/flink-1.14.4/conf'</span>) already contains a LOG4J config file.If you want to use logback, <span class="keyword">then</span> please delete or rename the <span class="built_in">log</span> configuration file.</span><br><span class="line">2022-05-28 09:22:57,400 INFO  org.apache.hadoop.yarn.client.RMProxy                        [] - Connecting to ResourceManager at localhost/127.0.0.1:8050</span><br><span class="line">2022-05-28 09:22:57,512 INFO  org.apache.flink.yarn.YarnClusterDescriptor                  [] - No path <span class="keyword">for</span> the flink jar passed. Using the location of class org.apache.flink.yarn.YarnClusterDescriptor to locate the jar</span><br><span class="line">2022-05-28 09:22:57,592 INFO  org.apache.flink.yarn.YarnClusterDescriptor                  [] - Found Web Interface localhost:58343 of application <span class="string">'application_1653690191446_0011'</span>.</span><br><span class="line">Job has been submitted with JobID 23d36df8aeabea35eb1ec08e8788bc5b</span><br></pre></td></tr></table></figure><h4 id="页面"><a href="#页面" class="headerlink" title="页面"></a>页面</h4><p><img src="/IT/it-bigdata-flink-installation/image-20220528092940808.png" alt="image-20220528092940808"></p><p><img src="/IT/it-bigdata-flink-installation/image-20220528093009336.png" alt="image-20220528093009336"></p><p><img src="/IT/it-bigdata-flink-installation/image-20220528092526928.png" alt="image-20220528092526928"></p><h3 id="查看任务"><a href="#查看任务" class="headerlink" title="查看任务"></a>查看任务</h3><h4 id="命令行"><a href="#命令行" class="headerlink" title="命令行"></a>命令行</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">flink bin/flink list -a -Dyarn.application.id=&lt;application id&gt; -t yarn-session</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">(base) ➜  flink bin/flink list -a -Dyarn.application.id=application_1653690191446_0011 -t yarn-session</span><br><span class="line">2022-05-28 09:31:29,869 INFO  org.apache.flink.yarn.cli.FlinkYarnSessionCli                [] - Found Yarn properties file under /var/folders/y7/45pp3_f51f5f0z_mcj851j4h0000gn/T/.yarn-properties-arthur.</span><br><span class="line">2022-05-28 09:31:29,869 INFO  org.apache.flink.yarn.cli.FlinkYarnSessionCli                [] - Found Yarn properties file under /var/folders/y7/45pp3_f51f5f0z_mcj851j4h0000gn/T/.yarn-properties-arthur.</span><br><span class="line">2022-05-28 09:31:30,026 WARN  org.apache.flink.yarn.configuration.YarnLogConfigUtil        [] - The configuration directory (<span class="string">'/Users/arthur/opt/apache/flink-1.14.4/conf'</span>) already contains a LOG4J config file.If you want to use logback, <span class="keyword">then</span> please delete or rename the <span class="built_in">log</span> configuration file.</span><br><span class="line">2022-05-28 09:31:30,090 INFO  org.apache.hadoop.yarn.client.RMProxy                        [] - Connecting to ResourceManager at localhost/127.0.0.1:8050</span><br><span class="line">2022-05-28 09:31:30,200 INFO  org.apache.flink.yarn.YarnClusterDescriptor                  [] - No path <span class="keyword">for</span> the flink jar passed. Using the location of class org.apache.flink.yarn.YarnClusterDescriptor to locate the jar</span><br><span class="line">2022-05-28 09:31:30,281 INFO  org.apache.flink.yarn.YarnClusterDescriptor                  [] - Found Web Interface localhost:58343 of application <span class="string">'application_1653690191446_0011'</span>.</span><br><span class="line">Waiting <span class="keyword">for</span> response...</span><br><span class="line">------------------ Running/Restarting Jobs -------------------</span><br><span class="line">28.05.2022 09:22:58 : 23d36df8aeabea35eb1ec08e8788bc5b : CarTopSpeedWindowingExample (RUNNING)</span><br><span class="line">--------------------------------------------------------------</span><br><span class="line">No scheduled <span class="built_in">jobs</span>.</span><br></pre></td></tr></table></figure><h4 id="页面-1"><a href="#页面-1" class="headerlink" title="页面"></a>页面</h4><p><img src="/IT/it-bigdata-flink-installation/image-20220528092824803.png" alt="image-20220528092824803"></p><h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><ul><li><p>java.lang.NoSuchMethod<strong>Error</strong>: org.apache.commons.cli.Option.builder</p><blockquote><p>flink-arthur-standalonesession-0-sleety.local.out:Exception in thread “main” java.lang.NoSuchMethod<strong>Error</strong>: org.apache.commons.cli.Option.builder(Ljava/lang/String;)Lorg/apache/commons/cli/Option$Builder;</p></blockquote><p>原因</p><blockquote><p>lib目录里缺少 commons-cli-<version>.jar </version></p></blockquote></li></ul><p>  解决方案</p><blockquote><p>将最新版本的commons-cli-1.4.jar放到了lib目录</p></blockquote><p>​    </p>]]></content>
      
      
      <categories>
          
          <category> IT </category>
          
      </categories>
      
      
        <tags>
            
            <tag> streaming </tag>
            
            <tag> bigdata </tag>
            
            <tag> flink </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>hive查询和监控设置</title>
      <link href="/IT/it-bigdata-hive-simple-query/"/>
      <url>/IT/it-bigdata-hive-simple-query/</url>
      
        <content type="html"><![CDATA[<blockquote><p>hive查询设置，包括统计信息等以及和prometheus集成</p></blockquote><a id="more"></a><h2 id="统计信息"><a href="#统计信息" class="headerlink" title="统计信息"></a>统计信息</h2> <img src="/IT/it-bigdata-hive-simple-query/image-20220508091900565.png" alt="image-20220508091900565" style="zoom: 33%;"><h3 id="创建表"><a href="#创建表" class="headerlink" title="创建表"></a>创建表</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">use</span> <span class="keyword">default</span>;</span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> <span class="keyword">test</span> (<span class="keyword">id</span> <span class="keyword">string</span>);</span><br></pre></td></tr></table></figure><h3 id="插入数据"><a href="#插入数据" class="headerlink" title="插入数据"></a>插入数据</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> <span class="keyword">test</span> <span class="keyword">values</span> (<span class="string">'hello'</span>);</span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> <span class="keyword">test</span> <span class="keyword">values</span> (<span class="string">'hello'</span>);</span><br></pre></td></tr></table></figure><h3 id="查看数据"><a href="#查看数据" class="headerlink" title="查看数据"></a>查看数据</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> <span class="keyword">test</span>;</span><br><span class="line">+<span class="comment">----------+</span></span><br><span class="line">| test.id  |</span><br><span class="line">+<span class="comment">----------+</span></span><br><span class="line">| hello    |</span><br><span class="line">| hello    |</span><br><span class="line">+<span class="comment">----------+</span></span><br></pre></td></tr></table></figure><h3 id="查看统计行数"><a href="#查看统计行数" class="headerlink" title="查看统计行数"></a>查看统计行数</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="keyword">count</span>(*) <span class="keyword">from</span> <span class="keyword">test</span>;</span><br><span class="line">+<span class="comment">------+</span></span><br><span class="line">| _c0  |</span><br><span class="line">+<span class="comment">------+</span></span><br><span class="line">| 2    |</span><br><span class="line">+<span class="comment">------+</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">select</span> <span class="keyword">count</span>(<span class="keyword">id</span>) <span class="keyword">from</span> <span class="keyword">test</span>;</span><br><span class="line">+<span class="comment">------+</span></span><br><span class="line">| _c0  |</span><br><span class="line">+<span class="comment">------+</span></span><br><span class="line">| 2    |</span><br><span class="line">+<span class="comment">------+</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">describe</span> formatted <span class="keyword">test</span>;</span><br></pre></td></tr></table></figure><p><img src="/IT/it-bigdata-hive-simple-query/image-20220508085646467.png" alt="image-20220508085646467"></p><h3 id="手动上传文件到-user-hive-warehouse-test"><a href="#手动上传文件到-user-hive-warehouse-test" class="headerlink" title="手动上传文件到/user/hive/warehouse/test"></a>手动上传文件到/user/hive/warehouse/test</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">(base) ➜  hive3 cat from_manual_upload </span><br><span class="line">y</span><br></pre></td></tr></table></figure><p><img src="/IT/it-bigdata-hive-simple-query/image-20220508085844122.png" alt="image-20220508085844122"></p><h3 id="查看数据-1"><a href="#查看数据-1" class="headerlink" title="查看数据"></a>查看数据</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> <span class="keyword">test</span>;</span><br><span class="line">+<span class="comment">----------+</span></span><br><span class="line">| test.id  |</span><br><span class="line">+<span class="comment">----------+</span></span><br><span class="line">| hello    |</span><br><span class="line">| hello    |</span><br><span class="line">| y        |</span><br><span class="line">+<span class="comment">----------+</span></span><br></pre></td></tr></table></figure><h3 id="查看统计行数-1"><a href="#查看统计行数-1" class="headerlink" title="查看统计行数"></a>查看统计行数</h3><blockquote><p>注意，数据条数依旧是2</p></blockquote><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="keyword">count</span>(*) <span class="keyword">from</span> <span class="keyword">test</span>;</span><br><span class="line">+<span class="comment">------+</span></span><br><span class="line">| _c0  |</span><br><span class="line">+<span class="comment">------+</span></span><br><span class="line">| 2    |</span><br><span class="line">+<span class="comment">------+</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">select</span> <span class="keyword">count</span>(<span class="keyword">id</span>) <span class="keyword">from</span> <span class="keyword">test</span>;</span><br><span class="line">+<span class="comment">------+</span></span><br><span class="line">| _c0  |</span><br><span class="line">+<span class="comment">------+</span></span><br><span class="line">| 2    |</span><br><span class="line">+<span class="comment">------+</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">describe</span> formatted <span class="keyword">test</span>;</span><br></pre></td></tr></table></figure><p><img src="/IT/it-bigdata-hive-simple-query/image-20220508085646467.png" alt="image-20220508085646467"></p><h3 id="hive-compute-query-using-stats参数"><a href="#hive-compute-query-using-stats参数" class="headerlink" title="hive.compute.query.using.stats参数"></a>hive.compute.query.using.stats参数</h3><blockquote><p>set hive.compute.query.using.stats=true;  – 默认值，使用统计信息</p><p>这里需要将其设置为false，就会通过计算引擎重新计算</p><p>不过metastore 里的统计信息依旧没有更新</p></blockquote><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span> hive.compute.query.using.stats=<span class="literal">false</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">select</span> <span class="keyword">count</span>(*) <span class="keyword">from</span> <span class="keyword">test</span>;</span><br><span class="line">+<span class="comment">------+</span></span><br><span class="line">| _c0  |</span><br><span class="line">+<span class="comment">------+</span></span><br><span class="line">| 3    |</span><br><span class="line">+<span class="comment">------+</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">select</span> <span class="keyword">count</span>(<span class="keyword">id</span>) <span class="keyword">from</span> <span class="keyword">test</span>;</span><br><span class="line">+<span class="comment">------+</span></span><br><span class="line">| _c0  |</span><br><span class="line">+<span class="comment">------+</span></span><br><span class="line">| 3    |</span><br><span class="line">+<span class="comment">------+</span></span><br></pre></td></tr></table></figure><h3 id="停止收集统计信息"><a href="#停止收集统计信息" class="headerlink" title="停止收集统计信息"></a>停止收集统计信息</h3><p>在大数据量时，在写完数据，做收集统计信息这个过程有点耗时，所以有些场景需要将收集统计信息停止掉，后面重新收集统计信息</p><blockquote><p>set hive.stats.autogather=false;<br>set hive.stats.column.autogather=false;</p></blockquote><h3 id="重新收集统计信息"><a href="#重新收集统计信息" class="headerlink" title="重新收集统计信息"></a>重新收集统计信息</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">ANALYZE</span> <span class="keyword">TABLE</span> [db_name.]tablename [<span class="keyword">PARTITION</span>(partcol1[=val1], partcol2[=val2], ...)]  <span class="comment">-- (<span class="doctag">Note:</span> Fully support qualified table name since Hive 1.2.0, see HIVE-10007.)</span></span><br><span class="line">  <span class="keyword">COMPUTE</span> <span class="keyword">STATISTICS</span> </span><br><span class="line">  [<span class="keyword">FOR</span> <span class="keyword">COLUMNS</span>]          <span class="comment">-- (<span class="doctag">Note:</span> Hive 0.10.0 and later.)</span></span><br><span class="line">  [<span class="keyword">CACHE</span> METADATA]       <span class="comment">-- (<span class="doctag">Note:</span> Hive 2.1.0 and later.)</span></span><br><span class="line">  [NOSCAN];</span><br></pre></td></tr></table></figure><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">analyze</span> <span class="keyword">table</span> <span class="keyword">test</span> <span class="keyword">compute</span> <span class="keyword">statistics</span> <span class="keyword">for</span> <span class="keyword">columns</span>;</span><br></pre></td></tr></table></figure><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="keyword">count</span>(*) <span class="keyword">from</span> <span class="keyword">test</span>;</span><br><span class="line">+<span class="comment">------+</span></span><br><span class="line">| _c0  |</span><br><span class="line">+<span class="comment">------+</span></span><br><span class="line">| 3    |</span><br><span class="line">+<span class="comment">------+</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">select</span> <span class="keyword">count</span>(<span class="keyword">id</span>) <span class="keyword">from</span> <span class="keyword">test</span>;</span><br><span class="line">+<span class="comment">------+</span></span><br><span class="line">| _c0  |</span><br><span class="line">+<span class="comment">------+</span></span><br><span class="line">| 3    |</span><br><span class="line">+<span class="comment">------+</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">describe</span> formatted <span class="keyword">test</span>;</span><br></pre></td></tr></table></figure><blockquote><p>注意，此时numFiles &amp; numRows等信息都依旧修正了。</p></blockquote><p><img src="/IT/it-bigdata-hive-simple-query/image-20220508091532354.png" alt="image-20220508091532354"></p><h3 id="Hive-Metastore-表"><a href="#Hive-Metastore-表" class="headerlink" title="Hive Metastore 表"></a>Hive Metastore 表</h3><p>统计信息存储在 <strong>TABLE_PARAMS</strong></p><p>例如：</p><p><img src="/IT/it-bigdata-hive-simple-query/image-20220508110523658.png" alt="image-20220508110523658"></p><h2 id="监控"><a href="#监控" class="headerlink" title="监控"></a>监控</h2><p>hive 默认在10002端口上开启了JMX JVM相关的监控。</p><h3 id="hive-metastore"><a href="#hive-metastore" class="headerlink" title="hive metastore"></a>hive metastore</h3><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.server2.metrics.enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">description</span>&gt;</span>Enable metrics on the HiveServer2.<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure><h3 id="hive-server2"><a href="#hive-server2" class="headerlink" title="hive server2"></a>hive server2</h3><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.metastore.metrics.enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">description</span>&gt;</span>Enable metrics on the metastore.<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure><p>以上两个设置，在重启服务之后，就可以通过jmx访问到相关的监控指标了。</p><h3 id="prometheus"><a href="#prometheus" class="headerlink" title="prometheus"></a>prometheus</h3><h4 id="jmx-exporter"><a href="#jmx-exporter" class="headerlink" title="jmx_exporter"></a>jmx_exporter</h4><ul><li><a href="https://github.com/prometheus/jmx_exporter?msclkid=ed1735b3ce9d11ec9d58a39101eb14ab" target="_blank" rel="noopener">https://github.com/prometheus/jmx_exporter?msclkid=ed1735b3ce9d11ec9d58a39101eb14ab</a></li><li><a href="https://repo1.maven.org/maven2/io/prometheus/jmx/jmx_prometheus_javaagent/0.16.1/jmx_prometheus_javaagent-0.16.1.jar" target="_blank" rel="noopener">https://repo1.maven.org/maven2/io/prometheus/jmx/jmx_prometheus_javaagent/0.16.1/jmx_prometheus_javaagent-0.16.1.jar</a></li></ul><h4 id="监控服务配置文件"><a href="#监控服务配置文件" class="headerlink" title="监控服务配置文件"></a>监控服务配置文件</h4><ul><li>hive_server2.yml</li></ul><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">startDelaySeconds:</span> <span class="number">0</span></span><br><span class="line"><span class="attr">ssl:</span> <span class="literal">false</span></span><br><span class="line"><span class="attr">lowercaseOutputName:</span> <span class="literal">false</span></span><br><span class="line"><span class="attr">lowercaseOutputLabelNames:</span> <span class="literal">false</span></span><br></pre></td></tr></table></figure><ul><li><p>hive_metastore.yml</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">startDelaySeconds:</span> <span class="number">0</span></span><br><span class="line"><span class="attr">ssl:</span> <span class="literal">false</span></span><br><span class="line"><span class="attr">lowercaseOutputName:</span> <span class="literal">false</span></span><br><span class="line"><span class="attr">lowercaseOutputLabelNames:</span> <span class="literal">false</span></span><br></pre></td></tr></table></figure></li></ul><p>例如我这里存放路径如下：</p> <img src="/IT/it-bigdata-hive-simple-query/image-20220508154107035.png" alt="image-20220508154107035" style="zoom: 50%;"><h4 id="hive-env-sh"><a href="#hive-env-sh" class="headerlink" title="hive-env.sh"></a>hive-env.sh</h4><ul><li><p>创建</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> <span class="variable">$HIVE_HOME</span>/conf</span><br><span class="line">cp hive-env.sh.template hive-env.sh</span><br></pre></td></tr></table></figure></li><li><p>配置</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> [ <span class="string">"<span class="variable">$SERVICE</span>"</span> = <span class="string">"hiveserver2"</span> ] ; <span class="keyword">then</span></span><br><span class="line">HADOOP_CLIENT_OPTS=<span class="string">"<span class="variable">$HADOOP_CLIENT_OPTS</span> -javaagent:/Users/arthur/opt/monitor/prometheus/jmx_prometheus_javaagent-0.16.1.jar=9094:/Users/arthur/opt/monitor/prometheus/hive_server2.yml"</span></span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> [ <span class="string">"<span class="variable">$SERVICE</span>"</span> = <span class="string">"metastore"</span> ] ; <span class="keyword">then</span></span><br><span class="line">HADOOP_CLIENT_OPTS=<span class="string">"<span class="variable">$HADOOP_CLIENT_OPTS</span> -javaagent:/Users/arthur/opt/monitor/prometheus/jmx_prometheus_javaagent-0.16.1.jar=9093:/Users/arthur/opt/monitor/prometheus/hive_metastore.yml"</span></span><br><span class="line"><span class="keyword">fi</span></span><br></pre></td></tr></table></figure></li><li><p>整个文件内容如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Licensed to the Apache Software Foundation (ASF) under one</span></span><br><span class="line"><span class="comment"># or more contributor license agreements.  See the NOTICE file</span></span><br><span class="line"><span class="comment"># distributed with this work for additional information</span></span><br><span class="line"><span class="comment"># regarding copyright ownership.  The ASF licenses this file</span></span><br><span class="line"><span class="comment"># to you under the Apache License, Version 2.0 (the</span></span><br><span class="line"><span class="comment"># "License"); you may not use this file except in compliance</span></span><br><span class="line"><span class="comment"># with the License.  You may obtain a copy of the License at</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">#     http://www.apache.org/licenses/LICENSE-2.0</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># Unless required by applicable law or agreed to in writing, software</span></span><br><span class="line"><span class="comment"># distributed under the License is distributed on an "AS IS" BASIS,</span></span><br><span class="line"><span class="comment"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></span><br><span class="line"><span class="comment"># See the License for the specific language governing permissions and</span></span><br><span class="line"><span class="comment"># limitations under the License.</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Set Hive and Hadoop environment variables here. These variables can be used</span></span><br><span class="line"><span class="comment"># to control the execution of Hive. It should be used by admins to configure</span></span><br><span class="line"><span class="comment"># the Hive installation (so that users do not have to set environment variables</span></span><br><span class="line"><span class="comment"># or set command line parameters to get correct behavior).</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># The hive service being invoked (CLI etc.) is available via the environment</span></span><br><span class="line"><span class="comment"># variable SERVICE</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Hive Client memory usage can be an issue if a large number of clients</span></span><br><span class="line"><span class="comment"># are running at the same time. The flags below have been useful in </span></span><br><span class="line"><span class="comment"># reducing memory usage:</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># if [ "$SERVICE" = "cli" ]; then</span></span><br><span class="line"><span class="comment">#   if [ -z "$DEBUG" ]; then</span></span><br><span class="line"><span class="comment">#     export HADOOP_OPTS="$HADOOP_OPTS -XX:NewRatio=12 -Xms10m -XX:MaxHeapFreeRatio=40 -XX:MinHeapFreeRatio=15 -XX:+UseParNewGC -XX:-UseGCOverheadLimit"</span></span><br><span class="line"><span class="comment">#   else</span></span><br><span class="line"><span class="comment">#     export HADOOP_OPTS="$HADOOP_OPTS -XX:NewRatio=12 -Xms10m -XX:MaxHeapFreeRatio=40 -XX:MinHeapFreeRatio=15 -XX:-UseGCOverheadLimit"</span></span><br><span class="line"><span class="comment">#   fi</span></span><br><span class="line"><span class="comment"># fi</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> [ <span class="string">"<span class="variable">$SERVICE</span>"</span> = <span class="string">"hiveserver2"</span> ] ; <span class="keyword">then</span></span><br><span class="line">        HADOOP_CLIENT_OPTS=<span class="string">"<span class="variable">$HADOOP_CLIENT_OPTS</span> -javaagent:/Users/arthur/opt/monitor/prometheus/jmx_prometheus_javaagent-0.16.1.jar=9094:/Users/arthur/opt/monitor/prometheus/hive_server2.yml"</span></span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> [ <span class="string">"<span class="variable">$SERVICE</span>"</span> = <span class="string">"metastore"</span> ] ; <span class="keyword">then</span></span><br><span class="line">        HADOOP_CLIENT_OPTS=<span class="string">"<span class="variable">$HADOOP_CLIENT_OPTS</span> -javaagent:/Users/arthur/opt/monitor/prometheus/jmx_prometheus_javaagent-0.16.1.jar=9093:/Users/arthur/opt/monitor/prometheus/hive_metastore.yml"</span></span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># The heap size of the jvm stared by hive shell script can be controlled via:</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># export HADOOP_HEAPSIZE=1024</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># Larger heap size may be required when running queries over large number of files or partitions. </span></span><br><span class="line"><span class="comment"># By default hive shell scripts use a heap size of 256 (MB).  Larger heap size would also be </span></span><br><span class="line"><span class="comment"># appropriate for hive server.</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Set HADOOP_HOME to point to a specific hadoop install directory</span></span><br><span class="line"><span class="comment"># HADOOP_HOME=$&#123;bin&#125;/../../hadoop</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Hive Configuration Directory can be controlled by:</span></span><br><span class="line"><span class="comment"># export HIVE_CONF_DIR=</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Folder containing extra libraries required for hive compilation/execution can be controlled by:</span></span><br><span class="line"><span class="comment"># export HIVE_AUX_JARS_PATH=</span></span><br></pre></td></tr></table></figure><h4 id="prometheus-yml"><a href="#prometheus-yml" class="headerlink" title="prometheus.yml"></a>prometheus.yml</h4><p>我的prometheus使用的是brew安装的，所以此文件在：/usr/local/etc/prometheus.yml</p><p>需要将开始配置的hiveserver2 和 metastore配置进来，即配置文件中的 hs2 和 hms。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">global:</span></span><br><span class="line">  <span class="attr">scrape_interval:</span> <span class="string">15s</span></span><br><span class="line"></span><br><span class="line"><span class="attr">scrape_configs:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">"prometheus"</span></span><br><span class="line">    <span class="attr">static_configs:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">targets:</span> <span class="string">["localhost:9090"]</span></span><br><span class="line"></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">"nifi"</span></span><br><span class="line">    <span class="attr">static_configs:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">targets:</span> <span class="string">["localhost:9092"]</span></span><br><span class="line"></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">"hs2"</span></span><br><span class="line">    <span class="attr">static_configs:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">targets:</span> <span class="string">["localhost:9094"]</span></span><br><span class="line"></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">"hms"</span></span><br><span class="line">    <span class="attr">static_configs:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">targets:</span> <span class="string">["localhost:9093"]</span></span><br><span class="line"></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">"nodes"</span></span><br><span class="line">    <span class="attr">static_configs:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">targets:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">localhost:9100</span></span><br></pre></td></tr></table></figure></li><li><p>重启</p><ul><li>hive metastore</li><li>hive server2</li><li>prometheus</li></ul></li><li><p>效果</p><ul><li><p><a href="http://localhost:9093/metrics" target="_blank" rel="noopener">http://localhost:9093/metrics</a></p></li><li><p><a href="http://localhost:9094/metrics" target="_blank" rel="noopener">http://localhost:9094/metrics</a></p></li><li><p><a href="http://localhost:9090" target="_blank" rel="noopener">http://localhost:9090</a></p><img src="/IT/it-bigdata-hive-simple-query/image-20220508155048646.png" alt="image-20220508155048646" style="zoom:50%;"></li><li><p>grafana<br>做了一个demo</p><p><img src="/IT/it-bigdata-hive-simple-query/image-20220508155247721.png" alt="image-20220508155247721"></p></li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> IT </category>
          
      </categories>
      
      
        <tags>
            
            <tag> bigdata </tag>
            
            <tag> hive </tag>
            
            <tag> query </tag>
            
            <tag> dml </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>hive3 安装</title>
      <link href="/IT/it-bigdata-hive-installation/"/>
      <url>/IT/it-bigdata-hive-installation/</url>
      
        <content type="html"><![CDATA[<blockquote><p>hive3安装过程和一些安装问题处理</p></blockquote><a id="more"></a><h2 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h2><ul><li>MacOS Monterey</li><li>Oracle JDK 1.8.0_181</li><li>Hadoop-3.3.1</li><li>Hive 3.1.3</li><li>MySQL 8.0.28 </li></ul><h2 id="官网"><a href="#官网" class="headerlink" title="官网"></a>官网</h2><p><a href="https://cwiki.apache.org/confluence/display/Hive//LanguageManual" target="_blank" rel="noopener">LanguageManual - Apache Hive - Apache Software Foundation</a></p><h2 id="下载"><a href="#下载" class="headerlink" title="下载"></a>下载</h2><p><a href="https://dlcdn.apache.org/hive/hive-3.1.3/apache-hive-3.1.3-bin.tar.gz" target="_blank" rel="noopener">https://dlcdn.apache.org/hive/hive-3.1.3/apache-hive-3.1.3-bin.tar.gz</a></p><h2 id="安装-amp-配置"><a href="#安装-amp-配置" class="headerlink" title="安装 &amp; 配置"></a>安装 &amp; 配置</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf apache-hive-3.1.3-bin.tar.gz</span><br><span class="line"></span><br><span class="line"><span class="comment"># 我做了一个软链接</span></span><br><span class="line">ln -s apache-hive-3.1.3-bin hive3</span><br></pre></td></tr></table></figure><h3 id="创建MySQL账户-amp-DB"><a href="#创建MySQL账户-amp-DB" class="headerlink" title="创建MySQL账户 &amp; DB"></a>创建MySQL账户 &amp; DB</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">DATABASE</span> <span class="string">`hive313`</span> <span class="comment">/*!40100 DEFAULT CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci */</span> <span class="comment">/*!80016 DEFAULT ENCRYPTION='N' */</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">create</span> <span class="keyword">user</span> hive <span class="keyword">identified</span> <span class="keyword">with</span> mysql_native_password <span class="keyword">by</span> <span class="string">'Awesome@123'</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">grant</span> <span class="keyword">all</span> <span class="keyword">privileges</span> <span class="keyword">on</span> hive313.* <span class="keyword">to</span> hive;</span><br></pre></td></tr></table></figure><h3 id="hive-site-xml"><a href="#hive-site-xml" class="headerlink" title="hive-site.xml"></a>hive-site.xml</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> hive3/conf</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建hive的配置文件</span></span><br><span class="line">cp hive-default.xml.template hive-site.xml</span><br></pre></td></tr></table></figure><h4 id="db"><a href="#db" class="headerlink" title="db"></a>db</h4><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.metastore.db.type<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>mysql<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">description</span>&gt;</span></span><br><span class="line">    Expects one of [derby, oracle, mysql, mssql, postgres].</span><br><span class="line">    Type of database used by the metastore. Information schema <span class="symbol">&amp;amp;</span> JDBCStorageHandler depend on it.</span><br><span class="line">  <span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionURL<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>jdbc:mysql://localhost:3306/hive313?useSSL=false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">description</span>&gt;</span></span><br><span class="line">    JDBC connect string for a JDBC metastore.</span><br><span class="line">    To use SSL to encrypt/authenticate the connection, provide database-specific SSL flag in the connection URL.</span><br><span class="line">    For example, jdbc:postgresql://myhost/db?ssl=true for postgres database.</span><br><span class="line">  <span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionUserName<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>hive<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">description</span>&gt;</span>Username to use against metastore database<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionPassword<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>Awesome@123<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">description</span>&gt;</span>password to use against metastore database<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure><h4 id="hive-metastore"><a href="#hive-metastore" class="headerlink" title="hive metastore"></a>hive metastore</h4><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.metastore.uris<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>thrift://localhost:9083<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">description</span>&gt;</span>Thrift URI for the remote metastore. Used by metastore client to connect to remote metastore.<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure><h4 id="hive-server2"><a href="#hive-server2" class="headerlink" title="hive server2"></a>hive server2</h4><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.server2.thrift.bind.host<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>localhost<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">description</span>&gt;</span>Bind host on which to run the HiveServer2 Thrift service.<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.server2.transport.mode<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>binary<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">description</span>&gt;</span></span><br><span class="line">    Expects one of [binary, http].</span><br><span class="line">    Transport mode of HiveServer2.</span><br><span class="line">  <span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span> </span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.server2.thrift.port<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>10000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">description</span>&gt;</span>Port number of HiveServer2 Thrift interface when hive.server2.transport.mode is 'binary'.<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure><h4 id="hdfs目录"><a href="#hdfs目录" class="headerlink" title="hdfs目录"></a>hdfs目录</h4><blockquote><p>这样设置，将内表和外表都统一在/user/hive/warehouse目录下。</p></blockquote><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.metastore.warehouse.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>/user/hive/warehouse/managed<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">description</span>&gt;</span>location of default database for the warehouse<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.metastore.warehouse.external.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>/user/hive/warehouse/external<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">description</span>&gt;</span>Default location for external tables created in the warehouse. If not set or null, then the normal warehouse location will be used as the default location.<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure><h4 id="变量"><a href="#变量" class="headerlink" title="变量"></a>变量</h4><p>默认配置文件中有大量的${system:java.io.tmpdir} 和 ${system:user.name}，在我的电脑上有点问题，所以我全部将这些变量替换成了我自己的设置</p><p>${system:java.io.tmpdir}  ==&gt; /Users/arthur/opt/apache/hive3/logs</p><p>${system:user.name} ==&gt; arthur</p><h4 id="监控设置"><a href="#监控设置" class="headerlink" title="监控设置"></a>监控设置</h4><p>如果要开启hive metastore &amp; hive server2的指标监控，请参考<a href="it-bigdata-hive-simple-query.md">hive查询和监控设置</a></p><h3 id="日志配置文件"><a href="#日志配置文件" class="headerlink" title="日志配置文件"></a>日志配置文件</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> <span class="variable">$HIVE_HOME</span>/conf</span><br><span class="line">cp hive-log4j2.properties.template hive-log4j2.properties</span><br><span class="line"><span class="comment"># 同变量部分，修改property.hive.log.dir。</span></span><br></pre></td></tr></table></figure><p>Beeline 客户端日志配置文件</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cp beeline-log4j2.properties.template beeline-log4j2.properties</span><br></pre></td></tr></table></figure><h2 id="初始化schema"><a href="#初始化schema" class="headerlink" title="初始化schema"></a>初始化schema</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/schematool -dbType mysql -initSchema</span><br></pre></td></tr></table></figure><h2 id="启动服务"><a href="#启动服务" class="headerlink" title="启动服务"></a>启动服务</h2><h3 id="metastore"><a href="#metastore" class="headerlink" title="metastore"></a>metastore</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/hive --service metastore  &amp;</span><br></pre></td></tr></table></figure><h3 id="Hive-server2"><a href="#Hive-server2" class="headerlink" title="Hive server2"></a>Hive server2</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin&#x2F;hive --service hiveserver2  &amp;</span><br></pre></td></tr></table></figure><h2 id="客户端"><a href="#客户端" class="headerlink" title="客户端"></a>客户端</h2><h3 id="beeline"><a href="#beeline" class="headerlink" title="beeline"></a>beeline</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/beeline -u jdbc:hive2://localhost:10000 -n <span class="string">"arthur"</span> -p <span class="string">""</span></span><br></pre></td></tr></table></figure><h3 id="dbeaver"><a href="#dbeaver" class="headerlink" title="dbeaver"></a>dbeaver</h3><p>我这个社区22.0.0版本的有点不太友好，特别是在insert into这种语句时，会有问题，同时sql支持有点差。</p><h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><ul><li><p>hive.txn.xlock.iow注释问题</p><blockquote><p> 删除 &amp;#8;</p><p>下面是的配置是正确的</p></blockquote><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.txn.xlock.iow<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">description</span>&gt;</span></span><br><span class="line">    Ensures commands with OVERWRITE (such as INSERT OVERWRITE) acquire Exclusive locks for transactional tables.  This ensures that inserts (w/o overwrite) running concurrently</span><br><span class="line">    are not hidden by the INSERT OVERWRITE.</span><br><span class="line">  <span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure></li></ul><ul><li><p>cannot recognize input near ‘SHOW’ ‘INDEX’ ‘ON’ in ddl statement</p><blockquote><p>在执行select语句时，hive后台日志报错，具体的错误日志如下，</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"> &gt;-- a. 后台日志报错</span><br><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> dumy;</span><br><span class="line"><span class="comment">-- b. 后台无报错</span></span><br><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> default.dumy;</span><br><span class="line"><span class="comment">-- c. 后台无报错</span></span><br><span class="line"><span class="keyword">use</span> <span class="keyword">default</span>;</span><br><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> dumy;</span><br></pre></td></tr></table></figure></blockquote><p>原因</p><blockquote><p>经过测试，导致此问题的原因有可能是没有指定default数据库。</p></blockquote></li></ul><pre><code>报错日志<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">022</span>-<span class="number">05</span>-<span class="number">07</span>T21:<span class="number">52</span>:<span class="number">18</span>,<span class="number">858</span>  WARN [HiveServer2-Handler-Pool: Thread-<span class="number">56</span>] thrift.ThriftCLIService: Error executing statement: </span><br><span class="line">org.apache.hive.service.cli.HiveSQLException: Error <span class="keyword">while</span> compiling statement: FAILED: ParseException line <span class="number">1</span>:<span class="number">5</span> cannot recognize input near <span class="string">'SHOW'</span> <span class="string">'INDEX'</span> <span class="string">'ON'</span> in ddl statement</span><br><span class="line">at org.apache.hive.service.cli.operation.Operation.toSQLException(Operation.java:<span class="number">335</span>) ~[hive-service-<span class="number">3.1</span><span class="number">.3</span>.jar:<span class="number">3.1</span><span class="number">.3</span>]</span><br><span class="line">at org.apache.hive.service.cli.operation.SQLOperation.prepare(SQLOperation.java:<span class="number">199</span>) ~[hive-service-<span class="number">3.1</span><span class="number">.3</span>.jar:<span class="number">3.1</span><span class="number">.3</span>]</span><br><span class="line">at org.apache.hive.service.cli.operation.SQLOperation.runInternal(SQLOperation.java:<span class="number">260</span>) ~[hive-service-<span class="number">3.1</span><span class="number">.3</span>.jar:<span class="number">3.1</span><span class="number">.3</span>]</span><br><span class="line">at org.apache.hive.service.cli.operation.Operation.run(Operation.java:<span class="number">247</span>) ~[hive-service-<span class="number">3.1</span><span class="number">.3</span>.jar:<span class="number">3.1</span><span class="number">.3</span>]</span><br><span class="line">at org.apache.hive.service.cli.session.HiveSessionImpl.executeStatementInternal(HiveSessionImpl.java:<span class="number">541</span>) ~[hive-service-<span class="number">3.1</span><span class="number">.3</span>.jar:<span class="number">3.1</span><span class="number">.3</span>]</span><br><span class="line">at org.apache.hive.service.cli.session.HiveSessionImpl.executeStatementAsync(HiveSessionImpl.java:<span class="number">527</span>) ~[hive-service-<span class="number">3.1</span><span class="number">.3</span>.jar:<span class="number">3.1</span><span class="number">.3</span>]</span><br><span class="line">at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:<span class="number">1.8</span><span class="number">.0_181</span>]</span><br><span class="line">at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:<span class="number">62</span>) ~[?:<span class="number">1.8</span><span class="number">.0_181</span>]</span><br><span class="line">at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:<span class="number">43</span>) ~[?:<span class="number">1.8</span><span class="number">.0_181</span>]</span><br><span class="line">at java.lang.reflect.Method.invoke(Method.java:<span class="number">498</span>) ~[?:<span class="number">1.8</span><span class="number">.0_181</span>]</span><br><span class="line">at org.apache.hive.service.cli.session.HiveSessionProxy.invoke(HiveSessionProxy.java:<span class="number">78</span>) ~[hive-service-<span class="number">3.1</span><span class="number">.3</span>.jar:<span class="number">3.1</span><span class="number">.3</span>]</span><br><span class="line">at org.apache.hive.service.cli.session.HiveSessionProxy.access$<span class="number">000</span>(HiveSessionProxy.java:<span class="number">36</span>) ~[hive-service-<span class="number">3.1</span><span class="number">.3</span>.jar:<span class="number">3.1</span><span class="number">.3</span>]</span><br><span class="line">at org.apache.hive.service.cli.session.HiveSessionProxy$<span class="number">1</span>.run(HiveSessionProxy.java:<span class="number">63</span>) ~[hive-service-<span class="number">3.1</span><span class="number">.3</span>.jar:<span class="number">3.1</span><span class="number">.3</span>]</span><br><span class="line">at java.security.AccessController.doPrivileged(Native Method) ~[?:<span class="number">1.8</span><span class="number">.0_181</span>]</span><br><span class="line">at javax.security.auth.Subject.doAs(Subject.java:<span class="number">422</span>) ~[?:<span class="number">1.8</span><span class="number">.0_181</span>]</span><br><span class="line">at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:<span class="number">1878</span>) ~[hadoop-common-<span class="number">3.3</span><span class="number">.1</span>.jar:?]</span><br><span class="line">at org.apache.hive.service.cli.session.HiveSessionProxy.invoke(HiveSessionProxy.java:<span class="number">59</span>) ~[hive-service-<span class="number">3.1</span><span class="number">.3</span>.jar:<span class="number">3.1</span><span class="number">.3</span>]</span><br><span class="line">at com.sun.proxy.$Proxy37.executeStatementAsync(Unknown Source) ~[?:?]</span><br><span class="line">at org.apache.hive.service.cli.CLIService.executeStatementAsync(CLIService.java:<span class="number">312</span>) ~[hive-service-<span class="number">3.1</span><span class="number">.3</span>.jar:<span class="number">3.1</span><span class="number">.3</span>]</span><br><span class="line">at org.apache.hive.service.cli.thrift.ThriftCLIService.ExecuteStatement(ThriftCLIService.java:<span class="number">562</span>) ~[hive-service-<span class="number">3.1</span><span class="number">.3</span>.jar:<span class="number">3.1</span><span class="number">.3</span>]</span><br><span class="line">at org.apache.hive.service.rpc.thrift.TCLIService$Processor$ExecuteStatement.getResult(TCLIService.java:<span class="number">1557</span>) ~[hive-exec-<span class="number">3.1</span><span class="number">.3</span>.jar:<span class="number">3.1</span><span class="number">.3</span>]</span><br><span class="line">at org.apache.hive.service.rpc.thrift.TCLIService$Processor$ExecuteStatement.getResult(TCLIService.java:<span class="number">1542</span>) ~[hive-exec-<span class="number">3.1</span><span class="number">.3</span>.jar:<span class="number">3.1</span><span class="number">.3</span>]</span><br><span class="line">at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:<span class="number">39</span>) ~[hive-exec-<span class="number">3.1</span><span class="number">.3</span>.jar:<span class="number">3.1</span><span class="number">.3</span>]</span><br><span class="line">at org.apache.thrift.TBaseProcessor.process(TBaseProcessor.java:<span class="number">39</span>) ~[hive-exec-<span class="number">3.1</span><span class="number">.3</span>.jar:<span class="number">3.1</span><span class="number">.3</span>]</span><br><span class="line">at org.apache.hive.service.auth.TSetIpAddressProcessor.process(TSetIpAddressProcessor.java:<span class="number">56</span>) ~[hive-service-<span class="number">3.1</span><span class="number">.3</span>.jar:<span class="number">3.1</span><span class="number">.3</span>]</span><br><span class="line">at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:<span class="number">286</span>) ~[hive-exec-<span class="number">3.1</span><span class="number">.3</span>.jar:<span class="number">3.1</span><span class="number">.3</span>]</span><br><span class="line">at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:<span class="number">1149</span>) ~[?:<span class="number">1.8</span><span class="number">.0_181</span>]</span><br><span class="line">at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:<span class="number">624</span>) ~[?:<span class="number">1.8</span><span class="number">.0_181</span>]</span><br><span class="line">at java.lang.Thread.run(Thread.java:<span class="number">748</span>) [?:<span class="number">1.8</span><span class="number">.0_181</span>]</span><br><span class="line">Caused by: org.apache.hadoop.hive.ql.parse.ParseException: line <span class="number">1</span>:<span class="number">5</span> cannot recognize input near <span class="string">'SHOW'</span> <span class="string">'INDEX'</span> <span class="string">'ON'</span> in ddl statement</span><br><span class="line">at org.apache.hadoop.hive.ql.parse.ParseDriver.parse(ParseDriver.java:<span class="number">223</span>) ~[hive-exec-<span class="number">3.1</span><span class="number">.3</span>.jar:<span class="number">3.1</span><span class="number">.3</span>]</span><br><span class="line">at org.apache.hadoop.hive.ql.parse.ParseUtils.parse(ParseUtils.java:<span class="number">74</span>) ~[hive-exec-<span class="number">3.1</span><span class="number">.3</span>.jar:<span class="number">3.1</span><span class="number">.3</span>]</span><br><span class="line">at org.apache.hadoop.hive.ql.parse.ParseUtils.parse(ParseUtils.java:<span class="number">67</span>) ~[hive-exec-<span class="number">3.1</span><span class="number">.3</span>.jar:<span class="number">3.1</span><span class="number">.3</span>]</span><br><span class="line">at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:<span class="number">616</span>) ~[hive-exec-<span class="number">3.1</span><span class="number">.3</span>.jar:<span class="number">3.1</span><span class="number">.3</span>]</span><br><span class="line">at org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:<span class="number">1826</span>) ~[hive-exec-<span class="number">3.1</span><span class="number">.3</span>.jar:<span class="number">3.1</span><span class="number">.3</span>]</span><br><span class="line">at org.apache.hadoop.hive.ql.Driver.compileAndRespond(Driver.java:<span class="number">1773</span>) ~[hive-exec-<span class="number">3.1</span><span class="number">.3</span>.jar:<span class="number">3.1</span><span class="number">.3</span>]</span><br><span class="line">at org.apache.hadoop.hive.ql.Driver.compileAndRespond(Driver.java:<span class="number">1768</span>) ~[hive-exec-<span class="number">3.1</span><span class="number">.3</span>.jar:<span class="number">3.1</span><span class="number">.3</span>]</span><br><span class="line">at org.apache.hadoop.hive.ql.reexec.ReExecDriver.compileAndRespond(ReExecDriver.java:<span class="number">126</span>) ~[hive-exec-<span class="number">3.1</span><span class="number">.3</span>.jar:<span class="number">3.1</span><span class="number">.3</span>]</span><br><span class="line">at org.apache.hive.service.cli.operation.SQLOperation.prepare(SQLOperation.java:<span class="number">197</span>) ~[hive-service-<span class="number">3.1</span><span class="number">.3</span>.jar:<span class="number">3.1</span><span class="number">.3</span>]</span><br><span class="line">... <span class="number">27</span> more</span><br></pre></td></tr></table></figure></code></pre><ul><li><p>Count(*) 不报错 ，而count(x) 时报错</p><blockquote><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- a. 不报错</span></span><br><span class="line"><span class="keyword">select</span> <span class="keyword">count</span>(*) <span class="keyword">from</span> dumy;</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">+------+</span></span><br><span class="line"><span class="comment">| _c0  |</span></span><br><span class="line"><span class="comment">+------+</span></span><br><span class="line"><span class="comment">| 1    |</span></span><br><span class="line"><span class="comment">+------+</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- b. 报错, 报错信息如下</span></span><br><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> dumy;</span><br></pre></td></tr></table></figure></blockquote><p>报错日志</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">Error: Error <span class="keyword">while</span> processing statement: FAILED: Execution Error, <span class="keyword">return</span> code <span class="number">1</span> from org.apache.hadoop.hive.ql.exec.mr.MapRedTask. Permission denied: user=anonymous, access=EXECUTE, inode=<span class="string">"/tmp/hadoop-yarn"</span>:arthur:supergroup:drwx------</span><br><span class="line">at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:<span class="number">504</span>)</span><br><span class="line">at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkTraverse(FSPermissionChecker.java:<span class="number">420</span>)</span><br><span class="line">at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:<span class="number">323</span>)</span><br><span class="line">at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermissionWithContext(FSPermissionChecker.java:<span class="number">360</span>)</span><br><span class="line">at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:<span class="number">240</span>)</span><br><span class="line">at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkTraverse(FSPermissionChecker.java:<span class="number">711</span>)</span><br><span class="line">at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkTraverse(FSDirectory.java:<span class="number">1888</span>)</span><br><span class="line">at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkTraverse(FSDirectory.java:<span class="number">1906</span>)</span><br><span class="line">at org.apache.hadoop.hdfs.server.namenode.FSDirectory.resolvePath(FSDirectory.java:<span class="number">727</span>)</span><br><span class="line">at org.apache.hadoop.hdfs.server.namenode.FSDirStatAndListingOp.getFileInfo(FSDirStatAndListingOp.java:<span class="number">112</span>)</span><br><span class="line">at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:<span class="number">3355</span>)</span><br><span class="line">at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:<span class="number">1219</span>)</span><br><span class="line">at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:<span class="number">1042</span>)</span><br><span class="line">at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$<span class="number">2</span>.callBlockingMethod(ClientNamenodeProtocolProtos.java)</span><br><span class="line">at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:<span class="number">600</span>)</span><br><span class="line">at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:<span class="number">568</span>)</span><br><span class="line">at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:<span class="number">552</span>)</span><br><span class="line">at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:<span class="number">1093</span>)</span><br><span class="line">at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:<span class="number">1035</span>)</span><br><span class="line">at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:<span class="number">963</span>)</span><br><span class="line">at java.security.AccessController.doPrivileged(Native Method)</span><br><span class="line">at javax.security.auth.Subject.doAs(Subject.java:<span class="number">422</span>)</span><br><span class="line">at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:<span class="number">1878</span>)</span><br><span class="line">at org.apache.hadoop.ipc.Server$Handler.run(Server.java:<span class="number">2966</span>) (state=<span class="number">08</span>S01,code=<span class="number">1</span>)</span><br></pre></td></tr></table></figure><p>原因</p><blockquote><p>不过为啥会一样的原因是因为hive在执行一些统计信息时，是不会真的去执行，而是直接从元数据库里返回。所以count(*)就是直接返回。而有些操作则会调用执行引擎执行任务。</p></blockquote><p>解决报错问题</p><ol><li><p>tmp及其子目录赋予权限。 这种不建议</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfs -chmod -R 777 /tmp</span><br></pre></td></tr></table></figure></li><li><p>beeline 登录参数配置好用户名</p><p>   默认登录的用户为</p>   <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- bin/beeline -u jdbc:hive2://localhost:10000</span></span><br><span class="line">0: jdbc:hive2://localhost:10000&gt; select current_user();</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">+------------+</span></span><br><span class="line"><span class="comment">|    _c0     |</span></span><br><span class="line"><span class="comment">+------------+</span></span><br><span class="line"><span class="comment">| anonymous  |</span></span><br><span class="line"><span class="comment">+------------+</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure><p>   加上用户信息</p>   <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- bin/beeline -u jdbc:hive2://localhost:10000 -n arthur -p ""</span></span><br><span class="line">0: jdbc:hive2://localhost:10000&gt; select current_user();</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">+------------+</span></span><br><span class="line"><span class="comment">|    _c0     |</span></span><br><span class="line"><span class="comment">+------------+</span></span><br><span class="line"><span class="comment">| arthur     |</span></span><br><span class="line"><span class="comment">+------------+</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure></li></ol></li></ul>]]></content>
      
      
      <categories>
          
          <category> IT </category>
          
      </categories>
      
      
        <tags>
            
            <tag> bigdata </tag>
            
            <tag> hive </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>初探trino</title>
      <link href="/uncategorized/it-bigdata-distributed-sql-query-engine-trino/"/>
      <url>/uncategorized/it-bigdata-distributed-sql-query-engine-trino/</url>
      
        <content type="html"><![CDATA[<blockquote><p>大家对trino没有怎么听说过，我也是在做flink时，有人flink贡献者提到 OLAP 场景下 Flink 与 Trino 确实还存在差距，所以尝试去了解了一下，其与presto SQL是一样的，当然，trino与presto SQL的故事不仅仅如此，请参考<a href="https://trino.io/blog/2020/12/27/announcing-trino.html" target="_blank" rel="noopener">Trino | We’re rebranding PrestoSQL as Trino</a>。</p></blockquote><a id="more"></a><h2 id="官网"><a href="#官网" class="headerlink" title="官网"></a>官网</h2><ul><li><a href="https://trino.io/" target="_blank" rel="noopener">trino.io</a></li><li><a href="https://github.com/trinodb/trino" target="_blank" rel="noopener">github</a></li></ul><h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><h3 id="下载-amp-安装"><a href="#下载-amp-安装" class="headerlink" title="下载&amp;安装"></a>下载&amp;安装</h3><p><a href="https://trino.io/download.html" target="_blank" rel="noopener">Trino | Get started with Trino</a></p><ul><li><p>Server Package</p><ol><li><p>解压</p><img src="/uncategorized/it-bigdata-distributed-sql-query-engine-trino/image-20220502153434768.png" alt="image-20220502153434768" style="zoom:50%;"></li><li><p>创建data数据目录</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mkdir data</span><br></pre></td></tr></table></figure></li><li><p>创建etc配置目录</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mkdir etc</span><br></pre></td></tr></table></figure></li></ol><p>其目录结构如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">(base) ➜  trino-server-379 tree -L 1</span><br><span class="line">.</span><br><span class="line">├── NOTICE</span><br><span class="line">├── README.txt</span><br><span class="line">├── bin</span><br><span class="line">├── data</span><br><span class="line">├── etc</span><br><span class="line">├── lib</span><br><span class="line">├── plugin</span><br><span class="line">└── var</span><br></pre></td></tr></table></figure></li><li><p>Command line client</p><p>trino-cli-379-executable.jar</p><p>将此文件下载之后，放到Server Package解压之后的bin目录，然后软链接此文件为trino</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">(base) ➜  bin ln -s trino-cli-379-executable.jar trino</span><br><span class="line">(base) ➜  bin ls -l</span><br><span class="line">total 20592</span><br><span class="line">-rwxr-xr-x  1 arthur  staff      1450  4 29 09:36 launcher</span><br><span class="line">-rw-r--r--  1 arthur  staff        65  4 29 09:36 launcher.properties</span><br><span class="line">-rwxr-xr-x  1 arthur  staff     14608  4 29 09:36 launcher.py</span><br><span class="line">drwxr-xr-x  5 arthur  staff       160  4 29 09:36 procname</span><br><span class="line">lrwxr-xr-x  1 arthur  staff        28  5  2 12:39 trino -&gt; trino-cli-379-executable.jar</span><br><span class="line">-rwxr--r--@ 1 arthur  staff  10238827  5  2 03:28 trino-cli-379-executable.jar</span><br></pre></td></tr></table></figure></li></ul><h2 id="trino配置"><a href="#trino配置" class="headerlink" title="trino配置"></a>trino配置</h2><p>示例配置，放到了gitee上<a href="https://gitee.com/lianyouli/trino-quickstart-etc" target="_blank" rel="noopener">trino-quickstart-etc: trino入门配置</a></p><p>配置文档，请参考 <a href="https://trino.io/docs/current/installation/deployment.html" target="_blank" rel="noopener">Deploying Trino — Trino 379 Documentation</a></p><h3 id="node-properties"><a href="#node-properties" class="headerlink" title="node.properties"></a>node.properties</h3><blockquote><p>environment: 你随意，dev/sit/uat/prod等都可以</p><p>id: 节点的唯一标识，同一个集群里不能重名就好</p><p>data-dir:  请配置成你自己的数据目录，请参考步骤安装中的创建的数据目录</p></blockquote><figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">node.environment</span>=<span class="string">development</span></span><br><span class="line"><span class="meta">node.id</span>=<span class="string">ffff-ffff-ffff</span></span><br><span class="line"><span class="meta">node.data-dir</span>=<span class="string">/Users/arthur/opt/Software/trino/trino-server-379/data</span></span><br></pre></td></tr></table></figure><h3 id="jvm-config"><a href="#jvm-config" class="headerlink" title="jvm.config"></a>jvm.config</h3><blockquote><p>官网示例配置，不过我将内存配置从16G –&gt; 4G。</p></blockquote><figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">-server</span></span><br><span class="line"><span class="attr">-Xmx4G</span></span><br><span class="line"><span class="meta">-XX</span>:<span class="string">-UseBiasedLocking</span></span><br><span class="line"><span class="meta">-XX</span>:<span class="string">+UseG1GC</span></span><br><span class="line"><span class="meta">-XX</span>:<span class="string">G1HeapRegionSize=32M</span></span><br><span class="line"><span class="meta">-XX</span>:<span class="string">+ExplicitGCInvokesConcurrent</span></span><br><span class="line"><span class="meta">-XX</span>:<span class="string">+ExitOnOutOfMemoryError</span></span><br><span class="line"><span class="meta">-XX</span>:<span class="string">+HeapDumpOnOutOfMemoryError</span></span><br><span class="line"><span class="meta">-XX</span>:<span class="string">-OmitStackTraceInFastThrow</span></span><br><span class="line"><span class="meta">-XX</span>:<span class="string">ReservedCodeCacheSize=512M</span></span><br><span class="line"><span class="meta">-XX</span>:<span class="string">PerMethodRecompilationCutoff=10000</span></span><br><span class="line"><span class="meta">-XX</span>:<span class="string">PerBytecodeRecompilationCutoff=10000</span></span><br><span class="line"><span class="meta">-Djdk.attach.allowAttachSelf</span>=<span class="string">true</span></span><br><span class="line"><span class="meta">-Djdk.nio.maxCachedBufferSize</span>=<span class="string">2000000</span></span><br></pre></td></tr></table></figure><h3 id="config-properties"><a href="#config-properties" class="headerlink" title="config.properties"></a>config.properties</h3><p>trino是类似MPP的架构，要运行起来需要两个角色： Coordinator 和 Worker</p><ul><li><p><strong>Coordinator</strong><br>接收客户发起的查询请求和管理查询的执行；</p><p>设置参数coordinator为true，官方建议使用专用的一台服务器来做Coordinator</p><figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">coordinator</span>=<span class="string">true</span></span><br></pre></td></tr></table></figure><p>如果想设置Coordinator节点也做为worker，可以设置下面参数node-scheduler.include-coordinator为true</p><figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">node-scheduler.include-coordinator</span>=<span class="string">true</span></span><br></pre></td></tr></table></figure></li></ul><ul><li><p><strong>Worker</strong></p><p>运行任务的节点。</p><figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">coordinator</span>=<span class="string">false</span></span><br></pre></td></tr></table></figure></li></ul><blockquote><p>单机配置需要设置coordinator=true和node-scheduler.include-coordinator=true</p><p>http.port根据实际情况设置即可</p></blockquote><figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">coordinator</span>=<span class="string">true</span></span><br><span class="line"><span class="meta">node-scheduler.include-coordinator</span>=<span class="string">true</span></span><br><span class="line"><span class="meta">http-server.http.port</span>=<span class="string">7080</span></span><br><span class="line"><span class="meta">query.max-memory</span>=<span class="string">50GB</span></span><br><span class="line"><span class="meta">query.max-memory-per-node</span>=<span class="string">1GB</span></span><br><span class="line"><span class="meta">discovery.uri</span>=<span class="string">http://localhost:7080</span></span><br></pre></td></tr></table></figure><h3 id="log-properties"><a href="#log-properties" class="headerlink" title="log.properties"></a>log.properties</h3><p>日志级别设置</p><figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">io.trino</span>=<span class="string">INFO</span></span><br></pre></td></tr></table></figure><h2 id="Catalog配置"><a href="#Catalog配置" class="headerlink" title="Catalog配置"></a>Catalog配置</h2><p>trino是通过各种connector去访问各种类型的数据源，而这些connector的配置是通过catalog去管理的。</p><p>即通过在catalog里配置数据源的连接信息，用户名，密码等信息，将各种数据源连通起来。</p><h3 id="层级"><a href="#层级" class="headerlink" title="层级"></a>层级</h3><blockquote><p>catalog &gt; schema &gt; table</p></blockquote><ul><li><p>catalog</p><p>catalog名称与catalog目录的各个properties的配置文件名称同名</p></li><li><p>schema</p><p>如果没有的话，可能是default或者可以手动配置，例如kafka。</p><p>有可能是数据库名称，例如mysql。</p></li><li><p>table</p><p>可能是table名称，例如mysql</p><p>也可能是其它的，例如kafka的topic名称。</p></li></ul><h3 id="目录结构"><a href="#目录结构" class="headerlink" title="目录结构"></a>目录结构</h3><blockquote><p> etc &gt; catalog</p></blockquote><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">(base) ➜  etc git:(master) ✗ tree -L 2</span><br><span class="line">.</span><br><span class="line">├── README.MD</span><br><span class="line">├── catalog</span><br><span class="line">│   ├── jmx.properties</span><br><span class="line">│   ├── kafka_flink_sensor_iot.properties</span><br><span class="line">│   ├── mysql_tests.properties</span><br><span class="line">│   └── tpch.properties</span><br><span class="line">├── config.properties</span><br><span class="line">├── jvm.config</span><br><span class="line">├── kafka</span><br><span class="line">│   └── lab-flink-sensor-iot.json</span><br><span class="line">├── log.properties</span><br><span class="line">└── node.properties</span><br><span class="line"></span><br><span class="line">2 directories, 10 files</span><br></pre></td></tr></table></figure><h3 id="配置示例"><a href="#配置示例" class="headerlink" title="配置示例"></a>配置示例</h3><h4 id="jmx"><a href="#jmx" class="headerlink" title="jmx"></a>jmx</h4><p><a href="https://trino.io/docs/current/connector/jmx.html" target="_blank" rel="noopener">JMX connector — Trino 379 Documentation</a></p><p><strong>jmx.properties</strong></p><figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">connector.name</span>=<span class="string">jmx</span></span><br></pre></td></tr></table></figure><h4 id="tpch"><a href="#tpch" class="headerlink" title="tpch"></a>tpch</h4><p><a href="https://trino.io/docs/current/connector/tpch.html" target="_blank" rel="noopener">TPCH connector — Trino 379 Documentation</a></p><p><strong>tpch.properties</strong></p><figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">connector.name</span>=<span class="string">jmx</span></span><br></pre></td></tr></table></figure><h4 id="mysql"><a href="#mysql" class="headerlink" title="mysql"></a>mysql</h4><p><a href="https://trino.io/docs/current/connector/mysql.html" target="_blank" rel="noopener">MySQL connector — Trino 379 Documentation</a></p><p><strong>mysql_tests.properties</strong></p><figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">connector.name</span>=<span class="string">mysql</span></span><br><span class="line"><span class="meta">connection-url</span>=<span class="string">jdbc:mysql://localhost:3306</span></span><br><span class="line"><span class="meta">connection-user</span>=<span class="string">nifi</span></span><br><span class="line"><span class="meta">connection-password</span>=<span class="string">Awesome@123</span></span><br></pre></td></tr></table></figure><h4 id="kafka"><a href="#kafka" class="headerlink" title="kafka"></a>kafka</h4><p><a href="https://trino.io/docs/current/connector/kafka.html" target="_blank" rel="noopener">Kafka connector — Trino 379 Documentation</a></p><p><strong>kafka_flink_sensor_iot.properties</strong></p><figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">connector.name</span>=<span class="string">kafka</span></span><br><span class="line"><span class="meta">kafka.table-names</span>=<span class="string">lab-flink-sensor-iot</span></span><br><span class="line"><span class="meta">kafka.nodes</span>=<span class="string">localhost:9092</span></span><br><span class="line"><span class="meta">kafka.hide-internal-columns</span>=<span class="string">false</span></span><br></pre></td></tr></table></figure><h3 id="Decoder"><a href="#Decoder" class="headerlink" title="Decoder"></a>Decoder</h3><p><strong>Decoder</strong>是将数据从原始数据格式解析成我们方便读取的格式。</p><p>为什么需要呢decoder呢，请看下图，kafka的消息是csv格式的，所以我们在查看或者查询时都不方便。</p><p><img src="/uncategorized/it-bigdata-distributed-sql-query-engine-trino/image-20220502163335198.png" alt="image-20220502163335198"></p><p>下图是配置了Decoder之后效果，可以看到，_message里的数据展平成独立字段了。</p><p><img src="/uncategorized/it-bigdata-distributed-sql-query-engine-trino/image-20220502163452543.png" alt="image-20220502163452543"></p><h4 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h4><ul><li><p>路径</p><p>以kafka配置为例，其目录结构</p><blockquote><p>etc &gt; kafka </p></blockquote></li><li><p>文件名称随意</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">(base) ➜  etc git:(master) ✗ tree -L 2</span><br><span class="line">.</span><br><span class="line">....</span><br><span class="line">├── kafka</span><br><span class="line">│   └── lab-flink-sensor-iot.json</span><br><span class="line">....</span><br></pre></td></tr></table></figure><ul><li><p>文件内容</p><blockquote><p>需要与你的数据匹配上</p><p>tableName: 表名</p><p>schemaName: schema名称，kafka默认是default</p><p>topicName: kafka的topic名称</p></blockquote><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">"tableName"</span>: <span class="string">"lab-flink-sensor-iot"</span>,</span><br><span class="line">    <span class="attr">"schemaName"</span>: <span class="string">"default"</span>,</span><br><span class="line">    <span class="attr">"topicName"</span>: <span class="string">"lab-flink-sensor-iot"</span>,</span><br><span class="line">    <span class="attr">"message"</span>: &#123;</span><br><span class="line">      <span class="attr">"dataFormat"</span>: <span class="string">"csv"</span>,</span><br><span class="line">      <span class="attr">"fields"</span>: [</span><br><span class="line">        &#123;</span><br><span class="line">          <span class="attr">"name"</span>: <span class="string">"id"</span>,</span><br><span class="line">          <span class="attr">"type"</span>: <span class="string">"VARCHAR(10)"</span>,</span><br><span class="line">          <span class="attr">"mapping"</span>: <span class="string">"0"</span></span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">          <span class="attr">"name"</span>: <span class="string">"timestamp"</span>,</span><br><span class="line">          <span class="attr">"type"</span>: <span class="string">"BIGINT"</span>,</span><br><span class="line">          <span class="attr">"mapping"</span>: <span class="string">"1"</span></span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">          <span class="attr">"name"</span>: <span class="string">"temperature"</span>,</span><br><span class="line">          <span class="attr">"type"</span>: <span class="string">"DOUBLE"</span>,</span><br><span class="line">          <span class="attr">"mapping"</span>: <span class="string">"2"</span></span><br><span class="line">        &#125;</span><br><span class="line">      ]</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure></li></ul><h3 id="Encoder"><a href="#Encoder" class="headerlink" title="Encoder"></a>Encoder</h3><p><strong>Encoder</strong>是将方便我们读取的数据序列化成方便机器存储的格式。同Decoder，配置也是共享的。</p><h2 id="trino客户端"><a href="#trino客户端" class="headerlink" title="trino客户端"></a>trino客户端</h2><h3 id="帮助"><a href="#帮助" class="headerlink" title="帮助"></a>帮助</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br></pre></td><td class="code"><pre><span class="line">(base) ➜  trino-server-379 bin/trino --<span class="built_in">help</span></span><br><span class="line">Trino <span class="built_in">command</span> line interface</span><br><span class="line"></span><br><span class="line">USAGE:</span><br><span class="line"></span><br><span class="line">trino [-h] [--debug] [--<span class="built_in">disable</span>-compression] [--external-authentication] [--ignore-errors] [--insecure]</span><br><span class="line">      [--krb5-disable-remote-service-hostname-canonicalization] [--password] [--[no-]progress]</span><br><span class="line">      [--use-system-truststore] [--version] [--access-token=&lt;token&gt;] [--catalog=&lt;catalog&gt;] [--client-info=&lt;info&gt;]</span><br><span class="line">      [--client-request-timeout=&lt;timeout&gt;] [--client-tags=&lt;tags&gt;] [--editing-mode=&lt;editing-mode&gt;] [--execute=&lt;execute&gt;]</span><br><span class="line">      [-f=&lt;file&gt;] [--http-proxy=&lt;proxy&gt;] [--keystore-password=&lt;password&gt;] [--keystore-path=&lt;path&gt;]</span><br><span class="line">      [--keystore-type=&lt;<span class="built_in">type</span>&gt;] [--krb5-config-path=&lt;path&gt;] [--krb5-credential-cache-path=&lt;path&gt;]</span><br><span class="line">      [--krb5-keytab-path=&lt;path&gt;] [--krb5-principal=&lt;principal&gt;] [--krb5-remote-service-name=&lt;name&gt;]</span><br><span class="line">      [--krb5-service-principal-pattern=&lt;pattern&gt;] [--network-logging=&lt;level&gt;] [--output-format=&lt;format&gt;]</span><br><span class="line">      [--schema=&lt;schema&gt;] [--server=&lt;server&gt;] [--session-user=&lt;user&gt;] [--socks-proxy=&lt;proxy&gt;] [--<span class="built_in">source</span>=&lt;<span class="built_in">source</span>&gt;]</span><br><span class="line">      [--timezone=&lt;timezone&gt;] [--trace-token=&lt;token&gt;] [--truststore-password=&lt;password&gt;] [--truststore-path=&lt;path&gt;]</span><br><span class="line">      [--truststore-type=&lt;<span class="built_in">type</span>&gt;] [--user=&lt;user&gt;]</span><br><span class="line">      [--external-authentication-redirect-handler=&lt;externalAuthenticationRedirectHandler&gt;]...</span><br><span class="line">      [--extra-credential=&lt;credential&gt;]... [--resource-estimate=&lt;estimate&gt;]... [--session=&lt;session&gt;]...</span><br><span class="line"></span><br><span class="line">OPTIONS:</span><br><span class="line">      --access-token=&lt;token&gt; Access token</span><br><span class="line">      --catalog=&lt;catalog&gt;    Default catalog</span><br><span class="line">      --client-info=&lt;info&gt;   Extra information about client making query</span><br><span class="line">      --client-request-timeout=&lt;timeout&gt;</span><br><span class="line">                             Client request timeout (default: 2m)</span><br><span class="line">      --client-tags=&lt;tags&gt;   Client tags</span><br><span class="line">      --debug                Enable debug information</span><br><span class="line">      --<span class="built_in">disable</span>-compression  Disable compression of query results</span><br><span class="line">      --editing-mode=&lt;editing-mode&gt;</span><br><span class="line">                             Editing mode [EMACS, VI] (default: EMACS)</span><br><span class="line">      --execute=&lt;execute&gt;    Execute specified statements and <span class="built_in">exit</span></span><br><span class="line">      --external-authentication</span><br><span class="line">                             Enable external authentication</span><br><span class="line">      --external-authentication-redirect-handler=&lt;externalAuthenticationRedirectHandler&gt;</span><br><span class="line">                             External authentication redirect handlers: DESKTOP_OPEN, SYSTEM_OPEN, PRINT, OPEN, ALL</span><br><span class="line">                               (default: ALL)</span><br><span class="line">      --extra-credential=&lt;credential&gt;</span><br><span class="line">                             Extra credentials (property can be used multiple <span class="built_in">times</span>; format is key=value)</span><br><span class="line">  -f, --file=&lt;file&gt;          Execute statements from file and <span class="built_in">exit</span></span><br><span class="line">  -h, --<span class="built_in">help</span>                 Show this <span class="built_in">help</span> message and <span class="built_in">exit</span></span><br><span class="line">      --http-proxy=&lt;proxy&gt;   HTTP proxy to use <span class="keyword">for</span> server connections</span><br><span class="line">      --ignore-errors        Continue processing <span class="keyword">in</span> batch mode when an error occurs (default is to <span class="built_in">exit</span> immediately)</span><br><span class="line">      --insecure             Skip validation of HTTP server certificates (should only be used <span class="keyword">for</span> debugging)</span><br><span class="line">      --keystore-password=&lt;password&gt;</span><br><span class="line">                             Keystore password</span><br><span class="line">      --keystore-path=&lt;path&gt; Keystore path</span><br><span class="line">      --keystore-type=&lt;<span class="built_in">type</span>&gt; Keystore <span class="built_in">type</span></span><br><span class="line">      --krb5-config-path=&lt;path&gt;</span><br><span class="line">                             Kerberos config file path (default: /etc/krb5.conf)</span><br><span class="line">      --krb5-credential-cache-path=&lt;path&gt;</span><br><span class="line">                             Kerberos credential cache path</span><br><span class="line">      --krb5-disable-remote-service-hostname-canonicalization</span><br><span class="line">                             Disable service hostname canonicalization using the DNS reverse lookup</span><br><span class="line">      --krb5-keytab-path=&lt;path&gt;</span><br><span class="line">                             Kerberos key table path (default: /etc/krb5.keytab)</span><br><span class="line">      --krb5-principal=&lt;principal&gt;</span><br><span class="line">                             Kerberos principal to be used</span><br><span class="line">      --krb5-remote-service-name=&lt;name&gt;</span><br><span class="line">                             Remote peer<span class="string">'s kerberos service name</span></span><br><span class="line"><span class="string">      --krb5-service-principal-pattern=&lt;pattern&gt;</span></span><br><span class="line"><span class="string">                             Remote kerberos service principal pattern (default: $&#123;SERVICE&#125;@$&#123;HOST&#125;)</span></span><br><span class="line"><span class="string">      --network-logging=&lt;level&gt;</span></span><br><span class="line"><span class="string">                             Network logging level [NONE, BASIC, HEADERS, BODY] (default: NONE)</span></span><br><span class="line"><span class="string">      --output-format=&lt;format&gt;</span></span><br><span class="line"><span class="string">                             Output format for batch mode [ALIGNED, VERTICAL, TSV, TSV_HEADER, CSV, CSV_HEADER,</span></span><br><span class="line"><span class="string">                               CSV_UNQUOTED, CSV_HEADER_UNQUOTED, JSON, NULL] (default: CSV)</span></span><br><span class="line"><span class="string">      --password             Prompt for password</span></span><br><span class="line"><span class="string">      --[no-]progress        Show query progress</span></span><br><span class="line"><span class="string">      --resource-estimate=&lt;estimate&gt;</span></span><br><span class="line"><span class="string">                             Resource estimate (property can be used multiple times; format is key=value)</span></span><br><span class="line"><span class="string">      --schema=&lt;schema&gt;      Default schema</span></span><br><span class="line"><span class="string">      --server=&lt;server&gt;      Trino server location (default: localhost:8080)</span></span><br><span class="line"><span class="string">      --session=&lt;session&gt;    Session property (property can be used multiple times; format is key=value; use '</span>SHOW</span><br><span class="line">                               SESSION<span class="string">' to see available properties)</span></span><br><span class="line"><span class="string">      --session-user=&lt;user&gt;  Username to impersonate</span></span><br><span class="line"><span class="string">      --socks-proxy=&lt;proxy&gt;  SOCKS proxy to use for server connections</span></span><br><span class="line"><span class="string">      --source=&lt;source&gt;      Name of source making query (default: trino-cli)</span></span><br><span class="line"><span class="string">      --timezone=&lt;timezone&gt;  Session time zone (default: Asia/Shanghai)</span></span><br><span class="line"><span class="string">      --trace-token=&lt;token&gt;  Trace token</span></span><br><span class="line"><span class="string">      --truststore-password=&lt;password&gt;</span></span><br><span class="line"><span class="string">                             Truststore password</span></span><br><span class="line"><span class="string">      --truststore-path=&lt;path&gt;</span></span><br><span class="line"><span class="string">                             Truststore path</span></span><br><span class="line"><span class="string">      --truststore-type=&lt;type&gt;</span></span><br><span class="line"><span class="string">                             Truststore type</span></span><br><span class="line"><span class="string">      --use-system-truststore</span></span><br><span class="line"><span class="string">                             Use default system (OS) truststore</span></span><br><span class="line"><span class="string">      --user=&lt;user&gt;          Username (default: arthur)</span></span><br><span class="line"><span class="string">      --version              Print version information and exit</span></span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/trino --server localhost:7080</span><br></pre></td></tr></table></figure><h3 id="查询元数据"><a href="#查询元数据" class="headerlink" title="查询元数据"></a>查询元数据</h3><ul><li><p>查询catalogs</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">trino&gt; show catalogs;</span><br><span class="line">        Catalog         </span><br><span class="line"><span class="comment">------------------------</span></span><br><span class="line"> jmx                    </span><br><span class="line"> kafka_flink_sensor_iot </span><br><span class="line"> mysql_tests            </span><br><span class="line"> system                 </span><br><span class="line"> tpch                   </span><br><span class="line">(5 rows)</span><br><span class="line"></span><br><span class="line">Query 20220502_084453_00010_g7j4t, FINISHED, 1 node</span><br><span class="line">Splits: 7 total, 7 done (100.00%)</span><br><span class="line">0.04 [0 rows, 0B] [0 rows/s, 0B/s]</span><br></pre></td></tr></table></figure></li><li><p>查询schemas</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">trino&gt; show schemas from mysql_tests;</span><br><span class="line">       Schema       </span><br><span class="line"><span class="comment">--------------------</span></span><br><span class="line"> datasets           </span><br><span class="line"> hive3              </span><br><span class="line"> hive3statsstore    </span><br><span class="line"> information_schema </span><br><span class="line"> performance_schema </span><br><span class="line"> tests              </span><br><span class="line">(6 rows)</span><br><span class="line"></span><br><span class="line">Query 20220502_084534_00011_g7j4t, FINISHED, 1 node</span><br><span class="line">Splits: 7 total, 7 done (100.00%)</span><br><span class="line">0.05 [6 rows, 99B] [122 rows/s, 1.97KB/s]</span><br><span class="line"></span><br><span class="line">trino&gt; show schemas from kafka_flink_sensor_iot;</span><br><span class="line">       Schema       </span><br><span class="line"><span class="comment">--------------------</span></span><br><span class="line"> default            </span><br><span class="line"> information_schema </span><br><span class="line">(2 rows)</span><br><span class="line"></span><br><span class="line">Query 20220502_084548_00012_g7j4t, FINISHED, 1 node</span><br><span class="line">Splits: 7 total, 7 done (100.00%)</span><br><span class="line">0.03 [2 rows, 35B] [71 rows/s, 1.22KB/s]</span><br></pre></td></tr></table></figure></li><li><p>查询tables</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">trino&gt; show tables from mysql_tests.tests;</span><br><span class="line">  Table   </span><br><span class="line"><span class="comment">----------</span></span><br><span class="line"> nifi_lab </span><br><span class="line"> sensor   </span><br><span class="line"> sensor2  </span><br><span class="line">(3 rows)</span><br><span class="line"></span><br><span class="line">Query 20220502_084652_00014_g7j4t, FINISHED, 1 node</span><br><span class="line">Splits: 7 total, 7 done (100.00%)</span><br><span class="line">0.11 [3 rows, 66B] [27 rows/s, 600B/s]</span><br><span class="line"></span><br><span class="line">trino&gt; show tables from kafka_flink_sensor_iot.default;</span><br><span class="line">        Table         </span><br><span class="line"><span class="comment">----------------------</span></span><br><span class="line"> lab-flink-sensor-iot </span><br><span class="line">(1 row)</span><br><span class="line"></span><br><span class="line">Query 20220502_084636_00013_g7j4t, FINISHED, 1 node</span><br><span class="line">Splits: 7 total, 7 done (100.00%)</span><br><span class="line">0.07 [1 rows, 37B] [15 rows/s, 569B/s]</span><br></pre></td></tr></table></figure></li><li><p>查询表结构</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">trino&gt; desc mysql_tests.tests.sensor;</span><br><span class="line">   Column    |      Type      | Extra | <span class="keyword">Comment</span> </span><br><span class="line"><span class="comment">-------------+----------------+-------+---------</span></span><br><span class="line"> <span class="keyword">id</span>          | <span class="built_in">varchar</span>(<span class="number">10</span>)    |       |         </span><br><span class="line"> ts          | <span class="built_in">bigint</span>         |       |         </span><br><span class="line"> temperature | <span class="built_in">decimal</span>(<span class="number">18</span>,<span class="number">12</span>) |       |         </span><br><span class="line">(<span class="number">3</span> <span class="keyword">rows</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">Query</span> <span class="number">20220502</span>_084733_00015_g7j4t, FINISHED, <span class="number">1</span> node</span><br><span class="line">Splits: <span class="number">7</span> total, <span class="number">7</span> done (<span class="number">100.00</span>%)</span><br><span class="line"><span class="number">0.19</span> [<span class="number">3</span> <span class="keyword">rows</span>, <span class="number">176</span>B] [<span class="number">15</span> <span class="keyword">rows</span>/s, <span class="number">907</span>B/s]</span><br><span class="line"></span><br><span class="line">trino&gt; <span class="keyword">desc</span> kafka_flink_sensor_iot.default.<span class="string">"lab-flink-sensor-iot"</span>;</span><br><span class="line">      Column       |              Type              | Extra |                   <span class="keyword">Comment</span>                   </span><br><span class="line"><span class="comment">-------------------+--------------------------------+-------+---------------------------------------------</span></span><br><span class="line"> <span class="keyword">id</span>                | <span class="built_in">varchar</span>(<span class="number">10</span>)                    |       |                                             </span><br><span class="line"> <span class="built_in">timestamp</span>         | <span class="built_in">bigint</span>                         |       |                                             </span><br><span class="line"> temperature       | <span class="keyword">double</span>                         |       |                                             </span><br><span class="line"> _partition_id     | <span class="built_in">bigint</span>                         |       | <span class="keyword">Partition</span> <span class="keyword">Id</span>                                </span><br><span class="line"> _partition_offset | <span class="built_in">bigint</span>                         |       | <span class="keyword">Offset</span> <span class="keyword">for</span> the message <span class="keyword">within</span> the <span class="keyword">partition</span> </span><br><span class="line"> _message_corrupt  | <span class="built_in">boolean</span>                        |       | Message <span class="keyword">data</span> <span class="keyword">is</span> corrupt                     </span><br><span class="line"> _message          | <span class="built_in">varchar</span>                        |       | Message <span class="built_in">text</span>                                </span><br><span class="line"> _headers          | <span class="keyword">map</span>(<span class="built_in">varchar</span>, <span class="built_in">array</span>(varbinary)) |       | Headers <span class="keyword">of</span> the message <span class="keyword">as</span> <span class="keyword">map</span>               </span><br><span class="line"> _message_length   | <span class="built_in">bigint</span>                         |       | Total <span class="built_in">number</span> <span class="keyword">of</span> message <span class="keyword">bytes</span>               </span><br><span class="line"> _key_corrupt      | <span class="built_in">boolean</span>                        |       | <span class="keyword">Key</span> <span class="keyword">data</span> <span class="keyword">is</span> corrupt                         </span><br><span class="line"> _key              | <span class="built_in">varchar</span>                        |       | <span class="keyword">Key</span> <span class="built_in">text</span>                                    </span><br><span class="line"> _key_length       | <span class="built_in">bigint</span>                         |       | Total <span class="built_in">number</span> <span class="keyword">of</span> <span class="keyword">key</span> <span class="keyword">bytes</span>                   </span><br><span class="line"> _timestamp        | <span class="built_in">timestamp</span>(<span class="number">3</span>)                   |       | Message <span class="built_in">timestamp</span>                           </span><br><span class="line">(<span class="number">13</span> <span class="keyword">rows</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">Query</span> <span class="number">20220502</span>_084818_00016_g7j4t, FINISHED, <span class="number">1</span> node</span><br><span class="line">Splits: <span class="number">7</span> total, <span class="number">7</span> done (<span class="number">100.00</span>%)</span><br><span class="line"><span class="number">0.09</span> [<span class="number">13</span> <span class="keyword">rows</span>, <span class="number">1.24</span>KB] [<span class="number">146</span> <span class="keyword">rows</span>/s, <span class="number">13.9</span>KB/s]</span><br></pre></td></tr></table></figure></li><li><p>Use schema</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">trino&gt; use kafka_flink_sensor_iot.default;</span><br><span class="line"><span class="keyword">USE</span></span><br><span class="line">trino:<span class="keyword">default</span>&gt; <span class="keyword">use</span> mysql_tests.tests;</span><br><span class="line"><span class="keyword">USE</span></span><br></pre></td></tr></table></figure></li></ul><h3 id="查询数据"><a href="#查询数据" class="headerlink" title="查询数据"></a>查询数据</h3><ol><li><p>查询mysql</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">trino:tests&gt; select * from  mysql_tests.tests.sensor limit 5;</span><br><span class="line">    id    |      ts       |   temperature    </span><br><span class="line"><span class="comment">----------+---------------+------------------</span></span><br><span class="line"> sensor_1 | 1650585135196 | 102.768561119156 </span><br><span class="line"> sensor_2 | 1650585135196 |  34.569160670600 </span><br><span class="line"> sensor_3 | 1650585135196 |  37.874465883075 </span><br><span class="line"> sensor_4 | 1650585135196 |  18.399362581982 </span><br><span class="line"> sensor_5 | 1650585135196 |  38.842860145725 </span><br><span class="line">(5 rows)</span><br><span class="line"></span><br><span class="line">Query 20220502_085154_00023_g7j4t, FINISHED, 1 node</span><br><span class="line">Splits: 5 total, 5 done (100.00%)</span><br><span class="line">0.49 [5 rows, 0B] [10 rows/s, 0B/s]</span><br></pre></td></tr></table></figure></li></ol><ol start="2"><li><p>查询kafka</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">trino:tests&gt; select * from kafka_flink_sensor_iot.default."lab-flink-sensor-iot" limit 5;</span><br><span class="line">    id    |   timestamp   |    temperature     | _partition_id | _partition_offset | _message_corrupt |                &gt;</span><br><span class="line"><span class="comment">----------+---------------+--------------------+---------------+-------------------+------------------+----------------&gt;</span></span><br><span class="line"> sensor_5 | 1650585131665 | 37.792825657543474 |             0 |                 0 | false            | sensor_5,165058&gt;</span><br><span class="line"> sensor_1 | 1650585133183 |  99.28945242318458 |             0 |                 1 | false            | sensor_1,165058&gt;</span><br><span class="line"> sensor_1 | 1650595135196 |              -15.0 |             0 |                 2 | false            | sensor_1,165059&gt;</span><br><span class="line"> sensor_3 | 1650585134190 | 36.959661044177736 |             0 |                 3 | false            | sensor_3,165058&gt;</span><br><span class="line"> sensor_1 | 1650585134693 | 100.58058605543529 |             0 |                 4 | false            | sensor_1,165058&gt;</span><br><span class="line">(5 rows)</span><br></pre></td></tr></table></figure></li></ol><ol start="3"><li><p>联合查询mysql&amp;kafka</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">trino:tests&gt; select * from mysql_tests.tests.sensor a inner join kafka_flink_sensor_iot.default."lab-flink-sensor-iot" b on a.id = b.id ;</span><br></pre></td></tr></table></figure><p><img src="/uncategorized/it-bigdata-distributed-sql-query-engine-trino/image-20220502165441735.png" alt="image-20220502165441735"></p></li></ol><h2 id="UI"><a href="#UI" class="headerlink" title="UI"></a>UI</h2><p><img src="/uncategorized/it-bigdata-distributed-sql-query-engine-trino/image-20220502165706165.png" alt="image-20220502165706165"></p><blockquote><p>使用tpch的数据可以看到统计变化，数据量小时，基本上没有变化。</p></blockquote>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>flink 1.14.4使用flink mysql cdc connector 2.2时报guava18、guava30和blink冲突问题</title>
      <link href="/IT/it-bigdata-flink-cdc-guava18-blink-conflicts/"/>
      <url>/IT/it-bigdata-flink-cdc-guava18-blink-conflicts/</url>
      
        <content type="html"><![CDATA[<blockquote><p>使用flink mysql cdc 来采集mysql bin日志文件时，发现其使用guava18与flink的flink streaming依赖guava30冲突。<a href="https://github.com/ververica/flink-cdc-connectors/issues/1010" target="_blank" rel="noopener">Compatibility problem with Flink 1.14.* · Issue #1010 · ververica/flink-cdc-connectors (github.com)</a></p></blockquote><a id="more"></a><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><ul><li>Flink 与 blink合并了，现在没有blink了。</li><li>Flink-MySQL-CDC-Connector  2.2.x官方提示支持1.14.x和1.13.x，其实是只支持1.13.x。 具体请参考： <a href="https://ververica.github.io/flink-cdc-connectors/release-2.2/content/about.html#supported-connectors" target="_blank" rel="noopener">FLINK CDC</a></li></ul><h2 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h2><ul><li>MacOS Monterey</li><li>Oracle JDK 11.0.12 (x86_64) </li><li>Scala 2.12.4</li><li>Flink 1.14.4</li><li>MySQL 8.0.28 </li></ul><h2 id="解决方法"><a href="#解决方法" class="headerlink" title="解决方法"></a>解决方法</h2><ul><li>pom.xml删除blink依赖</li><li>将代码中的guava18替换成guava30</li></ul><blockquote><p>有些地方我做了暴力处理，例如把所有测试代码都删除了，还有一些maven插件也删除了。如果有朋友处理好了，也请告诉我学习学习。</p></blockquote><p>下图是在我自己的repository里修改的地方，供参考。</p><p><img src="/IT/it-bigdata-flink-cdc-guava18-blink-conflicts/%E7%BD%91%E9%A1%B5%E6%8D%95%E8%8E%B7_1-5-2022_175624_gitee.com.jpeg" alt="网页捕获_1-5-2022_175624_gitee.com"></p><h2 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h2><h3 id="pom-xml"><a href="#pom-xml" class="headerlink" title="pom.xml"></a>pom.xml</h3><blockquote><p> 不能添加mysql-connector-java依赖，因为flink-connector-mysql-cdc中已经包含了mysql driver，否则会报错</p><p>com.mysql.cj.CharsetMapping.getJavaEncodingForMysqlCharset(Ljava/lang/String;)Ljava/lang/String</p></blockquote><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- https://mvnrepository.com/artifact/mysql/mysql-connector-java --&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- </span></span><br><span class="line"><span class="comment"> &lt;dependency&gt;</span></span><br><span class="line"><span class="comment">            &lt;groupId&gt;mysql&lt;/groupId&gt;</span></span><br><span class="line"><span class="comment">            &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;</span></span><br><span class="line"><span class="comment">            &lt;version&gt;8.0.28&lt;/version&gt;</span></span><br><span class="line"><span class="comment"> &lt;/dependency&gt;</span></span><br><span class="line"><span class="comment">--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.ververica<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-connector-mysql-cdc<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.2-SNAPSHOT<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- https://mvnrepository.com/artifact/com.ververica/flink-connector-debezium --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.ververica<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-connector-debezium<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.2-SNAPSHOT<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- https://mvnrepository.com/artifact/org.apache.flink/flink-shaded-guava --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-shaded-guava<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>30.1.1-jre-14.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure><h3 id="scala代码"><a href="#scala代码" class="headerlink" title="scala代码"></a>scala代码</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> local.sleety.flink.quickstart.sensor</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.ververica.cdc.connectors.mysql.source.<span class="type">MySqlSource</span></span><br><span class="line"><span class="keyword">import</span> com.ververica.cdc.debezium.<span class="type">StringDebeziumDeserializationSchema</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.eventtime.<span class="type">WatermarkStrategy</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.scala._</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.<span class="type">Properties</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">SensorMySQLCDCDB</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> debeziumProperties = <span class="keyword">new</span> <span class="type">Properties</span>()</span><br><span class="line">    debeziumProperties.put(<span class="string">"snapshot.locking.mode"</span>, <span class="string">"none"</span>)</span><br><span class="line">    <span class="keyword">val</span> mysqlSource = <span class="type">MySqlSource</span>.builder[<span class="type">String</span>]()</span><br><span class="line">      .debeziumProperties(debeziumProperties)</span><br><span class="line">      .hostname(<span class="string">"localhost"</span>)</span><br><span class="line">      .port(<span class="number">3306</span>)</span><br><span class="line">      .databaseList(<span class="string">"tests"</span>)</span><br><span class="line">      <span class="comment">// tableList is a mandatory option</span></span><br><span class="line">      .tableList(<span class="string">"tests.sensor"</span>, <span class="string">"tests.sensor2"</span>)</span><br><span class="line">      <span class="comment">// it doesn't support the regex</span></span><br><span class="line">      <span class="comment">//      .tableList("tests.sensor*")</span></span><br><span class="line">      .username(<span class="string">"nifi"</span>)</span><br><span class="line">      .password(<span class="string">"secret"</span>)</span><br><span class="line">      .deserializer(<span class="keyword">new</span> <span class="type">StringDebeziumDeserializationSchema</span>())</span><br><span class="line">      .build()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> env = <span class="type">StreamExecutionEnvironment</span>.getExecutionEnvironment</span><br><span class="line">    env.enableCheckpointing(<span class="number">3000</span>)</span><br><span class="line">    env.fromSource(mysqlSource,</span><br><span class="line">      <span class="type">WatermarkStrategy</span>.noWatermarks(),</span><br><span class="line">      <span class="string">"MySQL CDC Source"</span>)</span><br><span class="line">      .setParallelism(<span class="number">1</span>)</span><br><span class="line">      .print(<span class="string">"MySQLCDC DB"</span>).setParallelism(<span class="number">1</span>)</span><br><span class="line">    env.execute()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="DDL"><a href="#DDL" class="headerlink" title="DDL"></a>DDL</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">--------------------------------------------------------------------</span></span><br><span class="line"><span class="comment">--  flink lab sensor </span></span><br><span class="line"><span class="comment">--------------------------------------------------------------------</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- tests.sensor definition</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> <span class="string">`sensor`</span> (</span><br><span class="line">  <span class="string">`id`</span> <span class="built_in">varchar</span>(<span class="number">10</span>) <span class="keyword">NOT</span> <span class="literal">NULL</span>,</span><br><span class="line">  <span class="string">`ts`</span> <span class="built_in">bigint</span> <span class="keyword">NOT</span> <span class="literal">NULL</span>,</span><br><span class="line">  <span class="string">`temperature`</span> <span class="built_in">decimal</span>(<span class="number">18</span>,<span class="number">12</span>) <span class="keyword">NOT</span> <span class="literal">NULL</span>,</span><br><span class="line">  PRIMARY <span class="keyword">KEY</span> (<span class="string">`id`</span>)</span><br><span class="line">) <span class="keyword">ENGINE</span>=<span class="keyword">InnoDB</span> <span class="keyword">DEFAULT</span> <span class="keyword">CHARSET</span>=utf8mb4 <span class="keyword">COLLATE</span>=utf8mb4_0900_ai_ci;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">-- tests.sensor2 definition</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> <span class="string">`sensor2`</span> (</span><br><span class="line">  <span class="string">`id`</span> <span class="built_in">int</span> <span class="keyword">NOT</span> <span class="literal">NULL</span> AUTO_INCREMENT,</span><br><span class="line">  <span class="string">`name`</span> <span class="built_in">varchar</span>(<span class="number">10</span>) <span class="keyword">NOT</span> <span class="literal">NULL</span>,</span><br><span class="line">  <span class="string">`ts`</span> <span class="built_in">bigint</span> <span class="keyword">unsigned</span> <span class="keyword">NOT</span> <span class="literal">NULL</span>,</span><br><span class="line">  <span class="string">`temperature`</span> <span class="built_in">decimal</span>(<span class="number">21</span>,<span class="number">15</span>) <span class="keyword">NOT</span> <span class="literal">NULL</span>,</span><br><span class="line">  PRIMARY <span class="keyword">KEY</span> (<span class="string">`id`</span>)</span><br><span class="line">) <span class="keyword">ENGINE</span>=<span class="keyword">InnoDB</span> AUTO_INCREMENT=<span class="number">3</span> <span class="keyword">DEFAULT</span> <span class="keyword">CHARSET</span>=utf8mb4 <span class="keyword">COLLATE</span>=utf8mb4_0900_ai_ci;</span><br></pre></td></tr></table></figure><h3 id="输出示例"><a href="#输出示例" class="headerlink" title="输出示例"></a>输出示例</h3><h4 id="insert"><a href="#insert" class="headerlink" title="insert"></a>insert</h4><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; insert into sensor2(name, ts, temperature) values ('sensor_2', 1650585135196, 26.842860145725);</span><br><span class="line"></span><br><span class="line">Query OK, 1 row affected (0.00 sec)</span><br></pre></td></tr></table></figure><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">MySQLCDC DB&gt; SourceRecord&#123;sourcePartition=&#123;server=mysql_binlog_source&#125;, sourceOffset=&#123;transaction_id=null, ts_sec=1651401623, file=binlog.000014, pos=5872, row=1, server_id=1, event=2&#125;&#125; ConnectRecord&#123;topic='mysql_binlog_source.tests.sensor2', kafkaPartition=null, key=Struct&#123;id=1&#125;, keySchema=Schema&#123;mysql_binlog_source.tests.sensor2.Key:STRUCT&#125;, </span><br><span class="line">value=Struct&#123;</span><br><span class="line">after=Struct&#123;id=1,name=sensor_2,ts=1650585135196,temperature=26.842860145725000&#125;,</span><br><span class="line">source=Struct&#123;version=1.5.4.Final,connector=mysql,name=mysql_binlog_source,ts_ms=1651401623000,db=tests,table=sensor2,server_id=1,file=binlog.000014,pos=6014,row=0&#125;,</span><br><span class="line">op=c,</span><br><span class="line">ts_ms=1651401623109&#125;, </span><br><span class="line">valueSchema=Schema&#123;mysql_binlog_source.tests.sensor2.Envelope:STRUCT&#125;, timestamp=null, headers=ConnectHeaders(headers=)&#125;</span><br></pre></td></tr></table></figure><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; insert into sensor2(name, ts, temperature) values ('sensor_1', 1650585135196, 46.842020145725);</span><br><span class="line"></span><br><span class="line">Query OK, 1 row affected (0.00 sec)</span><br></pre></td></tr></table></figure><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">MySQLCDC DB&gt; SourceRecord&#123;sourcePartition=&#123;server=mysql_binlog_source&#125;, sourceOffset=&#123;transaction_id=null, ts_sec=1651401631, file=binlog.000014, pos=6191, row=1, server_id=1, event=2&#125;&#125; ConnectRecord&#123;topic='mysql_binlog_source.tests.sensor2', kafkaPartition=null, key=Struct&#123;id=2&#125;, keySchema=Schema&#123;mysql_binlog_source.tests.sensor2.Key:STRUCT&#125;, </span><br><span class="line">value=Struct&#123;</span><br><span class="line">after=Struct&#123;id=2,name=sensor_1,ts=1650585135196,temperature=46.842020145725000&#125;,</span><br><span class="line">source=Struct&#123;version=1.5.4.Final,connector=mysql,name=mysql_binlog_source,ts_ms=1651401631000,db=tests,table=sensor2,server_id=1,file=binlog.000014,pos=6333,row=0&#125;,</span><br><span class="line">op=c,</span><br><span class="line">ts_ms=1651401631597&#125;, </span><br><span class="line">valueSchema=Schema&#123;mysql_binlog_source.tests.sensor2.Envelope:STRUCT&#125;, timestamp=null, headers=ConnectHeaders(headers=)&#125;</span><br></pre></td></tr></table></figure><h4 id="update"><a href="#update" class="headerlink" title="update"></a>update</h4><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; update sensor2 set temperature=50.2342234232 where name = 'sensor_1';</span><br><span class="line"></span><br><span class="line">Query OK, 1 row affected (0.00 sec)</span><br><span class="line"></span><br><span class="line">Rows matched: 1 Changed: 1 Warnings: 0</span><br></pre></td></tr></table></figure><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">MySQLCDC DB&gt; SourceRecord&#123;sourcePartition=&#123;server=mysql_binlog_source&#125;, sourceOffset=&#123;transaction_id=null, ts_sec=1651401638, file=binlog.000014, pos=6510, row=1, server_id=1, event=2&#125;&#125; ConnectRecord&#123;topic='mysql_binlog_source.tests.sensor2', kafkaPartition=null, key=Struct&#123;id=2&#125;, keySchema=Schema&#123;mysql_binlog_source.tests.sensor2.Key:STRUCT&#125;, </span><br><span class="line">value=Struct&#123;</span><br><span class="line">before=Struct&#123;id=2,name=sensor_1,ts=1650585135196,temperature=46.842020145725000&#125;,</span><br><span class="line">after=Struct&#123;id=2,name=sensor_1,ts=1650585135196,temperature=50.234223423200000&#125;,</span><br><span class="line">source=Struct&#123;version=1.5.4.Final,connector=mysql,name=mysql_binlog_source,ts_ms=1651401638000,db=tests,table=sensor2,server_id=1,file=binlog.000014,pos=6661,row=0&#125;,</span><br><span class="line">op=u,</span><br><span class="line">ts_ms=1651401638156&#125;, </span><br><span class="line">valueSchema=Schema&#123;mysql_binlog_source.tests.sensor2.Envelope:STRUCT&#125;, timestamp=null, headers=ConnectHeaders(headers=)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="delete"><a href="#delete" class="headerlink" title="delete"></a>delete</h4><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; delete from sensor2 where name = 'sensor_1';</span><br><span class="line"></span><br><span class="line">Query OK, 1 row affected (0.00 sec)</span><br></pre></td></tr></table></figure><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">MySQLCDC DB&gt; SourceRecord&#123;sourcePartition=&#123;server=mysql_binlog_source&#125;, sourceOffset=&#123;transaction_id=null, ts_sec=1651401643, file=binlog.000014, pos=6871, row=1, server_id=1, event=2&#125;&#125; ConnectRecord&#123;topic='mysql_binlog_source.tests.sensor2', kafkaPartition=null, key=Struct&#123;id=2&#125;, keySchema=Schema&#123;mysql_binlog_source.tests.sensor2.Key:STRUCT&#125;, </span><br><span class="line">value=Struct&#123;</span><br><span class="line">before=Struct&#123;id=2,name=sensor_1,ts=1650585135196,temperature=50.234223423200000&#125;,</span><br><span class="line">source=Struct&#123;version=1.5.4.Final,connector=mysql,name=mysql_binlog_source,ts_ms=1651401643000,db=tests,table=sensor2,server_id=1,file=binlog.000014,pos=7013,row=0&#125;,</span><br><span class="line">op=d,</span><br><span class="line">ts_ms=1651401643147&#125;, v</span><br><span class="line">alueSchema=Schema&#123;mysql_binlog_source.tests.sensor2.Envelope:STRUCT&#125;, timestamp=null, headers=ConnectHeaders(headers=)&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> IT </category>
          
      </categories>
      
      
        <tags>
            
            <tag> streaming </tag>
            
            <tag> bigdata </tag>
            
            <tag> cdc </tag>
            
            <tag> flink </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Nifi Mysql CDC</title>
      <link href="/IT/it-bigdata-nifi-mysql-cdc/"/>
      <url>/IT/it-bigdata-nifi-mysql-cdc/</url>
      
        <content type="html"><![CDATA[<blockquote><p>Nifi 采集Mysql的binlog示例</p></blockquote><a id="more"></a><h2 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h2><ul><li><p>MySQL 8.0.28</p></li><li><p>Nifi 1.15.3</p></li></ul><h2 id="检查MySQL-binlog开启情况"><a href="#检查MySQL-binlog开启情况" class="headerlink" title="检查MySQL binlog开启情况"></a>检查MySQL binlog开启情况</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">show variables like '%log_bin%';</span><br></pre></td></tr></table></figure> <img src="/IT/it-bigdata-nifi-mysql-cdc/image-20220403104549750.png" alt="image-20220403104549750" style="zoom:50%;"><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 我这里的global transaction id 模式是关闭的</span></span><br><span class="line">show variables like '%gtid%';</span><br></pre></td></tr></table></figure> <img src="/IT/it-bigdata-nifi-mysql-cdc/image-20220403104650480.png" alt="image-20220403104650480" style="zoom:50%;"><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">show variables like 'server_id';</span><br></pre></td></tr></table></figure> <img src="/IT/it-bigdata-nifi-mysql-cdc/image-20220403105008677.png" alt="image-20220403105008677" style="zoom:50%;"><h2 id="创建MySQL用户和数据库"><a href="#创建MySQL用户和数据库" class="headerlink" title="创建MySQL用户和数据库"></a>创建MySQL用户和数据库</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">USER</span> nifi@<span class="string">'%'</span> <span class="keyword">IDENTIFIED</span> <span class="keyword">WITH</span> mysql_native_password <span class="keyword">BY</span> <span class="string">'SecretPasswd'</span>;</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">DATABASE</span> tests;</span><br><span class="line"><span class="keyword">GRANT</span> <span class="keyword">select</span>, <span class="keyword">show</span> <span class="keyword">databases</span>  <span class="keyword">ON</span> *.* <span class="keyword">to</span> nifi@<span class="string">'%'</span>;</span><br><span class="line"><span class="keyword">GRANT</span> <span class="keyword">ALL</span> <span class="keyword">PRIVILEGES</span> <span class="keyword">ON</span> tests.* <span class="keyword">to</span> nifi@<span class="string">'%'</span>;</span><br><span class="line"><span class="keyword">GRANT</span> <span class="keyword">REPLICATION</span> <span class="keyword">SLAVE</span> <span class="keyword">ON</span> *.* <span class="keyword">to</span> nifi@<span class="string">'%'</span>;</span><br><span class="line"><span class="keyword">GRANT</span> <span class="keyword">REPLICATION</span> <span class="keyword">CLIENT</span> <span class="keyword">ON</span> *.* <span class="keyword">to</span> nifi@<span class="string">'%'</span>;</span><br></pre></td></tr></table></figure><h2 id="配置DistributedMapCacheServer-amp-Client"><a href="#配置DistributedMapCacheServer-amp-Client" class="headerlink" title="配置DistributedMapCacheServer&amp;Client"></a>配置DistributedMapCacheServer&amp;Client</h2><ul><li><p>DistributedMapCacheServer</p><blockquote><p>global menu  –&gt; Controller Settings –&gt; REPORTING TASK CONTROLLER SERVICES</p></blockquote> <img src="/IT/it-bigdata-nifi-mysql-cdc/image-20220403110758271.png" alt="image-20220403110758271" style="zoom:50%;"><p><img src="/IT/it-bigdata-nifi-mysql-cdc/image-20220403111957998.png" alt="image-20220403111957998"></p><blockquote><p>这里选择最简单的DistributedMapCacheServer。</p></blockquote> <img src="/IT/it-bigdata-nifi-mysql-cdc/image-20220403112736423.png" alt="image-20220403112736423" style="zoom:30%;"></li></ul>  <img src="/IT/it-bigdata-nifi-mysql-cdc/image-20220403113013282.png" alt="image-20220403113013282" style="zoom:30%;"><ul><li><p>DistributedMapCacheClient</p><blockquote><p>可以采用这种方式创建，也可以在CaptureChangeMySQL组件里选择创建一个服务。</p></blockquote> <img src="/IT/it-bigdata-nifi-mysql-cdc/image-20220403165001672.png" alt="image-20220403165001672" style="zoom:50%;"> <img src="/IT/it-bigdata-nifi-mysql-cdc/image-20220403165038376.png" alt="image-20220403165038376" style="zoom:50%;"><img src="/IT/it-bigdata-nifi-mysql-cdc/image-20220403164622602.png" alt="image-20220403164622602" style="zoom:30%;"></li></ul><h2 id="创建和配置CaptureChangeMySQL"><a href="#创建和配置CaptureChangeMySQL" class="headerlink" title="创建和配置CaptureChangeMySQL"></a>创建和配置CaptureChangeMySQL</h2><ul><li><p>整个流 <img src="/IT/it-bigdata-nifi-mysql-cdc/image-20220403161544824.png" alt="image-20220403161544824"></p></li><li><p>CaptureChangeMySQL</p><p><img src="/IT/it-bigdata-nifi-mysql-cdc/image-20220403113226934.png" alt="image-20220403113226934" style="zoom:50%;">   <img src="/IT/it-bigdata-nifi-mysql-cdc/image-20220403113606962.png" alt="image-20220403113606962" style="zoom:50%;"><img src="/IT/it-bigdata-nifi-mysql-cdc/image-20220403113827340.png" alt="image-20220403113827340" style="zoom:50%;"></p></li><li><p>RouteOnAttribute</p><p>根据SQL类型，新建了下面的4种类型 ，以及默认的unmatched类型，上图中设置了Include Begin/Commit Events将会路由到unmatched分支。<br><img src="/IT/it-bigdata-nifi-mysql-cdc/image-20220403161727165.png" alt="image-20220403161727165"></p></li></ul><h2 id="捕获的数据"><a href="#捕获的数据" class="headerlink" title="捕获的数据"></a>捕获的数据</h2><ul><li>SQL Statements</li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">use</span> tests;</span><br><span class="line"><span class="comment">-- 建议在cmd上执行</span></span><br><span class="line"><span class="keyword">drop</span> <span class="keyword">table</span> <span class="keyword">if</span> <span class="keyword">exists</span> tests.nifi_lab;</span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> <span class="keyword">if</span> <span class="keyword">not</span> <span class="keyword">exists</span> tests.nifi_lab ( <span class="keyword">id</span> <span class="built_in">int</span>, </span><br><span class="line"><span class="keyword">name</span> <span class="built_in">varchar</span>(<span class="number">10</span>), </span><br><span class="line">createtime <span class="built_in">timestamp</span> <span class="keyword">default</span> <span class="keyword">current_timestamp</span>  , </span><br><span class="line">updatetime <span class="built_in">timestamp</span> <span class="keyword">DEFAULT</span> <span class="keyword">CURRENT_TIMESTAMP</span> <span class="keyword">ON</span> <span class="keyword">UPDATE</span>  <span class="keyword">current_timestamp</span></span><br><span class="line">  );</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 可以在数据库客户端执行，例如dbeaver。</span></span><br><span class="line"><span class="keyword">SELECT</span> <span class="keyword">id</span>, <span class="keyword">name</span>, createtime, updatetime</span><br><span class="line"><span class="keyword">FROM</span> tests.nifi_lab;</span><br><span class="line"></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> tests.nifi_lab (<span class="keyword">id</span>, <span class="keyword">name</span>) <span class="keyword">values</span> (<span class="number">1</span>, <span class="string">'Arthur'</span>);</span><br><span class="line"><span class="comment">-- name &amp; updatetime will be changed</span></span><br><span class="line"><span class="keyword">update</span> tests.nifi_lab <span class="keyword">set</span> <span class="keyword">name</span> = <span class="string">'Amy'</span> <span class="keyword">where</span> <span class="keyword">id</span> = <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">delete</span> <span class="keyword">from</span> tests.nifi_lab <span class="keyword">where</span> <span class="keyword">id</span> = <span class="number">1</span>;</span><br></pre></td></tr></table></figure><ul><li><p>Include DDL Events: true</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">"type"</span>: <span class="string">"ddl"</span>,</span><br><span class="line">    <span class="attr">"timestamp"</span>: <span class="number">1648912744000</span>,</span><br><span class="line">    <span class="attr">"binlog_filename"</span>: <span class="string">"binlog.000001"</span>,</span><br><span class="line">    <span class="attr">"binlog_position"</span>: <span class="number">1893</span>,</span><br><span class="line">    <span class="attr">"database"</span>: <span class="string">"tests"</span>,</span><br><span class="line">    <span class="attr">"table_name"</span>: <span class="literal">null</span>,</span><br><span class="line">    <span class="attr">"table_id"</span>: <span class="literal">null</span>,</span><br><span class="line">    <span class="attr">"query"</span>: <span class="string">"DROP TABLE IF EXISTS `nifi_lab` /* generated by server */"</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">"type"</span>: <span class="string">"ddl"</span>,</span><br><span class="line">    <span class="attr">"timestamp"</span>: <span class="number">1648974582000</span>,</span><br><span class="line">    <span class="attr">"binlog_filename"</span>: <span class="string">"binlog.000001"</span>,</span><br><span class="line">    <span class="attr">"binlog_position"</span>: <span class="number">6045</span>,</span><br><span class="line">    <span class="attr">"database"</span>: <span class="string">"tests"</span>,</span><br><span class="line">    <span class="attr">"table_name"</span>: <span class="literal">null</span>,</span><br><span class="line">    <span class="attr">"table_id"</span>: <span class="literal">null</span>,</span><br><span class="line">    <span class="attr">"query"</span>: <span class="string">"create table tests.nifi_lab ( id int,  name varchar(10),  createtime timestamp default CURRENT_TIMESTAMP,  updatetime timestamp DEFAULT CURRENT_TIMESTAMP ON UPDATE  CURRENT_TIMESTAMP   )"</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul><ul><li><p>Include Begin/Commit Event: true</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">"type"</span>: <span class="string">"commit"</span>,</span><br><span class="line">    <span class="attr">"timestamp"</span>: <span class="number">1648912762000</span>,</span><br><span class="line">    <span class="attr">"binlog_filename"</span>: <span class="string">"binlog.000001"</span>,</span><br><span class="line">    <span class="attr">"binlog_position"</span>: <span class="number">2782</span>,</span><br><span class="line">    <span class="attr">"database"</span>: <span class="string">"tests"</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">"type"</span>: <span class="string">"begin"</span>,</span><br><span class="line">    <span class="attr">"timestamp"</span>: <span class="number">1648973319000</span>,</span><br><span class="line">    <span class="attr">"binlog_filename"</span>: <span class="string">"binlog.000001"</span>,</span><br><span class="line">    <span class="attr">"binlog_position"</span>: <span class="number">4885</span>,</span><br><span class="line">    <span class="attr">"database"</span>: <span class="string">"tests"</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul><ul><li><p>Insert</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">"type"</span>: <span class="string">"insert"</span>,</span><br><span class="line">    <span class="attr">"timestamp"</span>: <span class="number">1648912762000</span>,</span><br><span class="line">    <span class="attr">"binlog_filename"</span>: <span class="string">"binlog.000001"</span>,</span><br><span class="line">    <span class="attr">"binlog_position"</span>: <span class="number">2727</span>,</span><br><span class="line">    <span class="attr">"database"</span>: <span class="string">"tests"</span>,</span><br><span class="line">    <span class="attr">"table_name"</span>: <span class="string">"nifi_lab"</span>,</span><br><span class="line">    <span class="attr">"table_id"</span>: <span class="number">103</span>,</span><br><span class="line">    <span class="attr">"columns"</span>:</span><br><span class="line">    [</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="attr">"id"</span>: <span class="number">1</span>,</span><br><span class="line">            <span class="attr">"name"</span>: <span class="string">"id"</span>,</span><br><span class="line">            <span class="attr">"column_type"</span>: <span class="number">4</span>,</span><br><span class="line">            <span class="attr">"value"</span>: <span class="number">1</span></span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="attr">"id"</span>: <span class="number">2</span>,</span><br><span class="line">            <span class="attr">"name"</span>: <span class="string">"name"</span>,</span><br><span class="line">            <span class="attr">"column_type"</span>: <span class="number">12</span>,</span><br><span class="line">            <span class="attr">"value"</span>: <span class="string">"Arthur"</span></span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="attr">"id"</span>: <span class="number">3</span>,</span><br><span class="line">            <span class="attr">"name"</span>: <span class="string">"createtime"</span>,</span><br><span class="line">            <span class="attr">"column_type"</span>: <span class="number">93</span>,</span><br><span class="line">            <span class="attr">"value"</span>: <span class="string">"2022-04-02 23:19:22.0"</span></span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="attr">"id"</span>: <span class="number">4</span>,</span><br><span class="line">            <span class="attr">"name"</span>: <span class="string">"updatetime"</span>,</span><br><span class="line">            <span class="attr">"column_type"</span>: <span class="number">93</span>,</span><br><span class="line">            <span class="attr">"value"</span>: <span class="string">"2022-04-02 23:19:22.0"</span></span><br><span class="line">        &#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>update</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- name &amp; updatetime will be changed</span></span><br><span class="line"><span class="keyword">update</span> tests.nifi_lab <span class="keyword">set</span> <span class="keyword">name</span> = <span class="string">'Amy'</span> <span class="keyword">where</span> <span class="keyword">id</span> = <span class="number">1</span>;</span><br></pre></td></tr></table></figure><p>没有做修改的字段的值，依旧在update里。</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">"type"</span>: <span class="string">"update"</span>,</span><br><span class="line">    <span class="attr">"timestamp"</span>: <span class="number">1648957879000</span>,</span><br><span class="line">    <span class="attr">"binlog_filename"</span>: <span class="string">"binlog.000002"</span>,</span><br><span class="line">    <span class="attr">"binlog_position"</span>: <span class="number">837</span>,</span><br><span class="line">    <span class="attr">"database"</span>: <span class="string">"tests"</span>,</span><br><span class="line">    <span class="attr">"table_name"</span>: <span class="string">"nifi_lab"</span>,</span><br><span class="line">    <span class="attr">"table_id"</span>: <span class="number">82</span>,</span><br><span class="line">    <span class="attr">"columns"</span>:</span><br><span class="line">    [</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="attr">"id"</span>: <span class="number">1</span>,</span><br><span class="line">            <span class="attr">"name"</span>: <span class="string">"id"</span>,</span><br><span class="line">            <span class="attr">"column_type"</span>: <span class="number">4</span>,</span><br><span class="line">            <span class="attr">"last_value"</span>: <span class="number">1</span>,</span><br><span class="line">            <span class="attr">"value"</span>: <span class="number">1</span></span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="attr">"id"</span>: <span class="number">2</span>,</span><br><span class="line">            <span class="attr">"name"</span>: <span class="string">"name"</span>,</span><br><span class="line">            <span class="attr">"column_type"</span>: <span class="number">12</span>,</span><br><span class="line">            <span class="attr">"last_value"</span>: <span class="string">"Arthur"</span>,</span><br><span class="line">            <span class="attr">"value"</span>: <span class="string">"Amy"</span></span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="attr">"id"</span>: <span class="number">3</span>,</span><br><span class="line">            <span class="attr">"name"</span>: <span class="string">"createtime"</span>,</span><br><span class="line">            <span class="attr">"column_type"</span>: <span class="number">93</span>,</span><br><span class="line">            <span class="attr">"last_value"</span>: <span class="string">"2022-04-02 23:19:22.0"</span>,</span><br><span class="line">            <span class="attr">"value"</span>: <span class="string">"2022-04-02 23:19:22.0"</span></span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="attr">"id"</span>: <span class="number">4</span>,</span><br><span class="line">            <span class="attr">"name"</span>: <span class="string">"updatetime"</span>,</span><br><span class="line">            <span class="attr">"column_type"</span>: <span class="number">93</span>,</span><br><span class="line">            <span class="attr">"last_value"</span>: <span class="string">"2022-04-02 23:19:22.0"</span>,</span><br><span class="line">            <span class="attr">"value"</span>: <span class="string">"2022-04-03 11:51:19.0"</span></span><br><span class="line">        &#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>delete</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">delete</span> <span class="keyword">from</span> tests.nifi_lab <span class="keyword">where</span> <span class="keyword">id</span> = <span class="number">1</span>;</span><br></pre></td></tr></table></figure><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">"type"</span>: <span class="string">"delete"</span>,</span><br><span class="line">    <span class="attr">"timestamp"</span>: <span class="number">1648973324000</span>,</span><br><span class="line">    <span class="attr">"binlog_filename"</span>: <span class="string">"binlog.000001"</span>,</span><br><span class="line">    <span class="attr">"binlog_position"</span>: <span class="number">5671</span>,</span><br><span class="line">    <span class="attr">"database"</span>: <span class="string">"tests"</span>,</span><br><span class="line">    <span class="attr">"table_name"</span>: <span class="string">"nifi_lab"</span>,</span><br><span class="line">    <span class="attr">"table_id"</span>: <span class="number">104</span>,</span><br><span class="line">    <span class="attr">"columns"</span>:</span><br><span class="line">    [</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="attr">"id"</span>: <span class="number">1</span>,</span><br><span class="line">            <span class="attr">"name"</span>: <span class="string">"id"</span>,</span><br><span class="line">            <span class="attr">"column_type"</span>: <span class="number">4</span>,</span><br><span class="line">            <span class="attr">"value"</span>: <span class="number">1</span></span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="attr">"id"</span>: <span class="number">2</span>,</span><br><span class="line">            <span class="attr">"name"</span>: <span class="string">"name"</span>,</span><br><span class="line">            <span class="attr">"column_type"</span>: <span class="number">12</span>,</span><br><span class="line">            <span class="attr">"value"</span>: <span class="string">"Amy"</span></span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="attr">"id"</span>: <span class="number">3</span>,</span><br><span class="line">            <span class="attr">"name"</span>: <span class="string">"createtime"</span>,</span><br><span class="line">            <span class="attr">"column_type"</span>: <span class="number">93</span>,</span><br><span class="line">            <span class="attr">"value"</span>: <span class="string">"2022-04-03 16:08:39.0"</span></span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="attr">"id"</span>: <span class="number">4</span>,</span><br><span class="line">            <span class="attr">"name"</span>: <span class="string">"updatetime"</span>,</span><br><span class="line">            <span class="attr">"column_type"</span>: <span class="number">93</span>,</span><br><span class="line">            <span class="attr">"value"</span>: <span class="string">"2022-04-03 16:08:42.0"</span></span><br><span class="line">        &#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>没有设置<strong>Distributed Map Cache Client</strong>时</li></ul><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">"type"</span>: <span class="string">"delete"</span>,</span><br><span class="line">    <span class="attr">"timestamp"</span>: <span class="number">1648960096000</span>,</span><br><span class="line">    <span class="attr">"binlog_filename"</span>: <span class="string">"binlog.000002"</span>,</span><br><span class="line">    <span class="attr">"binlog_position"</span>: <span class="number">2084</span>,</span><br><span class="line">    <span class="attr">"database"</span>: <span class="literal">null</span>,</span><br><span class="line">    <span class="attr">"table_name"</span>: <span class="literal">null</span>,</span><br><span class="line">    <span class="attr">"table_id"</span>: <span class="literal">null</span>,</span><br><span class="line">    <span class="attr">"columns"</span>:</span><br><span class="line">    [</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="attr">"id"</span>: <span class="number">1</span>,</span><br><span class="line">            <span class="attr">"value"</span>: <span class="number">1</span></span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="attr">"id"</span>: <span class="number">2</span>,</span><br><span class="line">            <span class="attr">"value"</span>: <span class="literal">null</span></span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="attr">"id"</span>: <span class="number">3</span>,</span><br><span class="line">            <span class="attr">"value"</span>: <span class="literal">null</span></span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="attr">"id"</span>: <span class="number">4</span>,</span><br><span class="line">            <span class="attr">"value"</span>: <span class="literal">null</span></span><br><span class="line">        &#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul><h2 id="问题集"><a href="#问题集" class="headerlink" title="问题集"></a>问题集</h2><ul><li><p>如果没有配置<strong>Distributed Map Cache Client</strong>会提示warning</p><blockquote><p>可以忽略，不过输出结果没有字段名称和类型。所以建议设置。</p></blockquote></li><li><p>MySQL8账户密码类型不能使用默认的</p><blockquote><p>创建MySQL账户时需要指定mysql_native_password</p></blockquote></li></ul>]]></content>
      
      
      <categories>
          
          <category> IT </category>
          
      </categories>
      
      
        <tags>
            
            <tag> bigdata </tag>
            
            <tag> dataflow </tag>
            
            <tag> nifi </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Nifi集群安装</title>
      <link href="/IT/it-bigdata-dataflow-nifi-cluster-installation/"/>
      <url>/IT/it-bigdata-dataflow-nifi-cluster-installation/</url>
      
        <content type="html"><![CDATA[<blockquote><p>Nifi集群HTTP模式安装时遇到的一些问题记录集</p><p>官网：<a href="https://nifi.apache.org/index.html" target="_blank" rel="noopener">Apache NiFi</a></p><p>集群配置文档：<a href="https://nifi.apache.org/docs/nifi-docs/html/administration-guide.html#clustering" target="_blank" rel="noopener">NiFi System Administrator’s Guide (apache.org)</a></p></blockquote><a id="more"></a><h2 id="环境信息"><a href="#环境信息" class="headerlink" title="环境信息"></a>环境信息</h2><p><strong>nifi-1.5.3</strong></p><p><strong>Mac</strong></p><p><strong>JDK1.8</strong></p><p><img src="/IT/it-bigdata-dataflow-nifi-cluster-installation/image-20220329211103224.png" alt="image-20220329211103224"></p><h2 id="效果"><a href="#效果" class="headerlink" title="效果"></a>效果</h2><img src="/IT/it-bigdata-dataflow-nifi-cluster-installation/image-20220329210938014.png" alt="image-20220329210938014" style="zoom:50%;"><p><img src="/IT/it-bigdata-dataflow-nifi-cluster-installation/image-20220329211029825.png" alt="image-20220329211029825"></p><h2 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h2><h3 id="bin-nifi-env-sh"><a href="#bin-nifi-env-sh" class="headerlink" title="bin/nifi-env.sh"></a>bin/nifi-env.sh</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> JAVA_HOME=/Library/Java/JavaVirtualMachines/openjdk-8.jdk/Contents/Home</span><br></pre></td></tr></table></figure><h3 id="conf-nifi-properties"><a href="#conf-nifi-properties" class="headerlink" title="conf/nifi.properties"></a>conf/nifi.properties</h3><ol><li><p>Site to Site properties<br>这里关闭了secure配置</p><img src="/IT/it-bigdata-dataflow-nifi-cluster-installation/image-20220329182918332.png" alt="image-20220329182918332" style="zoom:50%;"></li><li><p>Web properties</p><p>这里http与https只能配置一个，因为我配置的是http，所以https注释了。</p><img src="/IT/it-bigdata-dataflow-nifi-cluster-installation/image-20220329182857162.png" alt="image-20220329182857162" style="zoom:50%;"></li><li><p>security properties<br><strong>nifi.sensitive.props.key</strong>长度有要求，12位长度以上。</p><img src="/IT/it-bigdata-dataflow-nifi-cluster-installation/image-20220329182529892.png" alt="image-20220329182529892" style="zoom:50%;"></li><li><p>cluster common properties</p><img src="/IT/it-bigdata-dataflow-nifi-cluster-installation/image-20220329205623271.png" alt="image-20220329205623271" style="zoom:50%;"></li><li><p>cluster node properties</p><p><strong>nifi.cluster.flow.election.max.wait.time</strong>和<strong>nifi.cluster.flow.election.max.candidates</strong>可以根据实际情况来设置，因为我这里只有一个节点。端口也按自己的情况设置。</p><img src="/IT/it-bigdata-dataflow-nifi-cluster-installation/image-20220329205726775.png" alt="image-20220329205726775" style="zoom:50%;"></li><li><p>cluster load balancing properties</p><img src="/IT/it-bigdata-dataflow-nifi-cluster-installation/image-20220329205954078.png" alt="image-20220329205954078" style="zoom:50%;"></li><li><p>zookeeper properties, used for cluster management </p><img src="/IT/it-bigdata-dataflow-nifi-cluster-installation/image-20220329210057852.png" alt="image-20220329205954078" style="zoom:50%;"></li></ol><figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Licensed to the Apache Software Foundation (ASF) under one or more</span></span><br><span class="line"><span class="comment"># contributor license agreements.  See the NOTICE file distributed with</span></span><br><span class="line"><span class="comment"># this work for additional information regarding copyright ownership.</span></span><br><span class="line"><span class="comment"># The ASF licenses this file to You under the Apache License, Version 2.0</span></span><br><span class="line"><span class="comment"># (the "License"); you may not use this file except in compliance with</span></span><br><span class="line"><span class="comment"># the License.  You may obtain a copy of the License at</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">#     http://www.apache.org/licenses/LICENSE-2.0</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># Unless required by applicable law or agreed to in writing, software</span></span><br><span class="line"><span class="comment"># distributed under the License is distributed on an "AS IS" BASIS,</span></span><br><span class="line"><span class="comment"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></span><br><span class="line"><span class="comment"># See the License for the specific language governing permissions and</span></span><br><span class="line"><span class="comment"># limitations under the License.</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Core Properties #</span></span><br><span class="line"><span class="meta">nifi.flow.configuration.file</span>=<span class="string">./conf/flow.xml.gz</span></span><br><span class="line"><span class="meta">nifi.flow.configuration.archive.enabled</span>=<span class="string">true</span></span><br><span class="line"><span class="meta">nifi.flow.configuration.archive.dir</span>=<span class="string">./conf/archive/</span></span><br><span class="line"><span class="meta">nifi.flow.configuration.archive.max.time</span>=<span class="string">30 days</span></span><br><span class="line"><span class="meta">nifi.flow.configuration.archive.max.storage</span>=<span class="string">500 MB</span></span><br><span class="line"><span class="meta">nifi.flow.configuration.archive.max.count</span>=<span class="string"></span></span><br><span class="line"><span class="meta">nifi.flowcontroller.autoResumeState</span>=<span class="string">true</span></span><br><span class="line"><span class="meta">nifi.flowcontroller.graceful.shutdown.period</span>=<span class="string">10 sec</span></span><br><span class="line"><span class="meta">nifi.flowservice.writedelay.interval</span>=<span class="string">500 ms</span></span><br><span class="line"><span class="meta">nifi.administrative.yield.duration</span>=<span class="string">30 sec</span></span><br><span class="line"><span class="comment"># If a component has no work to do (is "bored"), how long should we wait before checking again for work?</span></span><br><span class="line"><span class="meta">nifi.bored.yield.duration</span>=<span class="string">10 millis</span></span><br><span class="line"><span class="meta">nifi.queue.backpressure.count</span>=<span class="string">10000</span></span><br><span class="line"><span class="meta">nifi.queue.backpressure.size</span>=<span class="string">1 GB</span></span><br><span class="line"></span><br><span class="line"><span class="meta">nifi.authorizer.configuration.file</span>=<span class="string">./conf/authorizers.xml</span></span><br><span class="line"><span class="meta">nifi.login.identity.provider.configuration.file</span>=<span class="string">./conf/login-identity-providers.xml</span></span><br><span class="line"><span class="meta">nifi.templates.directory</span>=<span class="string">./conf/templates</span></span><br><span class="line"><span class="meta">nifi.ui.banner.text</span>=<span class="string"></span></span><br><span class="line"><span class="meta">nifi.ui.autorefresh.interval</span>=<span class="string">30 sec</span></span><br><span class="line"><span class="meta">nifi.nar.library.directory</span>=<span class="string">./lib</span></span><br><span class="line"><span class="meta">nifi.nar.library.autoload.directory</span>=<span class="string">./extensions</span></span><br><span class="line"><span class="meta">nifi.nar.working.directory</span>=<span class="string">./work/nar/</span></span><br><span class="line"><span class="meta">nifi.documentation.working.directory</span>=<span class="string">./work/docs/components</span></span><br><span class="line"></span><br><span class="line"><span class="comment">####################</span></span><br><span class="line"><span class="comment"># State Management #</span></span><br><span class="line"><span class="comment">####################</span></span><br><span class="line"><span class="meta">nifi.state.management.configuration.file</span>=<span class="string">./conf/state-management.xml</span></span><br><span class="line"><span class="comment"># The ID of the local state provider</span></span><br><span class="line"><span class="meta">nifi.state.management.provider.local</span>=<span class="string">local-provider</span></span><br><span class="line"><span class="comment"># The ID of the cluster-wide state provider. This will be ignored if NiFi is not clustered but must be populated if running in a cluster.</span></span><br><span class="line"><span class="meta">nifi.state.management.provider.cluster</span>=<span class="string">zk-provider</span></span><br><span class="line"><span class="comment"># Specifies whether or not this instance of NiFi should run an embedded ZooKeeper server</span></span><br><span class="line"><span class="meta">nifi.state.management.embedded.zookeeper.start</span>=<span class="string">true</span></span><br><span class="line"><span class="comment"># Properties file that provides the ZooKeeper properties to use if &lt;nifi.state.management.embedded.zookeeper.start&gt; is set to true</span></span><br><span class="line"><span class="meta">nifi.state.management.embedded.zookeeper.properties</span>=<span class="string">./conf/zookeeper.properties</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># H2 Settings</span></span><br><span class="line"><span class="meta">nifi.database.directory</span>=<span class="string">./database_repository</span></span><br><span class="line"><span class="meta">nifi.h2.url.append</span>=<span class="string">;LOCK_TIMEOUT=25000;WRITE_DELAY=0;AUTO_SERVER=FALSE</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Repository Encryption properties override individual repository implementation properties</span></span><br><span class="line"><span class="meta">nifi.repository.encryption.protocol.version</span>=<span class="string"></span></span><br><span class="line"><span class="meta">nifi.repository.encryption.key.id</span>=<span class="string"></span></span><br><span class="line"><span class="meta">nifi.repository.encryption.key.provider</span>=<span class="string"></span></span><br><span class="line"><span class="meta">nifi.repository.encryption.key.provider.keystore.location</span>=<span class="string"></span></span><br><span class="line"><span class="meta">nifi.repository.encryption.key.provider.keystore.password</span>=<span class="string"></span></span><br><span class="line"></span><br><span class="line"><span class="comment"># FlowFile Repository</span></span><br><span class="line"><span class="meta">nifi.flowfile.repository.implementation</span>=<span class="string">org.apache.nifi.controller.repository.WriteAheadFlowFileRepository</span></span><br><span class="line"><span class="meta">nifi.flowfile.repository.wal.implementation</span>=<span class="string">org.apache.nifi.wali.SequentialAccessWriteAheadLog</span></span><br><span class="line"><span class="meta">nifi.flowfile.repository.directory</span>=<span class="string">./flowfile_repository</span></span><br><span class="line"><span class="meta">nifi.flowfile.repository.checkpoint.interval</span>=<span class="string">20 secs</span></span><br><span class="line"><span class="meta">nifi.flowfile.repository.always.sync</span>=<span class="string">false</span></span><br><span class="line"><span class="meta">nifi.flowfile.repository.retain.orphaned.flowfiles</span>=<span class="string">true</span></span><br><span class="line"></span><br><span class="line"><span class="meta">nifi.swap.manager.implementation</span>=<span class="string">org.apache.nifi.controller.FileSystemSwapManager</span></span><br><span class="line"><span class="meta">nifi.queue.swap.threshold</span>=<span class="string">20000</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Content Repository</span></span><br><span class="line"><span class="meta">nifi.content.repository.implementation</span>=<span class="string">org.apache.nifi.controller.repository.FileSystemRepository</span></span><br><span class="line"><span class="meta">nifi.content.claim.max.appendable.size</span>=<span class="string">1 MB</span></span><br><span class="line"><span class="meta">nifi.content.repository.directory.default</span>=<span class="string">./content_repository</span></span><br><span class="line"><span class="meta">nifi.content.repository.archive.max.retention.period</span>=<span class="string">7 days</span></span><br><span class="line"><span class="meta">nifi.content.repository.archive.max.usage.percentage</span>=<span class="string">50%</span></span><br><span class="line"><span class="meta">nifi.content.repository.archive.enabled</span>=<span class="string">true</span></span><br><span class="line"><span class="meta">nifi.content.repository.always.sync</span>=<span class="string">false</span></span><br><span class="line"><span class="meta">nifi.content.viewer.url</span>=<span class="string">../nifi-content-viewer/</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Provenance Repository Properties</span></span><br><span class="line"><span class="meta">nifi.provenance.repository.implementation</span>=<span class="string">org.apache.nifi.provenance.WriteAheadProvenanceRepository</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Persistent Provenance Repository Properties</span></span><br><span class="line"><span class="meta">nifi.provenance.repository.directory.default</span>=<span class="string">./provenance_repository</span></span><br><span class="line"><span class="meta">nifi.provenance.repository.max.storage.time</span>=<span class="string">30 days</span></span><br><span class="line"><span class="meta">nifi.provenance.repository.max.storage.size</span>=<span class="string">10 GB</span></span><br><span class="line"><span class="meta">nifi.provenance.repository.rollover.time</span>=<span class="string">10 mins</span></span><br><span class="line"><span class="meta">nifi.provenance.repository.rollover.size</span>=<span class="string">100 MB</span></span><br><span class="line"><span class="meta">nifi.provenance.repository.query.threads</span>=<span class="string">2</span></span><br><span class="line"><span class="meta">nifi.provenance.repository.index.threads</span>=<span class="string">2</span></span><br><span class="line"><span class="meta">nifi.provenance.repository.compress.on.rollover</span>=<span class="string">true</span></span><br><span class="line"><span class="meta">nifi.provenance.repository.always.sync</span>=<span class="string">false</span></span><br><span class="line"><span class="comment"># Comma-separated list of fields. Fields that are not indexed will not be searchable. Valid fields are:</span></span><br><span class="line"><span class="comment"># EventType, FlowFileUUID, Filename, TransitURI, ProcessorID, AlternateIdentifierURI, Relationship, Details</span></span><br><span class="line"><span class="meta">nifi.provenance.repository.indexed.fields</span>=<span class="string">EventType, FlowFileUUID, Filename, ProcessorID, Relationship</span></span><br><span class="line"><span class="comment"># FlowFile Attributes that should be indexed and made searchable.  Some examples to consider are filename, uuid, mime.type</span></span><br><span class="line"><span class="meta">nifi.provenance.repository.indexed.attributes</span>=<span class="string"></span></span><br><span class="line"><span class="comment"># Large values for the shard size will result in more Java heap usage when searching the Provenance Repository</span></span><br><span class="line"><span class="comment"># but should provide better performance</span></span><br><span class="line"><span class="meta">nifi.provenance.repository.index.shard.size</span>=<span class="string">500 MB</span></span><br><span class="line"><span class="comment"># Indicates the maximum length that a FlowFile attribute can be when retrieving a Provenance Event from</span></span><br><span class="line"><span class="comment"># the repository. If the length of any attribute exceeds this value, it will be truncated when the event is retrieved.</span></span><br><span class="line"><span class="meta">nifi.provenance.repository.max.attribute.length</span>=<span class="string">65536</span></span><br><span class="line"><span class="meta">nifi.provenance.repository.concurrent.merge.threads</span>=<span class="string">2</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Volatile Provenance Respository Properties</span></span><br><span class="line"><span class="meta">nifi.provenance.repository.buffer.size</span>=<span class="string">100000</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Component and Node Status History Repository</span></span><br><span class="line"><span class="meta">nifi.components.status.repository.implementation</span>=<span class="string">org.apache.nifi.controller.status.history.VolatileComponentStatusRepository</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Volatile Status History Repository Properties</span></span><br><span class="line"><span class="meta">nifi.components.status.repository.buffer.size</span>=<span class="string">1440</span></span><br><span class="line"><span class="meta">nifi.components.status.snapshot.frequency</span>=<span class="string">1 min</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># QuestDB Status History Repository Properties</span></span><br><span class="line"><span class="meta">nifi.status.repository.questdb.persist.node.days</span>=<span class="string">14</span></span><br><span class="line"><span class="meta">nifi.status.repository.questdb.persist.component.days</span>=<span class="string">3</span></span><br><span class="line"><span class="meta">nifi.status.repository.questdb.persist.location</span>=<span class="string">./status_repository</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Site to Site properties</span></span><br><span class="line"><span class="meta">nifi.remote.input.host</span>=<span class="string"></span></span><br><span class="line"><span class="meta">nifi.remote.input.secure</span>=<span class="string">false</span></span><br><span class="line"><span class="meta">nifi.remote.input.socket.port</span>=<span class="string"></span></span><br><span class="line"><span class="meta">nifi.remote.input.http.enabled</span>=<span class="string">false</span></span><br><span class="line"><span class="meta">nifi.remote.input.http.transaction.ttl</span>=<span class="string">30 sec</span></span><br><span class="line"><span class="meta">nifi.remote.contents.cache.expiration</span>=<span class="string">30 secs</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># web properties #</span></span><br><span class="line"><span class="comment">#############################################</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># For security, NiFi will present the UI on 127.0.0.1 and only be accessible through this loopback interface.</span></span><br><span class="line"><span class="comment"># Be aware that changing these properties may affect how your instance can be accessed without any restriction.</span></span><br><span class="line"><span class="comment"># We recommend configuring HTTPS instead. The administrators guide provides instructions on how to do this.</span></span><br><span class="line"></span><br><span class="line"><span class="meta">nifi.web.http.host</span>=<span class="string">sleety.local</span></span><br><span class="line"><span class="meta">nifi.web.http.port</span>=<span class="string">18001</span></span><br><span class="line"><span class="meta">nifi.web.http.network.interface.default</span>=<span class="string"></span></span><br><span class="line"></span><br><span class="line"><span class="comment">#############################################</span></span><br><span class="line"></span><br><span class="line"><span class="meta">nifi.web.https.host</span>=<span class="string"></span></span><br><span class="line"><span class="comment"># 127.0.0.1</span></span><br><span class="line"><span class="meta">nifi.web.https.port</span>=<span class="string"></span></span><br><span class="line"><span class="comment"># 8443</span></span><br><span class="line"><span class="meta">nifi.web.https.network.interface.default</span>=<span class="string"></span></span><br><span class="line"><span class="meta">nifi.web.jetty.working.directory</span>=<span class="string">./work/jetty</span></span><br><span class="line"><span class="meta">nifi.web.jetty.threads</span>=<span class="string">200</span></span><br><span class="line"><span class="meta">nifi.web.max.header.size</span>=<span class="string">16 KB</span></span><br><span class="line"><span class="meta">nifi.web.proxy.context.path</span>=<span class="string"></span></span><br><span class="line"><span class="meta">nifi.web.proxy.host</span>=<span class="string"></span></span><br><span class="line"><span class="meta">nifi.web.max.content.size</span>=<span class="string"></span></span><br><span class="line"><span class="meta">nifi.web.max.requests.per.second</span>=<span class="string">30000</span></span><br><span class="line"><span class="meta">nifi.web.max.access.token.requests.per.second</span>=<span class="string">25</span></span><br><span class="line"><span class="meta">nifi.web.request.timeout</span>=<span class="string">60 secs</span></span><br><span class="line"><span class="meta">nifi.web.request.ip.whitelist</span>=<span class="string"></span></span><br><span class="line"><span class="meta">nifi.web.should.send.server.version</span>=<span class="string">true</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Include or Exclude TLS Cipher Suites for HTTPS</span></span><br><span class="line"><span class="meta">nifi.web.https.ciphersuites.include</span>=<span class="string"></span></span><br><span class="line"><span class="meta">nifi.web.https.ciphersuites.exclude</span>=<span class="string"></span></span><br><span class="line"></span><br><span class="line"><span class="comment"># security properties #</span></span><br><span class="line"><span class="meta">nifi.sensitive.props.key</span>=<span class="string">youchangeitok</span></span><br><span class="line"><span class="meta">nifi.sensitive.props.key.protected</span>=<span class="string"></span></span><br><span class="line"><span class="meta">nifi.sensitive.props.algorithm</span>=<span class="string">NIFI_PBKDF2_AES_GCM_256</span></span><br><span class="line"><span class="meta">nifi.sensitive.props.additional.keys</span>=<span class="string"></span></span><br><span class="line"></span><br><span class="line"><span class="meta">nifi.security.autoreload.enabled</span>=<span class="string">false</span></span><br><span class="line"><span class="meta">nifi.security.autoreload.interval</span>=<span class="string">10 secs</span></span><br><span class="line"><span class="meta">nifi.security.keystore</span>=<span class="string">./conf/keystore.p12</span></span><br><span class="line"><span class="meta">nifi.security.keystoreType</span>=<span class="string">PKCS12</span></span><br><span class="line"><span class="meta">nifi.security.keystorePasswd</span>=<span class="string">67cee0ed3aba2755de751ff0ac5380fb</span></span><br><span class="line"><span class="meta">nifi.security.keyPasswd</span>=<span class="string">67cee0ed3aba2755de751ff0ac5380fb</span></span><br><span class="line"><span class="meta">nifi.security.truststore</span>=<span class="string">./conf/truststore.p12</span></span><br><span class="line"><span class="meta">nifi.security.truststoreType</span>=<span class="string">PKCS12</span></span><br><span class="line"><span class="meta">nifi.security.truststorePasswd</span>=<span class="string">797877f1ba3bd64380f7f15494ac12ec</span></span><br><span class="line"><span class="meta">nifi.security.user.authorizer</span>=<span class="string">single-user-authorizer</span></span><br><span class="line"><span class="meta">nifi.security.allow.anonymous.authentication</span>=<span class="string">false</span></span><br><span class="line"><span class="meta">nifi.security.user.login.identity.provider</span>=<span class="string">single-user-provider</span></span><br><span class="line"><span class="meta">nifi.security.user.jws.key.rotation.period</span>=<span class="string">PT1H</span></span><br><span class="line"><span class="meta">nifi.security.ocsp.responder.url</span>=<span class="string"></span></span><br><span class="line"><span class="meta">nifi.security.ocsp.responder.certificate</span>=<span class="string"></span></span><br><span class="line"></span><br><span class="line"><span class="comment"># OpenId Connect SSO Properties #</span></span><br><span class="line"><span class="meta">nifi.security.user.oidc.discovery.url</span>=<span class="string"></span></span><br><span class="line"><span class="meta">nifi.security.user.oidc.connect.timeout</span>=<span class="string">5 secs</span></span><br><span class="line"><span class="meta">nifi.security.user.oidc.read.timeout</span>=<span class="string">5 secs</span></span><br><span class="line"><span class="meta">nifi.security.user.oidc.client.id</span>=<span class="string"></span></span><br><span class="line"><span class="meta">nifi.security.user.oidc.client.secret</span>=<span class="string"></span></span><br><span class="line"><span class="meta">nifi.security.user.oidc.preferred.jwsalgorithm</span>=<span class="string"></span></span><br><span class="line"><span class="meta">nifi.security.user.oidc.additional.scopes</span>=<span class="string"></span></span><br><span class="line"><span class="meta">nifi.security.user.oidc.claim.identifying.user</span>=<span class="string"></span></span><br><span class="line"><span class="meta">nifi.security.user.oidc.fallback.claims.identifying.user</span>=<span class="string"></span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Apache Knox SSO Properties #</span></span><br><span class="line"><span class="meta">nifi.security.user.knox.url</span>=<span class="string"></span></span><br><span class="line"><span class="meta">nifi.security.user.knox.publicKey</span>=<span class="string"></span></span><br><span class="line"><span class="meta">nifi.security.user.knox.cookieName</span>=<span class="string">hadoop-jwt</span></span><br><span class="line"><span class="meta">nifi.security.user.knox.audiences</span>=<span class="string"></span></span><br><span class="line"></span><br><span class="line"><span class="comment"># SAML Properties #</span></span><br><span class="line"><span class="meta">nifi.security.user.saml.idp.metadata.url</span>=<span class="string"></span></span><br><span class="line"><span class="meta">nifi.security.user.saml.sp.entity.id</span>=<span class="string"></span></span><br><span class="line"><span class="meta">nifi.security.user.saml.identity.attribute.name</span>=<span class="string"></span></span><br><span class="line"><span class="meta">nifi.security.user.saml.group.attribute.name</span>=<span class="string"></span></span><br><span class="line"><span class="meta">nifi.security.user.saml.metadata.signing.enabled</span>=<span class="string">false</span></span><br><span class="line"><span class="meta">nifi.security.user.saml.request.signing.enabled</span>=<span class="string">false</span></span><br><span class="line"><span class="meta">nifi.security.user.saml.want.assertions.signed</span>=<span class="string">true</span></span><br><span class="line"><span class="meta">nifi.security.user.saml.signature.algorithm</span>=<span class="string">http://www.w3.org/2001/04/xmldsig-more#rsa-sha256</span></span><br><span class="line"><span class="meta">nifi.security.user.saml.signature.digest.algorithm</span>=<span class="string">http://www.w3.org/2001/04/xmlenc#sha256</span></span><br><span class="line"><span class="meta">nifi.security.user.saml.message.logging.enabled</span>=<span class="string">false</span></span><br><span class="line"><span class="meta">nifi.security.user.saml.authentication.expiration</span>=<span class="string">12 hours</span></span><br><span class="line"><span class="meta">nifi.security.user.saml.single.logout.enabled</span>=<span class="string">false</span></span><br><span class="line"><span class="meta">nifi.security.user.saml.http.client.truststore.strategy</span>=<span class="string">JDK</span></span><br><span class="line"><span class="meta">nifi.security.user.saml.http.client.connect.timeout</span>=<span class="string">30 secs</span></span><br><span class="line"><span class="meta">nifi.security.user.saml.http.client.read.timeout</span>=<span class="string">30 secs</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Identity Mapping Properties #</span></span><br><span class="line"><span class="comment"># These properties allow normalizing user identities such that identities coming from different identity providers</span></span><br><span class="line"><span class="comment"># (certificates, LDAP, Kerberos) can be treated the same internally in NiFi. The following example demonstrates normalizing</span></span><br><span class="line"><span class="comment"># DNs from certificates and principals from Kerberos into a common identity string:</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># nifi.security.identity.mapping.pattern.dn=^CN=(.*?), OU=(.*?), O=(.*?), L=(.*?), ST=(.*?), C=(.*?)$</span></span><br><span class="line"><span class="comment"># nifi.security.identity.mapping.value.dn=$1@$2</span></span><br><span class="line"><span class="comment"># nifi.security.identity.mapping.transform.dn=NONE</span></span><br><span class="line"><span class="comment"># nifi.security.identity.mapping.pattern.kerb=^(.*?)/instance@(.*?)$</span></span><br><span class="line"><span class="comment"># nifi.security.identity.mapping.value.kerb=$1@$2</span></span><br><span class="line"><span class="comment"># nifi.security.identity.mapping.transform.kerb=UPPER</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Group Mapping Properties #</span></span><br><span class="line"><span class="comment"># These properties allow normalizing group names coming from external sources like LDAP. The following example</span></span><br><span class="line"><span class="comment"># lowercases any group name.</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># nifi.security.group.mapping.pattern.anygroup=^(.*)$</span></span><br><span class="line"><span class="comment"># nifi.security.group.mapping.value.anygroup=$1</span></span><br><span class="line"><span class="comment"># nifi.security.group.mapping.transform.anygroup=LOWER</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># cluster common properties (all nodes must have same values) #</span></span><br><span class="line"><span class="meta">nifi.cluster.protocol.heartbeat.interval</span>=<span class="string">5 sec</span></span><br><span class="line"><span class="meta">nifi.cluster.protocol.heartbeat.missable.max</span>=<span class="string">8</span></span><br><span class="line"><span class="meta">nifi.cluster.protocol.is.secure</span>=<span class="string">false</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># cluster node properties (only configure for cluster nodes) #</span></span><br><span class="line"><span class="meta">nifi.cluster.is.node</span>=<span class="string">true</span></span><br><span class="line"><span class="meta">nifi.cluster.node.address</span>=<span class="string">sleety.local</span></span><br><span class="line"><span class="meta">nifi.cluster.node.protocol.port</span>=<span class="string">28001</span></span><br><span class="line"><span class="meta">nifi.cluster.node.protocol.max.threads</span>=<span class="string">50</span></span><br><span class="line"><span class="meta">nifi.cluster.node.event.history.size</span>=<span class="string">25</span></span><br><span class="line"><span class="meta">nifi.cluster.node.connection.timeout</span>=<span class="string">5 sec</span></span><br><span class="line"><span class="meta">nifi.cluster.node.read.timeout</span>=<span class="string">5 sec</span></span><br><span class="line"><span class="meta">nifi.cluster.node.max.concurrent.requests</span>=<span class="string">100</span></span><br><span class="line"><span class="meta">nifi.cluster.firewall.file</span>=<span class="string"></span></span><br><span class="line"><span class="meta">nifi.cluster.flow.election.max.wait.time</span>=<span class="string">1 mins</span></span><br><span class="line"><span class="meta">nifi.cluster.flow.election.max.candidates</span>=<span class="string">1</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># cluster load balancing properties #</span></span><br><span class="line"><span class="meta">nifi.cluster.load.balance.host</span>=<span class="string">sleety.local</span></span><br><span class="line"><span class="meta">nifi.cluster.load.balance.port</span>=<span class="string">6342</span></span><br><span class="line"><span class="meta">nifi.cluster.load.balance.connections.per.node</span>=<span class="string">1</span></span><br><span class="line"><span class="meta">nifi.cluster.load.balance.max.thread.count</span>=<span class="string">8</span></span><br><span class="line"><span class="meta">nifi.cluster.load.balance.comms.timeout</span>=<span class="string">30 sec</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># zookeeper properties, used for cluster management #</span></span><br><span class="line"><span class="meta">nifi.zookeeper.connect.string</span>=<span class="string">sleety.local:12181</span></span><br><span class="line"><span class="meta">nifi.zookeeper.connect.timeout</span>=<span class="string">10 secs</span></span><br><span class="line"><span class="meta">nifi.zookeeper.session.timeout</span>=<span class="string">10 secs</span></span><br><span class="line"><span class="meta">nifi.zookeeper.root.node</span>=<span class="string">/nifi</span></span><br><span class="line"><span class="meta">nifi.zookeeper.client.secure</span>=<span class="string">false</span></span><br><span class="line"><span class="meta">nifi.zookeeper.security.keystore</span>=<span class="string"></span></span><br><span class="line"><span class="meta">nifi.zookeeper.security.keystoreType</span>=<span class="string"></span></span><br><span class="line"><span class="meta">nifi.zookeeper.security.keystorePasswd</span>=<span class="string"></span></span><br><span class="line"><span class="meta">nifi.zookeeper.security.truststore</span>=<span class="string"></span></span><br><span class="line"><span class="meta">nifi.zookeeper.security.truststoreType</span>=<span class="string"></span></span><br><span class="line"><span class="meta">nifi.zookeeper.security.truststorePasswd</span>=<span class="string"></span></span><br><span class="line"><span class="meta">nifi.zookeeper.jute.maxbuffer</span>=<span class="string"></span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Zookeeper properties for the authentication scheme used when creating acls on znodes used for cluster management</span></span><br><span class="line"><span class="comment"># Values supported for nifi.zookeeper.auth.type are "default", which will apply world/anyone rights on znodes</span></span><br><span class="line"><span class="comment"># and "sasl" which will give rights to the sasl/kerberos identity used to authenticate the nifi node</span></span><br><span class="line"><span class="comment"># The identity is determined using the value in nifi.kerberos.service.principal and the removeHostFromPrincipal</span></span><br><span class="line"><span class="comment"># and removeRealmFromPrincipal values (which should align with the kerberos.removeHostFromPrincipal and kerberos.removeRealmFromPrincipal</span></span><br><span class="line"><span class="comment"># values configured on the zookeeper server).</span></span><br><span class="line"><span class="meta">nifi.zookeeper.auth.type</span>=<span class="string"></span></span><br><span class="line"><span class="meta">nifi.zookeeper.kerberos.removeHostFromPrincipal</span>=<span class="string"></span></span><br><span class="line"><span class="meta">nifi.zookeeper.kerberos.removeRealmFromPrincipal</span>=<span class="string"></span></span><br><span class="line"></span><br><span class="line"><span class="comment"># kerberos #</span></span><br><span class="line"><span class="meta">nifi.kerberos.krb5.file</span>=<span class="string"></span></span><br><span class="line"></span><br><span class="line"><span class="comment"># kerberos service principal #</span></span><br><span class="line"><span class="meta">nifi.kerberos.service.principal</span>=<span class="string"></span></span><br><span class="line"><span class="meta">nifi.kerberos.service.keytab.location</span>=<span class="string"></span></span><br><span class="line"></span><br><span class="line"><span class="comment"># kerberos spnego principal #</span></span><br><span class="line"><span class="meta">nifi.kerberos.spnego.principal</span>=<span class="string"></span></span><br><span class="line"><span class="meta">nifi.kerberos.spnego.keytab.location</span>=<span class="string"></span></span><br><span class="line"><span class="meta">nifi.kerberos.spnego.authentication.expiration</span>=<span class="string">12 hours</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># external properties files for variable registry</span></span><br><span class="line"><span class="comment"># supports a comma delimited list of file locations</span></span><br><span class="line"><span class="meta">nifi.variable.registry.properties</span>=<span class="string"></span></span><br><span class="line"></span><br><span class="line"><span class="comment"># analytics properties #</span></span><br><span class="line"><span class="meta">nifi.analytics.predict.enabled</span>=<span class="string">false</span></span><br><span class="line"><span class="meta">nifi.analytics.predict.interval</span>=<span class="string">3 mins</span></span><br><span class="line"><span class="meta">nifi.analytics.query.interval</span>=<span class="string">5 mins</span></span><br><span class="line"><span class="meta">nifi.analytics.connection.model.implementation</span>=<span class="string">org.apache.nifi.controller.status.analytics.models.OrdinaryLeastSquares</span></span><br><span class="line"><span class="meta">nifi.analytics.connection.model.score.name</span>=<span class="string">rSquared</span></span><br><span class="line"><span class="meta">nifi.analytics.connection.model.score.threshold</span>=<span class="string">.90</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># runtime monitoring properties</span></span><br><span class="line"><span class="meta">nifi.monitor.long.running.task.schedule</span>=<span class="string"></span></span><br><span class="line"><span class="meta">nifi.monitor.long.running.task.threshold</span>=<span class="string"></span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Create automatic diagnostics when stopping/restarting NiFi.</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Enable automatic diagnostic at shutdown.</span></span><br><span class="line"><span class="meta">nifi.diagnostics.on.shutdown.enabled</span>=<span class="string">false</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Include verbose diagnostic information.</span></span><br><span class="line"><span class="meta">nifi.diagnostics.on.shutdown.verbose</span>=<span class="string">false</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># The location of the diagnostics folder.</span></span><br><span class="line"><span class="meta">nifi.diagnostics.on.shutdown.directory</span>=<span class="string">./diagnostics</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># The maximum number of files permitted in the directory. If the limit is exceeded, the oldest files are deleted.</span></span><br><span class="line"><span class="meta">nifi.diagnostics.on.shutdown.max.filecount</span>=<span class="string">10</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># The diagnostics folder's maximum permitted size in bytes. If the limit is exceeded, the oldest files are deleted.</span></span><br><span class="line"><span class="meta">nifi.diagnostics.on.shutdown.max.directory.size</span>=<span class="string">10 MB</span></span><br></pre></td></tr></table></figure><h3 id="conf-zookeeper-properties"><a href="#conf-zookeeper-properties" class="headerlink" title="conf/zookeeper.properties"></a>conf/zookeeper.properties</h3><p>端口和servers配置<br><img src="/IT/it-bigdata-dataflow-nifi-cluster-installation/image-20220329210340030.png" alt="image-20220329210340030" style="zoom:50%;"></p><figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="attr">clientPort</span>=<span class="string">12181</span></span><br><span class="line"><span class="attr">initLimit</span>=<span class="string">10</span></span><br><span class="line"><span class="meta">autopurge.purgeInterval</span>=<span class="string">24</span></span><br><span class="line"><span class="attr">syncLimit</span>=<span class="string">5</span></span><br><span class="line"><span class="attr">tickTime</span>=<span class="string">2000</span></span><br><span class="line"><span class="attr">dataDir</span>=<span class="string">./state/zookeeper</span></span><br><span class="line"><span class="meta">autopurge.snapRetainCount</span>=<span class="string">30</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Embedded/distributed ZK TLS connection support can be activated by setting these properties at minimum:</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># secureClientPort=2281</span></span><br><span class="line"><span class="comment"># serverCnxnFactory=org.apache.zookeeper.server.NettyServerCnxnFactory</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Most TLS configurations will set these values as well:</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># ssl.keyStore.location=/example/path/to/key-store.jks</span></span><br><span class="line"><span class="comment"># ssl.keyStore.password=change this value to the actual value in your installation</span></span><br><span class="line"><span class="comment"># ssl.trustStore.location=/example/path/to/trust-store.jks</span></span><br><span class="line"><span class="comment"># ssl.trustStore.password=change this value to the actual value in your installation</span></span><br><span class="line"><span class="comment"># ssl.hostnameVerification=false</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># Note that many ZK parameters can set as Java system properties, refer to the ZK admin guide for details:</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># https://zookeeper.apache.org/doc/current/zookeeperAdmin.html#sc_configuration</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Other common settings:</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># client.portUnification=true</span></span><br><span class="line"><span class="comment"># admin.enableServer=false</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># The server string has changed as of 3.5.5 and the client port is now specified at the end of the server string:</span></span><br><span class="line"><span class="comment"># https://zookeeper.apache.org/doc/r3.5.5/zookeeperReconfig.html#sc_reconfig_clientport</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># Specifies the servers that are part of this zookeeper ensemble. For</span></span><br><span class="line"><span class="comment"># every NiFi instance running an embedded zookeeper, there needs to be</span></span><br><span class="line"><span class="comment"># a server entry below. Client port is now specified at the end of the string</span></span><br><span class="line"><span class="comment"># after a semi-colon.</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># For instance:</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># server.1=nifi-node1-hostname:2888:3888;2181</span></span><br><span class="line"><span class="comment"># server.2=nifi-node2-hostname:2888:3888;2181</span></span><br><span class="line"><span class="comment"># server.3=nifi-node3-hostname:2888:3888;2181</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># The index of the server corresponds to the myid file that gets created</span></span><br><span class="line"><span class="comment"># in the dataDir of each node running an embedded zookeeper. See the</span></span><br><span class="line"><span class="comment"># administration guide for more details.</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"></span><br><span class="line"><span class="meta">server.1</span>=<span class="string">sleety.local:12888:13888;12181</span></span><br></pre></td></tr></table></figure><h3 id="conf-state-management-xml"><a href="#conf-state-management-xml" class="headerlink" title="conf/state-management.xml"></a>conf/state-management.xml</h3><p>配置zk-provider<br><img src="/IT/it-bigdata-dataflow-nifi-cluster-installation/image-20220329210545997.png" alt="image-20220329210545997" style="zoom:50%;"></p><figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml</span> <span class="string">version="1.0" encoding="UTF-8" standalone="yes"?&gt;</span></span><br><span class="line"><span class="attr">&lt;!--</span></span><br><span class="line">  <span class="attr">Licensed</span> <span class="string">to the Apache Software Foundation (ASF) under one or more</span></span><br><span class="line">  <span class="attr">contributor</span> <span class="string">license agreements.  See the NOTICE file distributed with</span></span><br><span class="line">  <span class="attr">this</span> <span class="string">work for additional information regarding copyright ownership.</span></span><br><span class="line">  <span class="attr">The</span> <span class="string">ASF licenses this file to You under the Apache License, Version 2.0</span></span><br><span class="line">  <span class="meta">(the</span> <span class="string">"License"); you may not use this file except in compliance with</span></span><br><span class="line">  <span class="attr">the</span> <span class="string">License.  You may obtain a copy of the License at</span></span><br><span class="line">      <span class="attr">http</span>:<span class="string">//www.apache.org/licenses/LICENSE-2.0</span></span><br><span class="line">  <span class="attr">Unless</span> <span class="string">required by applicable law or agreed to in writing, software</span></span><br><span class="line">  <span class="attr">distributed</span> <span class="string">under the License is distributed on an "AS IS" BASIS,</span></span><br><span class="line">  <span class="attr">WITHOUT</span> <span class="string">WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></span><br><span class="line">  <span class="attr">See</span> <span class="string">the License for the specific language governing permissions and</span></span><br><span class="line">  <span class="attr">limitations</span> <span class="string">under the License.</span></span><br><span class="line"><span class="attr">--&gt;</span></span><br><span class="line"><span class="attr">&lt;!--</span></span><br><span class="line">  <span class="attr">This</span> <span class="string">file provides a mechanism for defining and configuring the State Providers</span></span><br><span class="line">  <span class="attr">that</span> <span class="string">should be used for storing state locally and across a NiFi cluster. In order</span></span><br><span class="line">  <span class="attr">to</span> <span class="string">use a specific provider, it must be configured here and its identifier</span></span><br><span class="line">  <span class="attr">must</span> <span class="string">be specified in the nifi.properties file.</span></span><br><span class="line"><span class="attr">--&gt;</span></span><br><span class="line"><span class="attr">&lt;stateManagement&gt;</span></span><br><span class="line">    <span class="attr">&lt;!--</span></span><br><span class="line">        <span class="attr">State</span> <span class="string">Provider that stores state locally in a configurable directory. This Provider requires the following properties:</span></span><br><span class="line">        </span><br><span class="line">        <span class="attr">Directory</span> <span class="string">- the directory to store components' state in. If the directory being used is a sub-directory of the NiFi installation, it</span></span><br><span class="line">                    <span class="attr">is</span> <span class="string">important that the directory be copied over to the new version when upgrading NiFi.</span></span><br><span class="line">        <span class="attr">Always</span> <span class="string">Sync - If set to true, any change to the repository will be synchronized to the disk, meaning that NiFi will ask the operating system not to cache the information. This is very</span></span><br><span class="line">                <span class="attr">expensive</span> <span class="string">and can significantly reduce NiFi performance. However, if it is false, there could be the potential for data loss if either there is a sudden power loss or the</span></span><br><span class="line">                <span class="attr">operating</span> <span class="string">system crashes. The default value is false.</span></span><br><span class="line">        <span class="attr">Partitions</span> <span class="string">- The number of partitions.</span></span><br><span class="line">        <span class="attr">Checkpoint</span> <span class="string">Interval - The amount of time between checkpoints.</span></span><br><span class="line">     <span class="attr">--&gt;</span></span><br><span class="line">    <span class="attr">&lt;local-provider&gt;</span></span><br><span class="line">        <span class="attr">&lt;id&gt;local-provider&lt;/id&gt;</span></span><br><span class="line">        <span class="attr">&lt;class&gt;org.apache.nifi.controller.state.providers.local.WriteAheadLocalStateProvider&lt;/class&gt;</span></span><br><span class="line">        <span class="meta">&lt;property</span> <span class="string">name="Directory"&gt;./state/local&lt;/property&gt;</span></span><br><span class="line">        <span class="meta">&lt;property</span> <span class="string">name="Always Sync"&gt;false&lt;/property&gt;</span></span><br><span class="line">        <span class="meta">&lt;property</span> <span class="string">name="Partitions"&gt;16&lt;/property&gt;</span></span><br><span class="line">        <span class="meta">&lt;property</span> <span class="string">name="Checkpoint Interval"&gt;2 mins&lt;/property&gt;</span></span><br><span class="line">    <span class="attr">&lt;/local-provider&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="attr">&lt;!--</span></span><br><span class="line">        <span class="attr">State</span> <span class="string">Provider that is used to store state in ZooKeeper. This Provider requires the following properties:</span></span><br><span class="line">        </span><br><span class="line">        <span class="attr">Root</span> <span class="string">Node - the root node in ZooKeeper where state should be stored. The default is '/nifi', but it is advisable to change this to a different value if not using</span></span><br><span class="line">                   <span class="attr">the</span> <span class="string">embedded ZooKeeper server and if multiple NiFi instances may all be using the same ZooKeeper Server.</span></span><br><span class="line">                   </span><br><span class="line">        <span class="attr">Connect</span> <span class="string">String - A comma-separated list of host:port pairs to connect to ZooKeeper. For example, myhost.mydomain:2181,host2.mydomain:5555,host3:6666</span></span><br><span class="line">        </span><br><span class="line">        <span class="attr">Session</span> <span class="string">Timeout - Specifies how long this instance of NiFi is allowed to be disconnected from ZooKeeper before creating a new ZooKeeper Session. Default value is "30 seconds"</span></span><br><span class="line">        </span><br><span class="line">        <span class="attr">Access</span> <span class="string">Control - Specifies which Access Controls will be applied to the ZooKeeper ZNodes that are created by this State Provider. This value must be set to one of:</span></span><br><span class="line">                            <span class="meta">-</span> <span class="string">Open  : ZNodes will be open to any ZooKeeper client.</span></span><br><span class="line">                            <span class="meta">-</span> <span class="string">CreatorOnly  : ZNodes will be accessible only by the creator. The creator will have full access to create children, read, write, delete, and administer the ZNodes.</span></span><br><span class="line">                                             <span class="attr">This</span> <span class="string">option is available only if access to ZooKeeper is secured via Kerberos or if a Username and Password are set.</span></span><br><span class="line">    <span class="attr">--&gt;</span></span><br><span class="line">    <span class="attr">&lt;cluster-provider&gt;</span></span><br><span class="line">        <span class="attr">&lt;id&gt;zk-provider&lt;/id&gt;</span></span><br><span class="line">        <span class="attr">&lt;class&gt;org.apache.nifi.controller.state.providers.zookeeper.ZooKeeperStateProvider&lt;/class&gt;</span></span><br><span class="line">        <span class="meta">&lt;property</span> <span class="string">name="Connect String"&gt;sleety.local:12181&lt;/property&gt;</span></span><br><span class="line">        <span class="meta">&lt;property</span> <span class="string">name="Root Node"&gt;/nifi&lt;/property&gt;</span></span><br><span class="line">        <span class="meta">&lt;property</span> <span class="string">name="Session Timeout"&gt;10 seconds&lt;/property&gt;</span></span><br><span class="line">        <span class="meta">&lt;property</span> <span class="string">name="Access Control"&gt;Open&lt;/property&gt;</span></span><br><span class="line">    <span class="attr">&lt;/cluster-provider&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="attr">&lt;!--</span></span><br><span class="line">        <span class="attr">Cluster</span> <span class="string">State Provider that stores state in Redis. This can be used as an alternative to the ZooKeeper State Provider.</span></span><br><span class="line"></span><br><span class="line">        <span class="attr">This</span> <span class="string">provider requires the following properties:</span></span><br><span class="line"></span><br><span class="line">            <span class="attr">Redis</span> <span class="string">Mode - The type of Redis instance:</span></span><br><span class="line">                            <span class="meta">-</span> <span class="string">Standalone</span></span><br><span class="line">                            <span class="meta">-</span> <span class="string">Sentinel</span></span><br><span class="line">                            <span class="meta">-</span> <span class="string">Cluster (currently not supported for state-management due to use of WATCH command which Redis does not support in clustered mode)</span></span><br><span class="line"></span><br><span class="line">            <span class="attr">Connection</span> <span class="string">String - The connection string for Redis.</span></span><br><span class="line">                        <span class="meta">-</span> <span class="string">In a standalone instance this value will be of the form hostname:port.</span></span><br><span class="line">                        <span class="meta">-</span> <span class="string">In a sentinel instance this value will be the comma-separated list of sentinels, such as host1:port1,host2:port2,host3:port3.</span></span><br><span class="line">                        <span class="meta">-</span> <span class="string">In a clustered instance this value will be the comma-separated list of cluster masters, such as host1:port,host2:port,host3:port.</span></span><br><span class="line"></span><br><span class="line">        <span class="attr">This</span> <span class="string">provider has the following optional properties:</span></span><br><span class="line"></span><br><span class="line">            <span class="attr">Key</span> <span class="string">Prefix - The prefix for each key stored by this state provider. When sharing a single Redis across multiple NiFi instances, setting a unique</span></span><br><span class="line">                        <span class="attr">value</span> <span class="string">for the Key Prefix will make it easier to identify which instances the keys came from (default nifi/components/).</span></span><br><span class="line"></span><br><span class="line">            <span class="attr">Database</span> <span class="string">Index - The database index to be used by connections created from this connection pool.</span></span><br><span class="line">                        <span class="attr">See</span> <span class="string">the databases property in redis.conf, by default databases 0-15 will be available.</span></span><br><span class="line"></span><br><span class="line">            <span class="attr">Communication</span> <span class="string">Timeout - The timeout to use when attempting to communicate with Redis.</span></span><br><span class="line"></span><br><span class="line">            <span class="attr">Cluster</span> <span class="string">Max Redirects - The maximum number of redirects that can be performed when clustered.</span></span><br><span class="line"></span><br><span class="line">            <span class="attr">Sentinel</span> <span class="string">Master - The name of the sentinel master, require when Mode is set to Sentinel.</span></span><br><span class="line"></span><br><span class="line">            <span class="attr">Password</span> <span class="string">- The password used to authenticate to the Redis server. See the requirepass property in redis.conf.</span></span><br><span class="line"></span><br><span class="line">            <span class="attr">Enable</span> <span class="string">TLS - If true, the Redis connection will be configured to use TLS, using the keystore and truststore settings configured in</span></span><br><span class="line">                    <span class="meta">nifi.properties.</span>  <span class="string">This means that a TLS-enabled Redis connection is only possible if the Apache NiFi instance is running in secure mode.</span></span><br><span class="line">                    <span class="attr">If</span> <span class="string">this property is false, an insecure Redis connection will be used even if the Apache NiFi instance is secure (default false).</span></span><br><span class="line"></span><br><span class="line">            <span class="attr">Pool</span> <span class="string">- Max Total - The maximum number of connections that can be allocated by the pool (checked out to clients, or idle awaiting checkout).</span></span><br><span class="line">                        <span class="attr">A</span> <span class="string">negative value indicates that there is no limit.</span></span><br><span class="line"></span><br><span class="line">            <span class="attr">Pool</span> <span class="string">- Max Idle - The maximum number of idle connections that can be held in the pool, or a negative value if there is no limit.</span></span><br><span class="line"></span><br><span class="line">            <span class="attr">Pool</span> <span class="string">- Min Idle - The target for the minimum number of idle connections to maintain in the pool. If the configured value of Min Idle is</span></span><br><span class="line">                    <span class="attr">greater</span> <span class="string">than the configured value for Max Idle, then the value of Max Idle will be used instead.</span></span><br><span class="line"></span><br><span class="line">            <span class="attr">Pool</span> <span class="string">- Block When Exhausted - Whether or not clients should block and wait when trying to obtain a connection from the pool when the pool</span></span><br><span class="line">                    <span class="attr">has</span> <span class="string">no available connections. Setting this to false means an error will occur immediately when a client requests a connection and</span></span><br><span class="line">                    <span class="attr">none</span> <span class="string">are available.</span></span><br><span class="line"></span><br><span class="line">            <span class="attr">Pool</span> <span class="string">- Max Wait Time - The amount of time to wait for an available connection when Block When Exhausted is set to true.</span></span><br><span class="line"></span><br><span class="line">            <span class="attr">Pool</span> <span class="string">- Min Evictable Idle Time - The minimum amount of time an object may sit idle in the pool before it is eligible for eviction.</span></span><br><span class="line"></span><br><span class="line">            <span class="attr">Pool</span> <span class="string">- Time Between Eviction Runs - The amount of time between attempting to evict idle connections from the pool.</span></span><br><span class="line"></span><br><span class="line">            <span class="attr">Pool</span> <span class="string">- Num Tests Per Eviction Run - The number of connections to tests per eviction attempt. A negative value indicates to test all connections.</span></span><br><span class="line"></span><br><span class="line">            <span class="attr">Pool</span> <span class="string">- Test On Create - Whether or not connections should be tested upon creation (default false).</span></span><br><span class="line"></span><br><span class="line">            <span class="attr">Pool</span> <span class="string">- Test On Borrow - Whether or not connections should be tested upon borrowing from the pool (default false).</span></span><br><span class="line"></span><br><span class="line">            <span class="attr">Pool</span> <span class="string">- Test On Return - Whether or not connections should be tested upon returning to the pool (default false).</span></span><br><span class="line"></span><br><span class="line">            <span class="attr">Pool</span> <span class="string">- Test While Idle - Whether or not connections should be tested while idle (default true).</span></span><br><span class="line"></span><br><span class="line">        <span class="attr">&lt;cluster-provider&gt;</span></span><br><span class="line">            <span class="attr">&lt;id&gt;redis-provider&lt;/id&gt;</span></span><br><span class="line">            <span class="attr">&lt;class&gt;org.apache.nifi.redis.state.RedisStateProvider&lt;/class&gt;</span></span><br><span class="line">            <span class="meta">&lt;property</span> <span class="string">name="Redis Mode"&gt;Standalone&lt;/property&gt;</span></span><br><span class="line">            <span class="meta">&lt;property</span> <span class="string">name="Connection String"&gt;localhost:6379&lt;/property&gt;</span></span><br><span class="line">        <span class="attr">&lt;/cluster-provider&gt;</span></span><br><span class="line">    <span class="attr">--&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="attr">&lt;/stateManagement&gt;</span></span><br></pre></td></tr></table></figure><h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><ul><li>ERROR [main] o.a.nifi.properties.NiFiPropertiesLoader Clustered Configuration Found: Shared Sensitive Properties Key [nifi.sensitive.props.key] required for cluster nodes</li></ul><blockquote><p>设置<strong>nifi.sensitive.props.key</strong></p></blockquote><ul><li>nested exception is org.apache.nifi.encrypt.EncryptionException: Key Password length less than required [12]</li></ul><blockquote><p><strong>nifi.sensitive.props.key</strong>长度需要12位以上</p></blockquote><ul><li>ERROR [main] org.apache.nifi.web.server.JettyServer NiFi only supports one mode of HTTP or HTTPS operation, not both simultaneously. Check the nifi.properties file and ensure that either the HTTP hostname and port or the HTTPS hostname and port are empty</li></ul><blockquote><p><strong>nifi.web.http.host/port</strong>与<strong>nifi.web.https.host/port</strong>二选一</p></blockquote><ul><li>ERROR [main] org.apache.nifi.NiFi Failure to launch NiFi org.xerial.snappy.SnappyError: [FAILED_TO_LOAD_NATIVE_LIBRARY] Unable to make protected final java.lang.Class java.lang.ClassLoader.defineClass(java.lang.String,byte[],int,int,java.security.ProtectionDomain) throws java.lang.ClassFormatError accessible: module java.base does not “opens java.lang” to unnamed module @729feae8</li></ul><blockquote><p>java版本问题，设置为nifi所支持的jdk版本</p></blockquote><ul><li>nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name ‘flowController’: FactoryBean threw exception on object creation; nested exception is java.lang.IllegalStateException: Unable to initialize Flow because NiFi was configured to start an Embedded Zookeeper server but failed to do so</li></ul><blockquote><p>检查zookeeper配置conf/zookeeper.properties</p><p>例如clientPort和server.N配置</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> IT </category>
          
      </categories>
      
      
        <tags>
            
            <tag> bigdata </tag>
            
            <tag> dataflow </tag>
            
            <tag> nifi </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>hive - lateral view使用事例</title>
      <link href="/IT/it-bigdata-hive-lateralview/"/>
      <url>/IT/it-bigdata-hive-lateralview/</url>
      
        <content type="html"><![CDATA[<blockquote><p>lateral view在处理拆分一列多值的情况非常有用，例如array，map等数据拆分。</p></blockquote><a id="more"></a><ol><li><p>创建一个专门用户hive language manual的数据</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">database</span> langmanual;</span><br><span class="line"><span class="keyword">use</span> langmanual;</span><br></pre></td></tr></table></figure></li><li><p>创建一个lateral view专属表： pageads</p></li></ol><ul><li><p><a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+LateralView" target="_blank" rel="noopener">lateral view</a></p></li><li><p><a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+UDF#LanguageManualUDF-Built-inTable-GeneratingFunctions(UDTF)" target="_blank" rel="noopener">Built-in Table-Generating Functions[UDTF]</a></p></li><li><p>syntax [改进版本]</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">lateralView: LATERAL VIEW [outer] udtf(expression) tableAlias AS columnAlias (',' columnAlias)*</span><br><span class="line">fromClause: FROM baseTable (',' lateralView)*</span><br></pre></td></tr></table></figure><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">drop</span> <span class="keyword">table</span> <span class="keyword">if</span> <span class="keyword">exists</span> pageads;</span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> pageAds</span><br><span class="line">( pageid <span class="keyword">string</span>, </span><br><span class="line">adid_list <span class="built_in">array</span>&lt;<span class="built_in">int</span>&gt;</span><br><span class="line">);</span><br></pre></td></tr></table></figure></li></ul><ol start="3"><li><p>插入两条数据</p><blockquote><p>array关键字</p></blockquote><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> pageAds <span class="keyword">values</span> (<span class="string">'front-page'</span>, <span class="built_in">array</span>(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>));</span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> pageAds <span class="keyword">values</span> (<span class="string">'contact-page'</span>, <span class="built_in">array</span>(<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>));</span><br></pre></td></tr></table></figure></li><li><p>查看数据</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> pageads ;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;*</span><br><span class="line">pageid      |adid_list|</span><br><span class="line">------------|---------|</span><br><span class="line">front-page  |[1,2,3]  |</span><br><span class="line">contact-page|[3,4,5]  |</span><br><span class="line">*&#x2F;</span><br></pre></td></tr></table></figure></li><li><p>使用lateral view 拆分广告id列表</p><blockquote><p>多个值转换成多行</p></blockquote><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">  <span class="keyword">select</span> pageid, adid </span><br><span class="line"><span class="keyword">from</span> pageads <span class="keyword">lateral</span> <span class="keyword">view</span> <span class="keyword">explode</span>(adid_list) adTable <span class="keyword">as</span> adid;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;*</span><br><span class="line">pageid      |adid|</span><br><span class="line">------------|----|</span><br><span class="line">front-page  |   1|</span><br><span class="line">front-page  |   2|</span><br><span class="line">front-page  |   3|</span><br><span class="line">contact-page|   3|</span><br><span class="line">contact-page|   4|</span><br><span class="line">contact-page|   5|</span><br><span class="line">*&#x2F;</span><br></pre></td></tr></table></figure></li><li><p>lateral view拆分成多个字段：adidx, adid [index，value]。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> pageid, adidx, adid <span class="keyword">from</span> pageads <span class="keyword">lateral</span> <span class="keyword">view</span> posexplode(adid_list) adTable <span class="keyword">as</span> adidx, adid;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;*</span><br><span class="line">pageid      |adidx|adid|</span><br><span class="line">------------|-----|----|</span><br><span class="line">front-page  |    0|   1|</span><br><span class="line">front-page  |    1|   2|</span><br><span class="line">front-page  |    2|   3|</span><br><span class="line">contact-page|    0|   3|</span><br><span class="line">contact-page|    1|   4|</span><br><span class="line">contact-page|    2|   5|</span><br><span class="line"> *&#x2F;</span><br></pre></td></tr></table></figure></li><li><p>插入adid_list为null的记录</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> pageAds(pageid) <span class="keyword">values</span> (<span class="string">'link-page'</span>);</span><br></pre></td></tr></table></figure></li><li><p>查看记录</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> pageads ;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">| pageid       | adid_list |</span><br><span class="line">| ------------ | --------- |</span><br><span class="line">| front-page   | [1,2,3]   |</span><br><span class="line">| contact-page | [3,4,5]   |</span><br><span class="line">| link-page    | NULL      |</span><br></pre></td></tr></table></figure></li><li><p>查看lateral view针对null记录的处理</p><blockquote><p>将会忽略 adid_list为NULL记录</p></blockquote><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> pageid, adid </span><br><span class="line"><span class="keyword">from</span> pageads <span class="keyword">lateral</span> <span class="keyword">view</span> <span class="keyword">explode</span>(adid_list) adTable <span class="keyword">as</span> adid;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;* </span><br><span class="line">pageid      |adid|</span><br><span class="line">------------|----|</span><br><span class="line">front-page  |   1|</span><br><span class="line">front-page  |   2|</span><br><span class="line">front-page  |   3|</span><br><span class="line">contact-page|   3| </span><br><span class="line">contact-page|   4|</span><br><span class="line">contact-page|   5|</span><br><span class="line">*&#x2F;</span><br></pre></td></tr></table></figure></li><li><p>查看lateral view outer 对null记录的处理</p><blockquote><p>加上outer关键字将会保留id_list为null的记录</p></blockquote><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> pageid, adid </span><br><span class="line"><span class="keyword">from</span> pageads <span class="keyword">lateral</span> <span class="keyword">view</span> <span class="keyword">outer</span> <span class="keyword">explode</span>(adid_list) adTable <span class="keyword">as</span> adid;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;* </span><br><span class="line">pageid      |adid|</span><br><span class="line">------------|----|</span><br><span class="line">front-page  |   1|</span><br><span class="line">front-page  |   2|</span><br><span class="line">front-page  |   3|</span><br><span class="line">contact-page|   3|</span><br><span class="line">contact-page|   4|</span><br><span class="line">contact-page|   5|</span><br><span class="line">link-page   |    |</span><br><span class="line">*&#x2F;</span><br></pre></td></tr></table></figure></li><li><p>lateral view 对group by的处理</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> adid, <span class="keyword">count</span>(adid)</span><br><span class="line"><span class="keyword">from</span> pageads  <span class="keyword">lateral</span> <span class="keyword">view</span> <span class="keyword">explode</span>(adid_list) adTable <span class="keyword">as</span> adid</span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span> adid;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;*</span><br><span class="line">adid|_c1|</span><br><span class="line">----|---|</span><br><span class="line"> 1|  1|</span><br><span class="line"> 2|  1|</span><br><span class="line"> 3|  2|</span><br><span class="line"> 4|  1|</span><br><span class="line"> 5|  1| </span><br><span class="line">*&#x2F;</span><br></pre></td></tr></table></figure></li><li><p>多个多值字段： 新增一个array字段，visit_count</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> pageads  <span class="keyword">add</span> <span class="keyword">columns</span> (visit_count <span class="built_in">array</span>&lt;<span class="built_in">int</span>&gt; <span class="keyword">comment</span> <span class="string">'访问次数'</span>);</span><br></pre></td></tr></table></figure></li><li><p>造数&amp;查看数据</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> pageAds <span class="keyword">values</span> (<span class="string">'footer-page'</span>, <span class="built_in">array</span>(<span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>), <span class="built_in">array</span>(<span class="number">700</span>, <span class="number">800</span>, <span class="number">900</span>));</span><br><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> pageads ;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;*</span><br><span class="line">pageid      |adid_list|visit_count  |</span><br><span class="line">------------|---------|-------------|</span><br><span class="line">front-page  |[1,2,3]  |NULL         |</span><br><span class="line">contact-page|[3,4,5]  |NULL         |</span><br><span class="line">link-page   |NULL     |NULL         |</span><br><span class="line">footer-page |[7,8,9]  |[700,800,900]|</span><br><span class="line">*&#x2F;</span><br></pre></td></tr></table></figure></li><li><p>一个lateral view对另外一个字段的处理</p><blockquote><p>另外一字段和常规字段一样，都是不变。</p></blockquote><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> * </span><br><span class="line"><span class="keyword">from</span> pageads </span><br><span class="line"><span class="keyword">lateral</span> <span class="keyword">view</span> <span class="keyword">explode</span>(adid_list) adTable <span class="keyword">as</span> adid;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;*</span><br><span class="line">pageid      |adid_list|visit_count  |adid|</span><br><span class="line">------------|---------|-------------|----|</span><br><span class="line">front-page  |[1,2,3]  |NULL         |   1|</span><br><span class="line">front-page  |[1,2,3]  |NULL         |   2|</span><br><span class="line">front-page  |[1,2,3]  |NULL         |   3|</span><br><span class="line">contact-page|[3,4,5]  |NULL         |   3|</span><br><span class="line">contact-page|[3,4,5]  |NULL         |   4|</span><br><span class="line">contact-page|[3,4,5]  |NULL         |   5|</span><br><span class="line">footer-page |[7,8,9]  |[700,800,900]|   7|</span><br><span class="line">footer-page |[7,8,9]  |[700,800,900]|   8|</span><br><span class="line">footer-page |[7,8,9]  |[700,800,900]|   9|</span><br><span class="line">*&#x2F;</span><br></pre></td></tr></table></figure></li><li><p>多个lateral view</p><blockquote><p>会拆分成多对多情况，即full outer join中，排除lateral view 任何字段为null的记录。</p></blockquote><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> * </span><br><span class="line"><span class="keyword">from</span> pageads </span><br><span class="line"><span class="keyword">lateral</span> <span class="keyword">view</span> <span class="keyword">explode</span>(adid_list) adTable <span class="keyword">as</span> adid</span><br><span class="line"><span class="keyword">lateral</span> <span class="keyword">view</span> <span class="keyword">explode</span>(visit_count)  vTable <span class="keyword">as</span> vct;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;*</span><br><span class="line">pageid     |adid_list|visit_count  |adid|vct|</span><br><span class="line">-----------|---------|-------------|----|---|</span><br><span class="line">footer-page|[7,8,9]  |[700,800,900]|   7|700|</span><br><span class="line">footer-page|[7,8,9]  |[700,800,900]|   7|800|</span><br><span class="line">footer-page|[7,8,9]  |[700,800,900]|   7|900|</span><br><span class="line">footer-page|[7,8,9]  |[700,800,900]|   8|700|</span><br><span class="line">footer-page|[7,8,9]  |[700,800,900]|   8|800|</span><br><span class="line">footer-page|[7,8,9]  |[700,800,900]|   8|900|</span><br><span class="line">footer-page|[7,8,9]  |[700,800,900]|   9|700|</span><br><span class="line">footer-page|[7,8,9]  |[700,800,900]|   9|800|</span><br><span class="line">footer-page|[7,8,9]  |[700,800,900]|   9|900|</span><br><span class="line">*&#x2F;</span><br></pre></td></tr></table></figure></li><li><p>多个lateral view outer</p><blockquote><p>会拆分成多对多情况，类似full outer join。</p></blockquote><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> * </span><br><span class="line"><span class="keyword">from</span> pageads </span><br><span class="line"><span class="keyword">lateral</span> <span class="keyword">view</span> <span class="keyword">outer</span> <span class="keyword">explode</span>(adid_list) adTable <span class="keyword">as</span> adid</span><br><span class="line"><span class="keyword">lateral</span> <span class="keyword">view</span> <span class="keyword">outer</span> <span class="keyword">explode</span>(visit_count)  vTable <span class="keyword">as</span> vct;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;*</span><br><span class="line">pageid      |adid_list|visit_count  |adid|vct|</span><br><span class="line">------------|---------|-------------|----|---|</span><br><span class="line">front-page  |[1,2,3]  |NULL         |   1|   |</span><br><span class="line">front-page  |[1,2,3]  |NULL         |   2|   |</span><br><span class="line">front-page  |[1,2,3]  |NULL         |   3|   |</span><br><span class="line">contact-page|[3,4,5]  |NULL         |   3|   |</span><br><span class="line">contact-page|[3,4,5]  |NULL         |   4|   |</span><br><span class="line">contact-page|[3,4,5]  |NULL         |   5|   |</span><br><span class="line">footer-page |[7,8,9]  |[700,800,900]|   7|700|</span><br><span class="line">footer-page |[7,8,9]  |[700,800,900]|   7|800|</span><br><span class="line">footer-page |[7,8,9]  |[700,800,900]|   7|900|</span><br><span class="line">footer-page |[7,8,9]  |[700,800,900]|   8|700|</span><br><span class="line">footer-page |[7,8,9]  |[700,800,900]|   8|800|</span><br><span class="line">footer-page |[7,8,9]  |[700,800,900]|   8|900|</span><br><span class="line">footer-page |[7,8,9]  |[700,800,900]|   9|700|</span><br><span class="line">footer-page |[7,8,9]  |[700,800,900]|   9|800|</span><br><span class="line">footer-page |[7,8,9]  |[700,800,900]|   9|900|</span><br><span class="line"> *&#x2F;</span><br></pre></td></tr></table></figure></li></ol>]]></content>
      
      
      <categories>
          
          <category> IT </category>
          
      </categories>
      
      
        <tags>
            
            <tag> bigdata </tag>
            
            <tag> hive </tag>
            
            <tag> lateral </tag>
            
            <tag> lateralview </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>259号文</title>
      <link href="/Payment/%E6%B3%95%E8%A7%84/rules-pboc-no259/"/>
      <url>/Payment/%E6%B3%95%E8%A7%84/rules-pboc-no259/</url>
      
        <content type="html"><![CDATA[<blockquote><p><a href="http://www.pbc.gov.cn/tiaofasi/144941/3581332/4359567/index.html" target="_blank" rel="noopener">259号文</a>是既21号之后针对终端再次补充，更加严格了，当然此次也针对了条码支付终端相关的要求。足以看出终端的重要性，也侧面反映了现在洗钱、涉黑涉黄等非法行为泛滥。</p><p>259号文是提纲挈领的法规，那么中国支付清算协会关于印发<a href="http://www.pcac.org.cn/eportal/ui?pageId=598041&articleKey=614091&columnId=595027" target="_blank" rel="noopener">《特约商户巡检指引》</a>的通知就针对特约商户明确了巡检的方式、周期、内容和频率等内容。</p></blockquote><a id="more"></a><h1 id="259号文"><a href="#259号文" class="headerlink" title="259号文"></a>259号文</h1><p>支付受理终端业务管理其大多数内容还是延续21号文，其总结起来就是<strong>1：1：1</strong>，即：</p><blockquote><p>一台银行卡受理终端对应一个终端序列号，对应一个特约商户</p></blockquote><p>条码支付受理终端及相关业务要求了 条码的场景和用途。</p><p>例如个人静态收款条码不可以远程非面对面收款，这个也有效扼制了现在微信支付宝之类的跑分等洗钱行为。</p>]]></content>
      
      
      <categories>
          
          <category> Payment </category>
          
          <category> 法规 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Payment </tag>
            
            <tag> 中国人民银行法规 </tag>
            
            <tag> 终端 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>docker jupyter nignix 400问题</title>
      <link href="/IT/Issues/it-issue-jupyter-nignix-400/"/>
      <url>/IT/Issues/it-issue-jupyter-nignix-400/</url>
      
        <content type="html"><![CDATA[<h1 id="jupyter-kernel一直连接不上服务器"><a href="#jupyter-kernel一直连接不上服务器" class="headerlink" title="jupyter kernel一直连接不上服务器"></a>jupyter kernel一直连接不上服务器</h1><blockquote><p> Docker上拉取了hortonworks/sandbox-hdp 和 hortonworks/sandbox-proxy, 在sandbox-hdp上安装了jupyter来写一些pyspark的代码。不过jupyter kernel一直连接不上服务器</p></blockquote><a id="more"></a><h2 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h2><p>其中sandbox-proxy做了如下配置</p><h3 id="HDP3-sandbox-proxy-conf-d-http-hdp-conf"><a href="#HDP3-sandbox-proxy-conf-d-http-hdp-conf" class="headerlink" title="HDP3/sandbox/proxy/conf.d/http-hdp.conf"></a>HDP3/sandbox/proxy/conf.d/http-hdp.conf</h3><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># jupyter notebook </span><br><span class="line">server &#123;</span><br><span class="line">  listen 9999;</span><br><span class="line">  server_name sandbox-hdp.hortonworks.com;</span><br><span class="line">  location / &#123;</span><br><span class="line">                proxy_pass http://sandbox-hdp:9999;</span><br><span class="line">                proxy_set_header      Host $host;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="HDP3-sandbox-proxy-proxy-deploy-sh"><a href="#HDP3-sandbox-proxy-proxy-deploy-sh" class="headerlink" title="HDP3/sandbox/proxy/proxy-deploy.sh"></a>HDP3/sandbox/proxy/proxy-deploy.sh</h3><p>新增一行-p 9999:9999 \</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">!/usr/bin/env bash</span><br><span class="line">docker rm -f sandbox-proxy 2&gt;/dev/null</span><br><span class="line">docker run --name sandbox-proxy --network=cda \</span><br><span class="line">-v /Users/arthur/Software/Docker/HDP3/assets/nginx.conf:/etc/nginx/nginx.conf \</span><br><span class="line">-v /Users/arthur/Software/Docker/HDP3/sandbox/proxy/conf.d:/etc/nginx/conf.d \</span><br><span class="line">-v /Users/arthur/Software/Docker/HDP3/sandbox/proxy/conf.stream.d:/etc/nginx/conf.stream.d \</span><br><span class="line">-p 1080:1080 \</span><br><span class="line">-p 9999:9999 \</span><br><span class="line">...</span><br></pre></td></tr></table></figure><h2 id="浏览器访问，jupyter后台错误日志"><a href="#浏览器访问，jupyter后台错误日志" class="headerlink" title="浏览器访问，jupyter后台错误日志"></a>浏览器访问，jupyter后台错误日志</h2><p>NotebookApp] 400 GET /api/kernels/</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">sh-4.2<span class="comment"># jupyter-notebook --allow-root</span></span><br><span class="line">[W 23:05:07.281 NotebookApp] Config option `use_redirect_file` not recognized by `NotebookApp`.</span><br><span class="line">[I 23:05:07.462 NotebookApp] Serving notebooks from <span class="built_in">local</span> directory: /root/notebook</span><br><span class="line">[I 23:05:07.462 NotebookApp] The Jupyter Notebook is running at:</span><br><span class="line">[I 23:05:07.462 NotebookApp] http://sandbox-hdp.hortonworks.com:9999/?token=9c46a4fbfa4a432be0275f2381cd24543ba763566c0cc8fe</span><br><span class="line">[I 23:05:07.462 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).</span><br><span class="line">[W 23:05:07.466 NotebookApp] No web browser found: could not locate runnable browser.</span><br><span class="line">[C 23:05:07.467 NotebookApp] </span><br><span class="line"></span><br><span class="line">    To access the notebook, open this file <span class="keyword">in</span> a browser:</span><br><span class="line">        file:///root/.<span class="built_in">local</span>/share/jupyter/runtime/nbserver-38953-open.html</span><br><span class="line">    Or copy and paste one of these URLs:</span><br><span class="line">        http://sandbox-hdp.hortonworks.com:9999/?token=9c46a4fbfa4a432be0275f2381cd24543ba763566c0cc8fe</span><br><span class="line">[E 23:05:14.835 NotebookApp] Could not open static file <span class="string">''</span></span><br><span class="line">[W 23:05:15.184 NotebookApp] 404 GET /static/components/react/react-dom.production.min.js (172.18.0.2) 14.91ms referer=http://sandbox-hdp.hortonworks.com:9999/notebooks/Untitled1.ipynb?kernel_name=python2</span><br><span class="line">[I 23:05:15.786 NotebookApp] Kernel started: eae1b42e-120e-4d69-9266-c06432677d5a</span><br><span class="line">[I 23:05:16.372 NotebookApp] Adapting to protocol v5.1 <span class="keyword">for</span> kernel eae1b42e-120e-4d69-9266-c06432677d5a</span><br><span class="line">[W 23:05:16.375 NotebookApp] 400 GET /api/kernels/eae1b42e-120e-4d69-9266-c06432677d5a/channels?session_id=0fea190ca5e94abd89500020f29a66fb (172.18.0.2) 521.39ms referer=None</span><br><span class="line">[W 23:05:17.437 NotebookApp] Replacing stale connection: eae1b42e-120e-4d69-9266-c06432677d5a:0fea190ca5e94abd89500020f29a66fb</span><br><span class="line">[W 23:05:18.140 NotebookApp] 404 GET /static/components/react/react-dom.production.min.js (172.18.0.2) 6.56ms referer=http://sandbox-hdp.hortonworks.com:9999/tree?token=9c46a4fbfa4a432be0275f2381cd24543ba763566c0cc8fe</span><br><span class="line">[W 23:05:20.220 NotebookApp] 404 GET /static/components/react/react-dom.production.min.js (172.18.0.2) 4.17ms referer=http://sandbox-hdp.hortonworks.com:9999/notebooks/Untitled1.ipynb</span><br><span class="line">[I 23:05:20.443 NotebookApp] Adapting to protocol v5.1 <span class="keyword">for</span> kernel eae1b42e-120e-4d69-9266-c06432677d5a</span><br><span class="line">[W 23:05:20.444 NotebookApp] 400 GET /api/kernels/eae1b42e-120e-4d69-9266-c06432677d5a/channels?session_id=ed975e0dfee44503a3a2405dac3718cc (172.18.0.2) 3.54ms referer=None</span><br><span class="line">[W 23:05:21.516 NotebookApp] Replacing stale connection: eae1b42e-120e-4d69-9266-c06432677d5a:ed975e0dfee44503a3a2405dac3718cc</span><br><span class="line">[W 23:06:23.550 NotebookApp] Replacing stale connection: eae1b42e-120e-4d69-9266-c06432677d5a:ed975e0dfee44503a3a2405dac3718cc</span><br></pre></td></tr></table></figure><h2 id="解决方式"><a href="#解决方式" class="headerlink" title="解决方式"></a>解决方式</h2><p><a href="https://www.cnblogs.com/ycc1/p/14229534.html" target="_blank" rel="noopener">Virya的博客</a></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># jupyter notebook</span></span><br><span class="line">server &#123;</span><br><span class="line">  listen 9999;</span><br><span class="line">  server_name sandbox-hdp.hortonworks.com;</span><br><span class="line">  location / &#123;</span><br><span class="line">                proxy_pass http://sandbox-hdp:9999;</span><br><span class="line">                proxy_set_header      Host <span class="variable">$host</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  location ~ /api/kernels/ &#123;</span><br><span class="line">                proxy_pass            http://sandbox-hdp:9999;</span><br><span class="line">                proxy_set_header      Host <span class="variable">$host</span>;</span><br><span class="line"></span><br><span class="line">                proxy_http_version    1.1;  <span class="comment"># websocket support</span></span><br><span class="line">                proxy_set_header      Upgrade <span class="string">"websocket"</span>;</span><br><span class="line">                proxy_set_header      Connection <span class="string">"Upgrade"</span>;</span><br><span class="line">                proxy_read_timeout    86400;</span><br><span class="line">        &#125;</span><br><span class="line">  location ~ /terminals/ &#123;</span><br><span class="line">                proxy_pass            http://sandbox-hdp:9999;</span><br><span class="line">                proxy_set_header      Host <span class="variable">$host</span>;</span><br><span class="line"></span><br><span class="line">                proxy_http_version    1.1;  <span class="comment"># websocket support</span></span><br><span class="line">                proxy_set_header      Upgrade <span class="string">"websocket"</span>;</span><br><span class="line">                proxy_set_header      Connection <span class="string">"Upgrade"</span>;</span><br><span class="line">                proxy_read_timeout    86400;</span><br><span class="line">        &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> IT </category>
          
          <category> Issues </category>
          
      </categories>
      
      
        <tags>
            
            <tag> jupyter </tag>
            
            <tag> nginx </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>TLS 模式</title>
      <link href="/uncategorized/tls-mode/"/>
      <url>/uncategorized/tls-mode/</url>
      
        <content type="html"><![CDATA[<h1 id="TLS模式"><a href="#TLS模式" class="headerlink" title="TLS模式"></a>TLS模式</h1><p>有三种模式，见下图</p><ol><li><p>客户端直接忽略TLS证书访问服务</p><p>例如使用curl -k -tlsv1 等参数可以忽略证书验证直接访问。即客户端不检查证书的有效性和合法性。即此时，客户端不检查服务端的网址合法性和有效性，同时网络传输也是明文。</p></li><li><p>客户端使用TLS证书访问服务</p><p>此场景是最常见的，即客户端需要检查服务端证书的合法性和有效性，传输也是加密的。</p></li><li><p>双向认证</p><p>此时除了服务端证书需要提供给客户端，同时客户端的证书需要添加到服务端。登录时，可以直接使用证书验证直接登录。另外，例如U盾等也是双向认证的应用</p></li></ol><p><img src="/uncategorized/tls-mode/tls.jpg" alt="tls"></p>]]></content>
      
      
      
        <tags>
            
            <tag> IT </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>云闪付</title>
      <link href="/Payment/payment-yunshanfu/"/>
      <url>/Payment/payment-yunshanfu/</url>
      
        <content type="html"><![CDATA[<h1 id="云闪付"><a href="#云闪付" class="headerlink" title="云闪付"></a>云闪付</h1><p>没错，就是你想的那个云闪付。千人千面，今天我要从卡组织的角度来看。</p><p>银联大力推广，所以云闪付涉及方方面面。</p><a id="more"></a><h2 id="付的世界"><a href="#付的世界" class="headerlink" title="付的世界"></a>付的世界</h2><h3 id="便民服务"><a href="#便民服务" class="headerlink" title="便民服务"></a>便民服务</h3><p>乘车码、公共缴费、健康码、手机充值等</p><p>国庆期间，我去杭州西湖玩，地铁入口看到提示，可以使用云闪付和支付宝乘坐地铁；本着云闪付也是我支付软件后宫佳丽之一，今天就翻她牌了；众所周知，杭州基本上是支付宝的天下，到深圳是微信的天下，坐过城市交通的深深的体会到地方城市的溺爱。关键她以国家队的形式打破了地方城市的保护；关键操作非常简单而且还打9折优惠，爱了爱了。</p><h3 id="财富管理"><a href="#财富管理" class="headerlink" title="财富管理"></a>财富管理</h3><p>信用卡还款、转账、借款、申请信用卡等</p><p>信用卡还款免手续费！支付宝或者微信还信用卡从免费到收费，广大<strong>打工人</strong>表示马爸爸你变了。</p><h3 id="政务民生"><a href="#政务民生" class="headerlink" title="政务民生"></a>政务民生</h3><p>我的社保、我的医保、税款缴纳、交通罚款等</p><p>税款缴纳竟然可以使用信用卡！这个出乎意料。</p><h3 id="购物娱乐"><a href="#购物娱乐" class="headerlink" title="购物娱乐"></a>购物娱乐</h3><p>商城、数字景区等</p><p>数字景区买门票有优惠的。</p><h3 id="境外服务"><a href="#境外服务" class="headerlink" title="境外服务"></a>境外服务</h3><p>境外海淘、境外退税、权益U赏等</p><p>这个大类里的服务点击时有Error，测试人员的鸡腿没有了吧。</p><h3 id="第三方服务"><a href="#第三方服务" class="headerlink" title="第三方服务"></a>第三方服务</h3><p>租房、猫眼电影、淘车位等</p><h2 id="角色扮演"><a href="#角色扮演" class="headerlink" title="角色扮演"></a>角色扮演</h2><p>云闪付出自银联，银联做为卡组织；单纯从卡组织的角色来看，其云闪付的定位是非常契合的。</p><p>因为卡组织有服务、协调，自律以及监督等功能；这里就只从服务角度来看，就需要集发卡、收单、商户和持卡人于一体，满足各方一部分需求，平衡各方的利益点，以共荣为目的，在一个平台上提供服务。</p><p>所以从战略方向来看，前途一片光明。可是，云闪付却干了收单的事，这个平台就不再是拧成一股绳,搏尽一份力,狠下一条心,共圆一个梦的那个平台了。</p><h2 id="世事造化"><a href="#世事造化" class="headerlink" title="世事造化"></a>世事造化</h2><p>现在支付行业环境再也不是从前了。</p><h4 id="拉新"><a href="#拉新" class="headerlink" title="拉新"></a>拉新</h4><p>以前获取一个新用户的成本非常低的；但是现在获取一个新用户的成本比较高了，你看支付宝为了获取一个为了获取新用户，给老用户的推荐奖是20元的电话费。而且从现在的互联网用户总量来看，市场差不多快饱和了。</p><h4 id="用户量为王"><a href="#用户量为王" class="headerlink" title="用户量为王"></a>用户量为王</h4><p>谁的用户量大，谁就了不得，谁就话语权就大，得用户者得天下；甚至连监管都要考虑三分，有种三国时代的携天子而以令诸侯。</p><h4 id="互联网时代"><a href="#互联网时代" class="headerlink" title="互联网时代"></a>互联网时代</h4><p>而且现在互联网的世界是不再是4321，即龙头老大老二的市场份额占比基本上是70%左右，其它的基本上还能吃饱饭。而现在第三方支付的市场份额的90%多被龙头老大老二占了，所以除了微信支付宝，剩余的就只能叫做其它了；关键是老大老二利用行业领头优势，全面围杀竞争者的反击；最后，互联网的时代是一个变化万千的时代，是一个瞬息万变的时代，是一个与监管相爱相杀的时代；很多时候，行业龙头老大老二为了抢占市场，面子上对监管服服帖帖的，背后依旧干些偷偷摸摸的事，因为惩罚的成本与其利润相比显得微不足道。</p><h4 id="卡基过渡到帐基"><a href="#卡基过渡到帐基" class="headerlink" title="卡基过渡到帐基"></a>卡基过渡到帐基</h4><p>以前基本上是卡基支付，而现在是帐户支付的时代；卡基变成了帐基的基石，上层应用更多围绕着帐户来构建丰富的生态和应用场景。</p><p>所以内因加外因，这也是为什么银联投资和市场占比来看有点不成正比的主要原因。</p><h2 id="异军突起"><a href="#异军突起" class="headerlink" title="异军突起"></a>异军突起</h2><p>国家队的云闪付这几年的大力推广，效果虽然不是那么显著，但是起色还是不错的。如果要突破，本人的愚见还是回归支付本质和卡组织的本质。深耕支付场景，广惠各个实体，互助共荣不称霸。</p>]]></content>
      
      
      <categories>
          
          <category> Payment </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Payment </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>国家发展改革委 中国人民银行关于完善银行卡刷卡手续费定价机制的通知</title>
      <link href="/Payment/%E6%B3%95%E8%A7%84/rules-pboc-96fees/"/>
      <url>/Payment/%E6%B3%95%E8%A7%84/rules-pboc-96fees/</url>
      
        <content type="html"><![CDATA[<blockquote><p> <a href="http://www.pbc.gov.cn/goutongjiaoliu/113456/113469/3034338/index.html" target="_blank" rel="noopener">国家发展改革委 中国人民银行 关于完善银行卡刷卡手续费定价机制的通知</a> 俗称96费改，是因为从2016年9月6日起实施的。有此宝典，如同如来佛祖的手掌，各种费率都逃不出手掌心。</p></blockquote><a id="more"></a>]]></content>
      
      
      <categories>
          
          <category> Payment </category>
          
          <category> 法规 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Payment </tag>
            
            <tag> 中国人民银行法规 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>清算架构</title>
      <link href="/Payment/payment-clearing-architecture/"/>
      <url>/Payment/payment-clearing-architecture/</url>
      
        <content type="html"><![CDATA[<blockquote><p>这里只是我根据央行发布的支付体系运行总体情况报告整理得来的信息，对一些系统或者周边系统还没有深入了解到。</p></blockquote><a id="more"></a><p><img src="/Payment/payment-clearing-architecture/%E6%94%AF%E4%BB%98%E7%B3%BB%E7%BB%9F.png" alt="支付系统信息"></p><blockquote><p>CIPS 是人民币国际化的重要部分</p><p>其他清算系统也有美国运通一个位置了，因为美国运通也拿到清算牌照，正式营业了。</p></blockquote><p><img src="/Payment/payment-clearing-architecture/%E6%B8%85%E7%AE%97%E6%9C%BA%E6%9E%84%E6%9E%B6%E6%9E%84.png" alt="&#39;架构&#39;"></p><p>这里这么多清算机构，是不是都懵圈了？ 在开始之前，先铺垫一点基础术语：</p><ul><li><p>实时</p><p>每一笔交易都实时处理，即来一笔交易就处理一笔。</p></li><li><p>批量</p><p>交易累积一段时间做处理。例如，累积一天做处理的叫做99批次；累积半天做处理的叫做13批次[13点]和23批次[23点]；还有每小时累积一次，那全天一共24个批次了。</p></li></ul><p>现在简单概述一下央行的这四个主要的清算系统。</p><h2 id="央行四大支付系统"><a href="#央行四大支付系统" class="headerlink" title="央行四大支付系统"></a>央行四大支付系统</h2><h3 id="大额实时支付系统"><a href="#大额实时支付系统" class="headerlink" title="大额实时支付系统"></a>大额实时支付系统</h3><p>大额是实时处理交易的；</p><p>金融机构都会在央行大额支付系统里开立清算账户，然后其他清算系统基本上会在清算的批次时调用央行大额支付将钱从各个金融机构的清算账户上划付。</p><blockquote><p>另外，不要被名称中的大额给误导了，因为大额支付系统的金额起点为0。也就是说，1毛钱的生意也可以使用大额。</p></blockquote><h3 id="小额批量支付系统"><a href="#小额批量支付系统" class="headerlink" title="小额批量支付系统"></a>小额批量支付系统</h3><p>小额是批量处理交易的；</p><p>主要是定位零售的，其实和美国的ACH [ <a href="https://baike.baidu.com/item/自动清算所系统/6889060?fr=aladdin" target="_blank" rel="noopener">Automated Clearing House</a>]类似，一些什么代发工资，代收水电煤气之类的缴费等等；</p><p>是有金额上限限制的。</p><h3 id="网上支付跨行清算系统"><a href="#网上支付跨行清算系统" class="headerlink" title="网上支付跨行清算系统"></a>网上支付跨行清算系统</h3><p>这个也叫做超级网银</p><p>银行网银就是使用的这个系统。</p><h3 id="境内外币支付系统"><a href="#境内外币支付系统" class="headerlink" title="境内外币支付系统"></a>境内外币支付系统</h3><p>这个满足国内对外币的需求，例如我们兑换美元，可以预约去中国银行兑换。</p><h2 id="清算系统"><a href="#清算系统" class="headerlink" title="清算系统"></a>清算系统</h2><h3 id="人民币跨境支付系统"><a href="#人民币跨境支付系统" class="headerlink" title="人民币跨境支付系统"></a>人民币跨境支付系统</h3><p>这个和境内外币支付系统恰恰相反，其用来国外满足人民币的清算。这个是人民币走出去的关键一步。</p><h3 id="城银清-amp-农信银"><a href="#城银清-amp-农信银" class="headerlink" title="城银清 &amp; 农信银"></a>城银清 &amp; 农信银</h3><p>这两个一个是为城市商业银行做清算的，一个是为农村合作信用社做清算的。</p><h3 id="银行卡跨行支付系统"><a href="#银行卡跨行支付系统" class="headerlink" title="银行卡跨行支付系统"></a>银行卡跨行支付系统</h3><p>这个是银行卡跨行支付的系统，即参与方是多家不同的金融机构，也称之为本代他</p><p>一般银行系统是不能直接处理其它银行的交易的，其中主要原因有两个方面，以A银行和B银行为例</p><ol><li><p>处理交易协议不同</p><p>A银行发行的卡其处理逻辑基本上大体上是按照标准来的，例如ISO8583；但是，还有一些自定义的地方或者各家支持的业务也有所不同，各个银行实现是不同的，所以会导致处理失败。</p></li><li><p>资金积压严重</p><p>及时第一点不是一个障碍，那么A银行发行的卡在B银行取款，那么为什么B银行要把钱给卡持有者呢？那么A就得在B银行开户，在B银行的账户上存钱，其钱叫做头寸。如果有10家机构或者100家机构或者更多呢？正如当时支付宝等支付机构在630‘断直连’之前都是一样的。所以会导致很多资金都在各个金融机构的账户里存着，白白浪费了资金的流动性。</p></li></ol><p>解决上述两个方面的问题，有什么方案呢？现在通用的方案是</p><ul><li><p>同一种通信协议或者规范</p><p>卡组织就是来做这个事情的，卡组织制定统一的规范，同时开发各种支付产品等等；这样大家就使用同一种通信规范，基本上可以跨越不同银行，做交易往来了。</p></li><li><p>在央行统一开立清算账户</p><p>这样央行开立一个清算账户，里面存上钱，供资金划付使用。如果金融机构在账户里存的钱不够，可以同行拆借等等；这样就不用在各个金融机构里开立账户。</p></li></ul><p>好了，银行卡跨行支付系统就是做这个事情的。</p><h3 id="网联清算系统"><a href="#网联清算系统" class="headerlink" title="网联清算系统"></a>网联清算系统</h3><p>这个清算系统有点特殊，因为它的出现，网上有很多马云与银联故事。其实网上支付现在不一定是全部通过它的，其实也可以通过银联等跨行支付系统的；后面再详细讲讲它的业务类型。</p>]]></content>
      
      
      <categories>
          
          <category> Payment </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Payment </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>非金融机构支付服务管理办法</title>
      <link href="/Payment/%E6%B3%95%E8%A7%84/rules-pboc-no2-201006/"/>
      <url>/Payment/%E6%B3%95%E8%A7%84/rules-pboc-no2-201006/</url>
      
        <content type="html"><![CDATA[<blockquote><p>2010年6月份央行发布了 <a href="http://www.pbc.gov.cn/tiaofasi/144941/144957/2845832/index.html" target="_blank" rel="noopener"> 中国人民银行令〔2010〕第2号（非金融机构支付服务管理办法）</a>（以下简称2号令）开启了第三方支付的合法性，从此第三方支付群雄逐鹿，单支付牌照就一度炒到几亿</p></blockquote><a id="more"></a><p>2号令规定了，支付机构需要取得《支付业务许可证》才是合法的，已经从事支付业务的非金融机构在一年以内完成申请；所以从<strong>已获许可机构（支付机构）</strong>名单里看到的机构的开始生效时间基本都是2011年5月份，包括银联商务，支付宝，财付通等等。下面我们来看看其内容：</p><h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><p>规范非金融机构支付服务行为，防范支付风险。</p><h2 id="非金融机构支付服务种类"><a href="#非金融机构支付服务种类" class="headerlink" title="非金融机构支付服务种类"></a>非金融机构支付服务种类</h2><ul><li><p>网络支付</p><p>互联网支付，移动电话支付，固话支付，数字电视支付等等，例如微信支付宝，电话购物等</p></li><li><p>预付卡的发行与受理</p><p>例如你去理发店，Tony老师总是推荐你办张卡。当然这个卡不是理发店能够发行的，而是需要有预付卡的发行与受理的支付公司给理发店定制的。</p></li><li><p>银行卡收单</p><p>POS终端等收单</p></li><li><p>其他支付服务</p></li></ul><h2 id="义务"><a href="#义务" class="headerlink" title="义务"></a>义务</h2><ul><li>依法接受央行的监督管理</li><li>履行发洗钱</li><li>不得损害国家利益、社会公共利益和客户合法权益</li></ul><h2 id="申请资质"><a href="#申请资质" class="headerlink" title="申请资质"></a>申请资质</h2><p>略</p>]]></content>
      
      
      <categories>
          
          <category> Payment </category>
          
          <category> 法规 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Payment </tag>
            
            <tag> 中国人民银行法规 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>中国人民银行关于加强支付受理终端及相关业务管理的通知（征求意见稿）</title>
      <link href="/Payment/%E6%B3%95%E8%A7%84/rules-pboc-terminal-202006/"/>
      <url>/Payment/%E6%B3%95%E8%A7%84/rules-pboc-terminal-202006/</url>
      
        <content type="html"><![CDATA[<blockquote><p><a href="http://www.pbc.gov.cn/tiaofasi/144941/144979/3941920/4035719/index.html" target="_blank" rel="noopener">《中国人民银行关于加强支付受理终端及相关业务管理的通知（征求意见稿）》</a> 是既 <a href="/Payment/法规/rules-pboc-no21/index.html">21号文 </a> 之后，又一部关于支付受理终端的法规。</p></blockquote><a id="more"></a><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><h3 id="终端问题"><a href="#终端问题" class="headerlink" title="终端问题"></a>终端问题</h3><p>现象</p><ul><li>买卖终端</li><li>移机</li><li>一机多码</li><li>一机多户</li><li>…..</li></ul><p>严重性</p><ul><li>为违法犯罪分子进行资金转移带来便利</li></ul><h3 id="特约商户问题"><a href="#特约商户问题" class="headerlink" title="特约商户问题"></a>特约商户问题</h3><p>现象</p><ul><li>准入不严格</li><li>核实流于形式</li></ul><p>严重性</p><ul><li>虚假商户问题任然突出</li></ul><h3 id="条码支付问题"><a href="#条码支付问题" class="headerlink" title="条码支付问题"></a>条码支付问题</h3><p>现象</p><ul><li>没有健全条码支付终端、收单条码管理机制</li></ul><p>严重性</p><ul><li>导致条码支付业务涉黑灰产的风险加大</li></ul><h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><ul><li>规范收单等业务管理</li><li>打击跨境赌博、电信诈骗等违法犯罪活动</li><li>切断黑灰产业资金链</li><li>保障社会公众利益</li></ul><h2 id="整治方向"><a href="#整治方向" class="headerlink" title="整治方向"></a>整治方向</h2><h3 id="支付受理终端管理"><a href="#支付受理终端管理" class="headerlink" title="支付受理终端管理"></a>支付受理终端管理</h3><ul><li><p>银行卡受理终端</p><p><img src="/Payment/%E6%B3%95%E8%A7%84/rules-pboc-terminal-202006/Terminal_202006_Card.png" alt></p><blockquote><p>F -  终端生产厂商  - 深蓝青色<br>A - 收单机构 - 橘色<br>C -  清算机构 - 蓝色<br>五要素： 收单机构代码、特约商户编码、特约商户统一社会信用代码（小微商户为负责人身份证件号码）、特约商户收单结算账户、银行卡受理终端布放地址</p></blockquote></li><li><p>条码支付受理终端</p><ul><li><p>受理终端</p><p>终端序列号与五要素</p></li><li><p>辅助受理终端</p><p>四要素</p></li><li><p>收款条码</p><p>区分个人和特约商户</p></li></ul><blockquote><p>四要素： 收单机构代码、特约商户统一社会信用代码、特约商户收单结算账户和特约商户经营地址</p></blockquote></li><li><p>创新支付受理终端</p><p>至少提前30日向中国人民银行及其分支机构报告</p></li></ul><h3 id="特约商户管理"><a href="#特约商户管理" class="headerlink" title="特约商户管理"></a>特约商户管理</h3><ul><li>特约商户实名制</li><li>明确商户信息核验方式<ul><li>面对面</li><li>同步视频</li></ul></li><li>特约商户巡检要求</li></ul><h3 id="收单业务监测"><a href="#收单业务监测" class="headerlink" title="收单业务监测"></a>收单业务监测</h3><ul><li>交易信息的真实性和完整性</li><li>终端位置监测</li><li>特约商户资金结算监测</li><li>专项监测与信息核对<ul><li>边境地区</li><li>核对交易信息和五要素不一致的</li></ul></li></ul><h3 id="监督管理等相关内容"><a href="#监督管理等相关内容" class="headerlink" title="监督管理等相关内容"></a>监督管理等相关内容</h3><ul><li>相关市场主体报送落实情况和工作计划</li><li>明确对银行、支付机构、清算机构的违反行为相关罚则</li></ul><h2 id="解读"><a href="#解读" class="headerlink" title="解读"></a>解读</h2><p>该条法主要是解决：打击跨境赌博、电信诈骗等违法犯罪活动，切断黑灰产业资金链；相关的跨境赌博新闻可以参考：<a href="http://www.cyberpolice.cn/wfjb/html/zcjd/20200701/4739.shtml" target="_blank" rel="noopener">http://www.cyberpolice.cn/wfjb/html/zcjd/20200701/4739.shtml</a></p><p>现如今的条码支付或者叫二维码大家更熟知，大家的微信或者支付宝的二维码是有付款功能的，所以很多跑分平台（码商）利用大量个人收款条码来化整为零，从而给监管带来很大的难度。大概的操作流程请看下图；其资金的流向从原来原来的客户到支付机构的流向，转化为客户向客户C2C的流向了；</p><p><img src="/Payment/%E6%B3%95%E8%A7%84/rules-pboc-terminal-202006/%E8%B7%91%E5%88%86.png" alt="跑分平台与赌博平台"></p>]]></content>
      
      
      <categories>
          
          <category> Payment </category>
          
          <category> 法规 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Payment </tag>
            
            <tag> 中国人民银行法规 </tag>
            
            <tag> 终端 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>21号文</title>
      <link href="/Payment/%E6%B3%95%E8%A7%84/rules-pboc-no21/"/>
      <url>/Payment/%E6%B3%95%E8%A7%84/rules-pboc-no21/</url>
      
        <content type="html"><![CDATA[<blockquote><p>缩写或简称泛滥的地方，非金融莫属了。21号文的全称是：中国人民银行关于强化银行卡受理终端安全管理的通知（银发〔2017〕21号）；看完觉得还是21号文更好交流。该规范规范了银行卡受理终端。</p></blockquote><a id="more"></a><h2 id="规范"><a href="#规范" class="headerlink" title="规范"></a>规范</h2><p><a href="http://www.pbc.gov.cn/tiaofasi/144941/3581332/3589575/index.html" target="_blank" rel="noopener">21号文</a></p><h3 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h3><ul><li>加强终端安全管理</li><li>提升支付风险防控管理</li><li>防范电信网络诈骗以及伪卡欺诈</li><li>切实保护人民群众的财产安全和合法权益</li></ul><h3 id="措施"><a href="#措施" class="headerlink" title="措施"></a>措施</h3><h4 id="交易报文"><a href="#交易报文" class="headerlink" title="交易报文"></a>交易报文</h4><p>交易报文在下面的场景中需要包含必需的内容</p><table><thead><tr><th></th><th>ATM</th><th>POS</th></tr></thead><tbody><tr><td>本代本</td><td>- 终端代码</td><td>- 受理机构编码<br>- 商户编码<br>- 终端编码<br>- 终端序列号<br>- 终端应用版本编号</td></tr><tr><td>本代他</td><td>- 受理机构编码<br>- 终端编码</td><td>同上</td></tr></tbody></table><h4 id="受理终端注册管理"><a href="#受理终端注册管理" class="headerlink" title="受理终端注册管理"></a>受理终端注册管理</h4><h5 id="管理平台"><a href="#管理平台" class="headerlink" title="管理平台"></a>管理平台</h5><p>清算机构搭建受理终端注册管理平台，商业银行或者支付机构在其管理平台上注册终端信息。</p><h5 id="注册数据规范"><a href="#注册数据规范" class="headerlink" title="注册数据规范"></a>注册数据规范</h5><p>同步文件即商业银行或者支付机构在管理平台上的提交的终端信息文件，反馈文件即管理平台反馈给注册方的信息文件，主要包括了概要统计信息，例如总条数，成功条数，拒绝条数；如果有拒绝记录，则包括了拒绝记录的原始记录及其拒绝原因。</p><p>POS终端是需要商户信息的，因为POS是商户收单的机具。</p><table><thead><tr><th>ATM</th><th>POS</th></tr></thead><tbody><tr><td>ATM终端注册同步文件<br>ATM终端注册反馈文件</td><td>POS终端注册同步文件<br>POS终端注册反馈文件</td></tr><tr><td></td><td>商户注册同步文件<br>商户注册反馈文件</td></tr></tbody></table><h5 id="时间要求"><a href="#时间要求" class="headerlink" title="时间要求"></a>时间要求</h5><ul><li>新入网ATM终端至少于布放或变更前一个工作日完成终端信息注册</li><li>新入网POS终端至少于布放或变更后两个工作日完成终端信息注册</li></ul><h4 id="终端产品质量管理"><a href="#终端产品质量管理" class="headerlink" title="终端产品质量管理"></a>终端产品质量管理</h4><p>终端产品需要符合国家标准和金融行业标准</p><h4 id="受理终端支付风险防控"><a href="#受理终端支付风险防控" class="headerlink" title="受理终端支付风险防控"></a>受理终端支付风险防控</h4><ul><li>信息校验</li><li>风险监控</li><li>联动防控</li><li>密钥管理</li></ul><h2 id="解读"><a href="#解读" class="headerlink" title="解读"></a>解读</h2><p>该条法更多在于解决： 防范电信网络诈骗以及伪卡欺诈 ，因为近10年电信诈骗特别猖狂且疯狂增长，可以参考 <a href="https://www.sohu.com/a/114330177_454426/" target="_blank" rel="noopener">https://www.sohu.com/a/114330177_454426/</a> ；伪卡欺诈，可以参考：<a href="https://www.sohu.com/a/146377196_120702" target="_blank" rel="noopener">https://www.sohu.com/a/146377196_120702</a></p><p>同时参考银联最近的数据，伪卡欺诈依旧是主要的欺诈，不过非面对面欺诈呈逐年递增势头。</p>]]></content>
      
      
      <categories>
          
          <category> Payment </category>
          
          <category> 法规 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Payment </tag>
            
            <tag> 中国人民银行法规 </tag>
            
            <tag> 终端 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>银行卡清算机构管理办法</title>
      <link href="/Payment/%E6%B3%95%E8%A7%84/rules-pboc-clearing/"/>
      <url>/Payment/%E6%B3%95%E8%A7%84/rules-pboc-clearing/</url>
      
        <content type="html"><![CDATA[<blockquote><p>法律法规枯燥之中又妙趣横生；因为它定义了规则。</p><p>《银行卡清算机构管理办法》对很多人支付行业的从业人员都无关紧要，因为它是清算机构而且基本是高层需要关心的。对于像鄙人这样的一个小螺丝钉，读一下此法规，虽然理解不是很透切，只能说对公司的启动以及运营等有个粗略的了解。</p></blockquote><a id="more"></a><p><a href="http://www.pbc.gov.cn/goutongjiaoliu/113456/113469/3077866/index.html" target="_blank" rel="noopener">银行卡清算机构管理办法</a></p><p><img src="/Payment/%E6%B3%95%E8%A7%84/rules-pboc-clearing/rules_pboc_clearing_mindmap.svg" alt="脑图"></p><p>所以最慢成功的批准开业周期是1年7个月（30d + 90d + 1y + 90d），那最完美的最快速的批准开业周期就很难说了，一年算是好的了，因为一个清算交易系统以及相关的核心系统在一年内搞定可能也算是丰功伟绩了，更不用说搞定各种监管要求。</p>]]></content>
      
      
      <categories>
          
          <category> Payment </category>
          
          <category> 法规 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Payment </tag>
            
            <tag> 中国人民银行法规 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Informatica退出中国大陆市场</title>
      <link href="/%E9%9D%99%E5%A4%9C%E6%80%9D/thinking-infa-withdrawal/"/>
      <url>/%E9%9D%99%E5%A4%9C%E6%80%9D/thinking-infa-withdrawal/</url>
      
        <content type="html"><![CDATA[<blockquote><p>2020年好像开年不利，各种灾难接踵而至，例如全球新型冠状病毒肺炎，洪灾等；而最近听朋友说Informatica退出中国大陆市场，有点震惊，不管什么原因，终究是有些无奈与无力。</p></blockquote><a id="more"></a><p>我是从Informatica出来的，来Informatica工作也开启了我的上海之旅，而且在Informatica结识了很多的国内国外和港澳台朋友，Informatica的<strong>INFAmily</strong>文化是成功的，不仅仅是员工有归属感，而且员工的家人也有归属感；因为公司从来没有忘记背后支持员工的家属，家属的医疗保险和员工是一样的，而且非常非常好；每次员工生日有蛋糕一起庆祝，员工家属生日有购物卡；而且每年GC Kickoff meeting是给家属也考虑进去的，前面几天员工开会，员工家属就去当地旅游，后面大家一起活动；关键是家里有喜事等，公司都有礼物准备。真的非常人性化的文化。</p><p>很多人会问，为什么如此之好的福利，还是有人会离职，例如我自己。其实每个人都有自己的职业规划，如果你想去外面闯荡，Informatica也是祝福你的，因为你出去了，只会扩大Informatica的影响力。这个是我提出离职时，某位老板告诉我的，让我不用有任何心理负担。</p><p>有人问，如果Informatica退出中国大陆市场，对我们离职的人或者即将被离职的人来说有什么影响；影响肯定是有的，但是不会是很大的，因为Informatica招聘进来的人都是各行各业的行家，大家都不是完全依赖于工具了，都有一套自己的思想和快速学习适应变化的能力，这就是每个人的核心竞争力；换一个跑道，依然可以适应和胜任。</p><p>最后，我知道还在Informatica里的大陆同事现在很难过，还在消化。但是我相信你们是最棒的，在新的事业里前途似锦，万事如意！</p>]]></content>
      
      
      <categories>
          
          <category> 静夜思 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 静夜思 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ATM取款</title>
      <link href="/Payment/payment-trading-scenario/"/>
      <url>/Payment/payment-trading-scenario/</url>
      
        <content type="html"><![CDATA[<blockquote><p>如果要使用现金，则需要将钱从卡中取出来，当然，取钱的途径很多， 例如1. 从柜台取钱； 2. 从ATM取钱；3.转账给他人，他人给现金给你；4. 去商户消费，然后商户给你现金。这里只讨论第2点。</p></blockquote><a id="more"></a><h2 id="两种场景"><a href="#两种场景" class="headerlink" title="两种场景"></a>两种场景</h2><h3 id="不跨行"><a href="#不跨行" class="headerlink" title="不跨行"></a>不跨行</h3><p>A银行的卡在A银行自己的ATM上取款</p><p>不跨行的情况，该笔ATM取款交易不需要经过卡组织的，直接是该银行自己处理。 有些有银行在有些场景也会收取手续费。例如，上海办理的卡，到广州的ATM取款就会收取手续费。</p><h3 id="跨行"><a href="#跨行" class="headerlink" title="跨行"></a>跨行</h3><p>A银行的卡在B银行的ATM上取款</p><p>因为涉及到跨行交易，那么资金需要经过卡组织进行批量清算，因此卡组织需要收取清算费，收单行需要收取交换费。</p><h2 id="交易流程"><a href="#交易流程" class="headerlink" title="交易流程"></a>交易流程</h2><p>这里以跨行的场景为例，A银行就是发卡行（Issuer），B银行就是收单行（Acquirer)，这里以取款1000元为例。</p><ol><li>B - ATM 向 卡组织 发起请求</li><li>卡组织将请求转发给A</li><li>A将请求信息回复给卡组织</li><li>卡组织将信息回复给B-ATM</li></ol><p>如果上述4步种任何一方出现了中断，例如第4步中，卡组织无法连接到B-ATM，无法将信息回复给B，那么卡组织这里会发起冲正交易；冲正交易会将原交易给冲正了，不会出现说你钱没有取到，但是卡里已经扣了的情况。</p><h2 id="交易数据分析"><a href="#交易数据分析" class="headerlink" title="交易数据分析"></a>交易数据分析</h2><h3 id="交易文件类型"><a href="#交易文件类型" class="headerlink" title="交易文件类型"></a>交易文件类型</h3><p>ATM取款这种交易会出现在COM类文件中，例如OOM/COMN。同时，同一笔交易，卡组织会生产两个文件：ICOM和ACOM，这两个文件大部分相同，部分不同，ICOM给银行A，ACOM给银行B。</p><p>所以区分一个文件到底是给收单机构还是给发卡机构，可以从交易文件的文件名上直接判断。 如果没有文件名的情况下，如何判断ATM取款数据到底是发卡机构还是收单机构的呢？</p><p>答案是可以的，1） 根据交易类型，以及Fee（费）的借贷标志; 2）如果是COMN类型的，可以直接看扩展字段，有些字段是发卡方文件独有的，例如商户名称以及Token；有些字段是收单方文件所独有的，例如订单号，当然，不是所有支付场景，扩展字段中独有字段都有值。</p><p>第1种情况，针对ATM取现，交换费（Fee1）和转接清算费（Fee2）的借贷记标志，对于发卡行，它需要支付这两个费用给卡组织和收单行，所以对于这两个Fee的借贷记标志是D。但是对于收单机构，则没有该费用。</p><h3 id="交易类型"><a href="#交易类型" class="headerlink" title="交易类型"></a>交易类型</h3><p>如果从交易数据中判断该笔交易为ATM取款，那从哪些维度可以来确定呢？</p><ol><li>终端类型（Terminal Type) 如果是ATM取款，那么终端类型应该是ATM  <!-- 01 -->;</li><li>交易类型 交易处理码中前两位是交易类型为现金 <!-- 01 -->；</li><li>交易的报文类型 从报文类型标识符来看该笔交易的报文类型为请求类交易：0200，而不是ATM取款发生冲正的时候冲正类交易：0420。</li><li>服务点条件码 是交易处理码（第2点）的补充，其值应该是自助终端 <!-- 02 -->。</li></ol><p>综上，从这4个维度就可以将一笔交易确定为ATM取款。当然，如果商户类型代码存在，或者准确，那么可以直接使用商户类型代码来确定也是可以的。</p><h2 id="费用划付"><a href="#费用划付" class="headerlink" title="费用划付"></a>费用划付</h2><p>ATM取现的费用，由发卡机构支付。即：</p><ol><li>收单机构收取交换费；</li><li>卡组织收取转接清算费。</li></ol><h2 id="一点思考"><a href="#一点思考" class="headerlink" title="一点思考"></a>一点思考</h2><p>一般来说，一张卡整存整取，卡内不留余额等情况可能参与了洗钱活动；可以看<strong>《反腐风云》</strong>赛马会那部。</p><p>另外，引言的第4点是套现，<em>违法行为</em>。</p>]]></content>
      
      
      <categories>
          
          <category> Payment </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Payment </tag>
            
            <tag> 交易场景 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>猎狐</title>
      <link href="/Payment/%E7%94%B5%E8%A7%86%E5%89%A7/payment-tv-hunt-fox/"/>
      <url>/Payment/%E7%94%B5%E8%A7%86%E5%89%A7/payment-tv-hunt-fox/</url>
      
        <content type="html"><![CDATA[<blockquote><p>“猎狐” 经济犯罪类电视剧，还是非常精彩的，不管是表演，有我喜欢的演员；当然还有剧情，对于本人刚进入支付行业的新人来说，里面很多的经济犯罪行为值得学习。</p></blockquote><a id="more"></a><p><img src="/Payment/%E7%94%B5%E8%A7%86%E5%89%A7/payment-tv-hunt-fox/540x303.jpg" alt="猎狐剧照，来源于百度"></p><p>猎狐中有很多经济犯罪行为，</p><ol><li><p>操纵股市</p><p>例如利用媒体散布肝克净研发消息，然后股民为之兴奋，股价上涨，然后王柏林趁机抛售手中的股票，从而大赚一笔；</p></li><li><p>贷款诈骗<br>王柏林以回扣诱惑了支行主任，骗取贷款；哈哈，最搞笑的，是支行行长在这部剧里真的一点主见都没有。全程都被支行主任玩得团团转，而且最后还得被侮辱。</p></li><li><p>集资诈骗</p><p>马世才以理财高收益为诱饵，骗取人钱财</p></li></ol><p>最后的剧情是境外较量，比较精彩，美国看重的是申请绿卡的人在美国的行为是否违法，不管申请人以前是否违法等，所以最后的突破口，就是以王柏林的真实财产证明与其申报的财产差异巨口为突破口，然后成功打破王柏林的绿卡梦。</p><p>整个电视剧看完，真的还是非常有价值的，涨涨见识，已经看看经济犯罪的一般行为以及如何故事有趣。</p>]]></content>
      
      
      <categories>
          
          <category> Payment </category>
          
          <category> 电视剧 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Payment </tag>
            
            <tag> 经济犯罪 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>支付系统架构</title>
      <link href="/Payment/payment-architecture/"/>
      <url>/Payment/payment-architecture/</url>
      
        <content type="html"><![CDATA[<blockquote><p>这个是我认为的支付系统架构，后续再完善。</p></blockquote><a id="more"></a><!-- ![支付架构](payment-architecture/architecture.png)-->]]></content>
      
      
      <categories>
          
          <category> Payment </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Payment </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>支付战争</title>
      <link href="/Payment/%E4%B9%A6%E7%B1%8D/payment-book-paypal-war/"/>
      <url>/Payment/%E4%B9%A6%E7%B1%8D/payment-book-paypal-war/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      <categories>
          
          <category> Payment </category>
          
          <category> 书籍 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Payment </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>如何确定一笔交易</title>
      <link href="/Payment/payment-confirm-trx/"/>
      <url>/Payment/payment-confirm-trx/</url>
      
        <content type="html"><![CDATA[<h2 id="确定一笔交易的要素"><a href="#确定一笔交易的要素" class="headerlink" title="确定一笔交易的要素"></a>确定一笔交易的要素</h2><p>如何确定一笔交易，在ISO8583协议里就已经明确的定义了下面四个域来唯一确定一笔交易</p><ol><li>交易时间  - F7 </li><li>收单机构 - F32</li><li>系统跟踪号 - F11</li><li>发送机构 - F33</li></ol><a id="more"></a><p>前面【1，2】两项是收单机构提供的信息，即交易时间是收单机构在创建交易的时间；</p><p>后面【3，4】两项是发送机构提供的信息，即系统跟踪号是发送机构在收到订单时分配的唯一的ID，也就说同一秒钟，发送机构的系统跟踪号是唯一的。</p><!-- 为啥这四个要素就可以确定唯一一笔交易呢？一笔交易肯定是要经过收单和发卡，那么再加上时间和序列号就唯一确定了，确实设计得很妙和简洁；--><blockquote><p>发送机构 一般是收单机构的总部。</p></blockquote><p>一笔交易确定之后，其他的附加属性来判断是什么交易场景或者交易状态等；</p><p>交易状态例如交易请求还是冲正，根据报文类型标识符来判断，交易请求是0200；交易冲正是0420；</p><p>交易场景例如转账，可以根据交易处理码前2位判断是转账，转出转账还是转入转账。</p><h2 id="限制"><a href="#限制" class="headerlink" title="限制"></a>限制</h2><p>从ISO8583协议里可以看到对上面四个域的定义，其中交易时间为月日时分秒，系统跟踪号为6位数字。那么理论上来说一秒钟内发送机构的最大交易峰值为100万笔。如果超过的话，发送机构可能需要卡在下一秒再处理上一秒未处理完的交易。</p><!-- 不过大多数发送机构的交易处理能力都达不到这个标准，而且现阶段也很难达到交易峰值。--><p>以前听坊间传闻说，银行和阿里对接时，发现最后交易瓶颈都因为银行的系统处理能力达到了上限；</p><p>另外，从现在天猫双十一的交易情况来看，现在也没有超过100万笔上限，况且这些交易都还不是同一个发送机构；</p><p>所以现阶段还是安全的。</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">2018年天猫双11每秒订单创建峰值49.1万笔</span><br><span class="line">2019年天猫双十一，阿里巴巴核心系统100%上云，每秒交易峰值54.4万笔</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Payment </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Payment </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>金融的理解</title>
      <link href="/Payment/fin-service/"/>
      <url>/Payment/fin-service/</url>
      
        <content type="html"><![CDATA[<p>金融是什么，在没有接触金融相关的时候，真的觉得太高深了，头大，也不想去了解它。现在接触到金融相关的，还是一样的感觉，头大，太复杂了。</p><p>不过不管是什么复杂，其本质就服务，金融服务就是服务，那么如何提高服务质量，就需要重新定义支付场景，例如，现在的刷脸支付等都是很好的尝试，但重新定义支付场景都需要考虑时间和空间因素。</p><a id="more"></a><ol><li>时间维度上，尽可能的减少过程时间；</li></ol><p>对于消费者可以快速看到资金变化情况，例如你买的理财，不需要T+1或者T+3才到账；对于商户来说，那么希望资金可以实时到账，减少到账时间，提高资金的周转。</p><p>使用方式更加便捷，更加省时省力，让一切都不在繁琐，客户的体验感舒适。</p><ol start="2"><li>对于空间来说，让空间限制越来越小。</li></ol><p>资金能够透明地跨区域，例如，我到国外旅游，那么我能够自由的使用现有的卡，不管是银联发的卡，还是Visa；因为现阶段，拿着银联的卡去东南亚地区是可以的，但是去其他国家，例如印度或者美国等国家是不能使用的。另外，现在还有一些地方是明确禁止使用某些卡的。</p><p>另外，在网络空间影响更小，在无网络或者弱网络信号的时候，这些影响不再是影响支付的因素。</p><p>总之，重新定义的支付场景都得从时间和空间来衡量，如果解决了任何一个方面，那么此支付场景就是有效的。</p>]]></content>
      
      
      <categories>
          
          <category> Payment </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Payment </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>关于团队知识共享的一些思考</title>
      <link href="/Team/team-sharing/"/>
      <url>/Team/team-sharing/</url>
      
        <content type="html"><![CDATA[<h1 id="关于团队知识共享的一些思考"><a href="#关于团队知识共享的一些思考" class="headerlink" title="关于团队知识共享的一些思考"></a>关于团队知识共享的一些思考</h1><p>团队知识共享，大家都会认同是百利无一害的，但是在一个公司里又谁在做到知识共享呢？</p><p>是不是感到很奇怪？这么好的事情为啥又没有人喜欢呢？哈哈，真有点像渣男渣女讨人爱，好人就该没对象。今天我就谈谈我对团队知识共享的一些历程吧。</p><a id="more"></a><p>因为我从一毕业就在外企工作，外企的一些文化似乎深得大家喜欢；记得以前在HP，惠普之道深入人心，并不是需要去记住什么是惠普之道，而是在与同事一起讨论工作上的事情，一起吃饭谈谈项目情况或者什么有趣的事情，而且每天中午吃完饭都会在园区里溜达一圈消消食等等各种小事之间体会到什么是惠普之道。而在惠普的有段时间里，我从事了运维相关的工作，对的，就是7*24h没有正常作息时间的那种；每天3班倒，倒班时就需要交接，交接不清楚那么接班的人就很难处理，每个人都不希望这样，所以做好交接是一件非常重要的事情。所以交接时，都会把自己手上的事情解释的明明白白。</p><p>把事情解释得明明白白可不是一件容易的事情，每个人的背景或者专长都不一样，所以你要把事情解释清楚，一得看你能否说得清楚，另外还得看对方能否听得明白。</p><p>不过，我们都不会怀疑第一点，因为对于你要描述的事情，你自己是清楚的，所以不管我们怎么表述，我们都是明白的。很多人说，那我提升自己的口才，提升自己的口才这种软实力进步慢而且很长一段时间甚至没有效果，说不定还没到达彼岸就放弃了。别问我是怎么知道的，这个我是不会告诉你的。</p><p>个人觉得让对让对方听得明白，那就让对方懂你，毕竟懂你的才更显珍贵。一个最直接的方式，就是分享你的知识，把你的知识共享给对方，先从一些大家都知道的开始，然后添加一些自己一些特有的知识或者见解，让大家逐步接受你的知识，大家都懂你所说懂你所想，何尝不是一种幸福。同时，在分享过程中，也在丰富完善自己的知识体系，顺便也让你在不知不觉的分享过程中提升了自己的口才。</p><p>有人内心会想，把自己擅长的分享出去了，别人都能替换我，那么不是很容易被替代了吗？常言道，教会徒弟，饿死师傅，如果组织架构优化过程中，那么岂不是被优化的那批人？</p><p>是的，或许不是所有的行业或者职业都适合，但是我是从两个方面来看的：</p><ol><li>从自身来说，分享是个互动的过程，我们分享知识的过程中也在学习新的知识，同时，你也不用花时间去解释或者亲自去解决的事情了，把自己从繁杂的事情中解放出来，那么你可以腾出时间来学习思考新的知识了，或者有时间做点自己喜欢的事情了。</li><li>从管理层来看，也不希望有些事情只有一个人能够处理，<strong>张小平离职事件</strong>也充分提醒了不要把鸡蛋放到一个篮子里，同时也怕能人不服管。</li></ol><p>而分享能带来双赢，而首先需要转变自己的思维。</p>]]></content>
      
      
      <categories>
          
          <category> Team </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Team </tag>
            
            <tag> Sharing </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>央妈在新冠状病毒疫情结束之后的操作</title>
      <link href="/Payment/yangma-coronavirus-actions/"/>
      <url>/Payment/yangma-coronavirus-actions/</url>
      
        <content type="html"><![CDATA[<p>大家都说新冠状病毒疫情影响很大，那为啥这么说，又是如何影响的，央妈又是如何应对这种影响的？</p><a id="more"></a><p>疫情影响了各个领域，经济的齿轮⚙是环环相扣的，从小到每个人的衣食住行，到企业的生死存亡，大到国家的经济发展与金融秩序。</p><p>央妈出台了很多的新政策，让银行在疫情期间给实业搭一把手，所以就得让银行能够有资金来搭手，例如<a href="www.pbc.gov.cn/goutongjiaoliu/113456/113469/4002587/index.html">超额准备金利率从0.78%小调到0.38%，让银行的资金更多的流向市场</a>, 而且从<a href="http://www.pbc.gov.cn/goutongjiaoliu/113456/113469/3993125/index.html" target="_blank" rel="noopener">“应对国际疫情影响，维护金融市场稳定”发布会实录</a> 也可以看到很多的消息； 另外，有些符合条件的银行还降准了；对于个人，房贷可以申请延迟偿还；对于民营或者小微企业，提供差异化优惠金融服务让其有资金去恢复生产等等，然后消除不良贷款风险。</p><p>所以整个链路如下</p><p><img src="/Payment/yangma-coronavirus-actions/image-20200510163215695.png" alt="image-20200510163215695"></p>]]></content>
      
      
      <categories>
          
          <category> Payment </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 疫情 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>如何理解支付</title>
      <link href="/Payment/payment-dependencies-md/"/>
      <url>/Payment/payment-dependencies-md/</url>
      
        <content type="html"><![CDATA[<p>在支付行业，其背后有很多知识学科做支撑，也有很多的专业术语需要去理解。如果想要对支付更好的理解，需要补充很多的知识。经过这段时间，自学了微观经济学，以及还在学习的会计学原理，有一点小的体会，就记录于此。</p><a id="more"></a><h2 id="交易类型"><a href="#交易类型" class="headerlink" title="交易类型"></a>交易类型</h2><p>整个经济过程中，由无数的交易组成，而交易的类型分为两种</p><ul><li><p>货币</p><p>例如早上小李去小刘早餐店购买了一碗重庆小面，支付了现金6元。当然，微信支付宝等支付也算这种交易。</p></li><li><p>信贷</p><p>小李经常在小刘早餐店买早餐，所以小李和小刘早餐店老板刘老板也熟悉了，刘老板觉得小李人还不错，所以小李有一天忘记带钱了，就给刘老板说，这次先欠着，下次一起支付。这个过程叫做信贷，对于小刘来说，她是债权人，小李是债务人。此时相当于向小刘借款，不过后面是需要还的，也类似于向未来的自己借钱。</p></li></ul><p>其实在我们平常的经济活动中，遇到的最多的就是货币交易；但事实是信贷交易的金额占所有交易的95%，因为企业或者个人贷款等等是整个经济活动的金额大头，正如下图冰山图示。</p><p><img src="/Payment/payment-dependencies-md/image-20200412104955323.png" alt="货币信贷比例"></p><p>在水面之下的信贷影响也是最大的，我们知道的2008年的全球金融次贷危机也是这部分导致的。</p><h2 id="货币或者信贷是如何在交易中流通"><a href="#货币或者信贷是如何在交易中流通" class="headerlink" title="货币或者信贷是如何在交易中流通"></a>货币或者信贷是如何在交易中流通</h2><p>前面我们说整个经济活动是由无法交易组成，那么这些交易是如何影响经济活动的，或者说这些钱（包括信贷）是如何交易中流通的。我们假设只有两个人参与这次交易：小李和小刘早餐店刘老板。这里分下面两个场景：</p><ol><li><p>小李去小刘早餐店去买重庆小面并支付了6元，那么这个过程，小李将自己的工资收入中拿出6元，然后支付给刘老板，此时，刘老板的收入增加了6元；所以一个人的收入来自于另一个人的支出。</p></li><li><p>如果有一天小李想吃牛肉面，需要8元，而自己只有6元，此时他使用信用卡支付了2元。那么小李的支出包括两部分：a. 自己的收入：6元； b.自己的信贷：2元；那么刘老板的收入为8元。所以一个人的收入+信贷组成了另外一个人的收入。</p></li></ol><p>一个人的支出能力主要看两部分：收入和信贷；所以简单总结一下：</p><blockquote><p> 支出 = 收入 + 信贷</p></blockquote><p>那么交易过程中涉及金额转移，那么支付就出现了。</p><p><img src="/Payment/payment-dependencies-md/image-20200412130648501.png" alt="支付模型"></p><h2 id="支付"><a href="#支付" class="headerlink" title="支付"></a>支付</h2><p>支付从上述过程中看似简单，从申请一张银行卡或者信用卡，到消费一笔交易时，整个流程会发现有很多方组织参与：央行，卡组织，发卡行，收单机构，第三方收单机构。</p><p>在我们的印象中，如此简单的支付过程，为啥会涉及如此多的组织呢？因为在现在生产力的提高、社会分工精细化、制度和工具越来越成熟健全，以及从量到质的变化。</p><p>为了理解上面的原因，举几个例子</p><ol><li>1983年，中国人民银行才开始行使中国国家中央银行职能，也就说央妈是从1983年才开始成立的。到20世纪末和21世纪初，又从央妈中分离出了证监会，保监会，银监会，各个部门只能更加专一。</li><li>2002年，中国第一个卡组织银联才成立，负责打通各个发卡机构与收单机构的资金清结算网络，方便消费者，同时，更好的监控和了解交易情况。</li><li>从最新银联公布的数据，<a href="https://cn.unionpay.com/upowweb/upOverview" target="_blank" rel="noopener">至2019累计发行银联卡80多亿张</a>, 从<a href="http://data.stats.gov.cn/search.htm?s=总人口" target="_blank" rel="noopener">国家人口数据</a>获知到2019年末为140005万人，人均<strong>5</strong>张多银联卡；</li></ol><h2 id="组织机构关系"><a href="#组织机构关系" class="headerlink" title="组织机构关系"></a>组织机构关系</h2><p><img src="/Payment/payment-dependencies-md/image-20200412164817326.png" alt="组织关系图"></p><p>为了更好说明各个组织间的关系，我这里画了一个简图。在前面提到2002年才成立中国第一个卡组织银联，那么在银联成立之前，那么中间是没有银联的，此时交易是怎么回事呢？这个时候还没有第三方收单机构，银行既是发卡机构也是收单机构，自己发卡，自己收单，而且不支持另外一家的卡。下面通过三个例子来说明，</p><ol><li>你办理了一张招商银行的卡，然后去购物商家那里刷卡，商家得拿出招商银行的POS机来刷卡；如果刚好这个商家不支持招商银行，那么就无法刷卡。</li><li>另外一个现象就是去ATM取款等操作，招商银行只能去招商银行的ATM机，如果去工商银行ATM，对不起，不支持。</li><li>如果你需要从招商银行转账到工商银行，是需要支付手续费的，而且背后实现的原理是：工商银行和招商银行彼此在对方银行开立账户，通过此账户来实现资金转账。这样对各个机构来说，需要在其他机构下开立账户，这样白白的占用了大量资金。</li></ol><p>后面在央妈的牵头下，主要的85家机构共同出资成立了银联，相当于大家一起做老板，有蛋糕大家一起分着吃。</p><p>连线序列不代表先后顺序，而是为了更好的解释说明，同时，这里会屏蔽一些其它的因素，只涉及我自己描述相关的因素。</p><!--    1. 发卡机构得经过央妈批准和监督，且得在央妈开立账户，存入必需的存款准备金，以及超额准备金。    2. 卡组织得经过央妈批准和监督，负责银行卡跨行信息交换网络以及资金清算    3. 收单机构或者第三方收单机构得经过央妈批准和监督，负责受理银行卡业务。好像听说银行收单业务，对银行的利润比例不是特别大，我觉得更多的是收单的竞争太激烈了。    4. 卡组织和发卡机构的关系，a. 发卡机构要发卡，得到卡组织申请BIN号，下表是我从[银行卡BIN码大全](https://blog.csdn.net/zhaohong_bo/article/details/80225815)拷贝了一部分来举例，深圳发展银行发行了三种类型的卡：金卡，普卡和发展卡，可以从BIN区别开来。注意，62是中国银联的标识。b. 在跨行交易时，一些交易文件会发送给发卡机构，当然发卡机构也会发送给卡组织。 c. 在跨行交易时，资金清算之后的轧差会发送给发卡机构。d. 有异常交易等处理平台       | 银行名称     | 机构代码 | 卡类别           | 卡种   | 位数 | BIN号  |       | ------------ | -------- | ---------------- | ------ | ---- | ------ |       | 深圳发展银行 | 3070000  | 人民币信用卡金卡 | 贷记卡 | 16   | 622525 |       | 深圳发展银行 | 3070000  | 人民币信用卡普卡 | 贷记卡 | 16   | 622526 |       | 深圳发展银行 | 3070010  | 发展卡           | 借记卡 | 16   | 622538 |       |              |          |                  |        |      |        |    5. 收单机构和发卡机构类似。不过收单机构不用去卡组织申请BIN号。    6. 消费者到发卡机构申请卡。    7. 申请卡时可以选择不同的卡组织和不同的卡类别，对应的权益也不同。    8. 商户需要到卡组织关联，卡组织会针对不同类型的商户或者特定时间特定地域给与不同的费率。    9. 商户需要和收单机构签约。    10. 消费者拿卡去商户消费。--><p>上述过程，其实消费者在拿卡使用POS机消费之后，可以从小票看到上述发卡行信息，卡BIN信息，从卡BIN信息就知道使用了哪个卡组织，同时，也可以看到商户信息，以及商户对应的收单机构信息等等信息，所以一张小票，提供了很多交易相关信息。下图就是我自己在全家消费的POS小票。</p><p><img src="/Payment/payment-dependencies-md/image-20200412211417906.png" alt="image-20200412211417906"></p><h2 id="支付背后的会计支撑"><a href="#支付背后的会计支撑" class="headerlink" title="支付背后的会计支撑"></a>支付背后的会计支撑</h2><p>当时学习时，对对账文件中借贷总是不能理解，总是要和显示生活中的借贷行为联系上。后面在看了会计学原理之后，才算真正理解过来：借贷只是一种表示符号，不代表任何意义，借在左边，贷在右边而已，而且有借必有贷，借贷必相等。</p><p>借贷到底是增加还是减少，还得从静态会计恒等式说起：</p><figure class="highlight mathematica"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">资产 = 负债 + 所有者权益</span><br></pre></td></tr></table></figure><p>资产在等式的左边，所以对于资产的增加在借方，资产的减少在贷方。</p><p>而负债和所有者权益在等式的右边，所以对于这两个来说，增加在贷方，减少在借方。</p><p>另外一个还有一个坑人的地方，就是借贷的英文单词：Debit和Credit。Credit代表了贷，而Debit代表了借。</p>]]></content>
      
      
      <categories>
          
          <category> Payment </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Payment </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>payment 2019/10/21</title>
      <link href="/Payment/payment-20191021/"/>
      <url>/Payment/payment-20191021/</url>
      
        <content type="html"><![CDATA[<p>从2020年10月21日开始正式入职金融相关的行业，对能够进入自己一直想进入的行业充满了期待，也对自己对金融相关的知识是一片空白感到挑战；有挑战才有成长，所以我将在这里记录下自己对支付相关的学习历程和体会。</p>]]></content>
      
      
      <categories>
          
          <category> Payment </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Payment </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
